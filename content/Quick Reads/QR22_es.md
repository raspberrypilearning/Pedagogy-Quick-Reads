---
title: "Efectos de la antropomorfización en los modelos mentales de los estudiantes acerca de la IA"
lang: "Spanish"
translatedFrom: "[QR22](../QR22.md)"
aliases:
  - QR22_el
draft:
---

Como docentes, nuestro papel es ayudar a los y las adolescentes a desarrollar modelos mentales que les permitan navegar en un mundo que depende cada vez más de los sistemas de inteligencia artificial (IA). A menudo, a los sistemas de IA se les asignan atributos humanos, como sentimientos, estados mentales y comportamientos[^1]. La **antropomorfización** de la IA está consolidada por las representaciones de obras de ficción (películas, televisión y libros) y de los medios de comunicación. Los medios de comunicación suelen utilizar imágenes de robots sonrientes con apariencia humana para ilustrar historias relacionadas con los sistemas de IA[^1]. El lenguaje que se emplea en este campo también es inherentemente antropomórfico, desde el nombre de inteligencia artificial hasta términos como aprendizaje automático, alucinaciones o palabras de activación.

Estas descripciones pueden interpretarse de forma literal si el alumnado carece de un modelo mental sólido y establecido sobre los sistemas de IA[^2]. El lenguaje utilizado para describir los sistemas de IA los retrata como si fueran capaces de “pensar” o “razonar”, lo cual tergiversa los procesos que utilizan estos sistemas, haciéndolos parecer similares a la inteligencia humana[^3]. Si creemos que los sistemas de IA pueden pensar, entonces también podríamos atribuirles emociones. Esto nos lleva a ver a estas máquinas como si tuvieran intención y un carácter moral, lo que intensifica aún más los miedos y conceptos erróneos existentes sobre las capacidades de estos sistemas.[^3]

> [!example]- Conceptos clave
> **La antropomorfización** es la práctica de asignar características y comportamientos propios de los seres humanos a objetos no humanos[^1].
> 
> La inteligencia artificial (IA) a menudo se describe utilizando un lenguaje muy centrado en lo humano.
> 
> La antropomorfización de la inteligencia artificial genera conceptos erróneos sobre cómo funcionan\
> los sistemas de IA y sus capacidades actuales, además de provocar una pérdida de capacidad de decisión por parte de los usuarios[^3].
> 
> Estas son las acciones que pueden llevar a cabo los docentes para evitar la antropomorfización de los sistemas de IA:
> 
> - No usar IA como sustantivo contable, como en la frase “una IA”.
> - Reemplazar palabras como “escucha”, “entiende” y “crea” por “registra”, “procesa” y “genera”.
> - Utilizar el término IA de la misma manera que utilizarías “biología” o “ciberseguridad”.

## Riesgos de la antropomorfización

Si los y las adolescentes perciben esta tecnología como intrínsecamente similar a los seres humanos, corremos el riesgo de que ello afecte a su...

- **Sentido de capacidad de decisión**: la simplicidad intencional del uso de la IA puede llevar al alumnado a pensar que tienen poco o ningún control sobre su función y su impacto en sus vidas y decisiones. Las personas pueden someterse a los sistemas si los perciben como más inteligentes de lo que son[^4].
- **Seguridad**: cuando los sistemas de IA son vistos como humanos, los y las adolescentes crean conexiones emocionales hacia ellos, lo que puede aumentar la exposición a influencias y manipulaciones[^5].
- **Conexión social**: las personas son más propensas a antropomorfizar estos sistemas si carecen de conexión social en sus vidas o quieren darle sentido a un entorno impredecible[^6].
- **Curiosidad**: la percepción de los sistemas de IA como humanos puede llevar a una falta de compresión sobre su funcionamiento y sus aplicaciones. Este nivel de abstracción puede disuadir a las personas de querer aprender sobre su funcionamiento y fomentar su percepción como “magia”[^7].
- **Sesgos**: cuando los sistemas de IA se perciben como similares a los seres humanos, también suelen ser vistos como “blancos”. Esta percepción de la IA hace que muchas personas de color sientan rechazo por parte de los agentes de IA[^8]. Muchos sistemas de IA también están antropomorfizados como asistentes femeninas, lo que perpetúa el estereotipo de la sumisión de la mujer[^9].

## Casos en los que la antropomorfización funciona

La antropomorfización de los sistemas de IA tiene beneficios para los desarrolladores en términos de adopción y confianza. Cuando los usuarios perciben las herramientas como similares a los seres humanos, son mucho más receptivos a integrarlas en sus vidas y utilizarlas[^4], por lo que los desarrolladores de sistemas de IA pueden tener un interés particular en lograr que la gente los vea de esa manera.

Existen evidencias de que la antropomorfización ayuda a los y las estudiantes a comprender fenómenos complejos en la ciencia. Hacer que los sistemas parezcan más humanos de lo que realmente son también\
nos permite contar historias sobre ellos, lo cual puede resultar útil para aprender conceptos complejos.

En general, la utilidad de la antropomorfización está directamente relacionada con lo cerca que está algo de la inteligencia real. Por ejemplo, es útil para aprender sobre las mareas, pero\
puede llevar a malosentendidos en el aprendizaje sobre los monos[^2]. Los sistemas de IA se presentan como extremadamente cercanos a la inteligencia humana, por lo que la antropomorfización es particularmente peligrosa.

## Cómo evitar la antropomorfización de los sistemas de IA

Para ayudar al alumnado a desarrollar modelos mentales lo suficientemente sólidos que les permitan\
identificar cómo se presentan los sistemas de IA como similares a los seres humanos, puedes hacer lo siguiente:

- Evitar utilizar IA como sustantivo contable. En lugar de decir “una IA”, utiliza calificadores como “sistema de IA”, “aplicación” o “modelo”. Cuando uses el término “IA”, hazlo de la misma manera que los términos “biología” o “ciberseguridad”: como un campo de estudio y práctica, en lugar de como algo tangible.
- Evita utilizar lenguaje humano para describir el comportamiento de las aplicaciones de IA. Utiliza en su lugar un lenguaje propio de los sistemas. Reemplaza palabras como “escucha”, “entiende” y “crea” por “registra”, “procesa” y “genera”.
- No atribuyas demasiada capacidad de acción o control a los sistemas de IA cuando\
  los describas. En lugar de decir “el sistema de IA aprende” o “el modelo de aprendizaje automático (ML) lo hace”, coloca a un humano en la ecuación. Por ejemplo, “los desarrolladores de IA entrenaron el sistema para…” o “las personas usan el modelo de aprendizaje automático para…”.

![Image](Image)
![](../assets/img/quickreads/placeholder.svg)
## Ejemplos

A continuación se presentan algunos ejemplos prácticos de descripciones de sistemas de IA desantropomorfizadas:

### Altavoz inteligente

“Los altavoces inteligentes se activan con frases como 'Hola Google'. A continuación, graban nuestra voz y la envían a un equipo informático a través de Internet.\
Este equipo analiza la grabación y predice la respuesta a nuestras solicitudes, como, por ejemplo, reproducir música o responder una pregunta. A continuación, el altavoz recibe la respuesta prevista y la reproduce”.

### Modelos de lenguaje de gran tamaño (LLM)

“Un modelo de lenguaje de gran tamaño (LLM) es un sistema de IA que genera texto en respuesta a las instrucciones de los usuarios. Cuando se introduce una instrucción, el sistema la divide en partes más pequeñas y las compara con un amplio conjunto de datos de texto con el que se entrenó el LLM. El LLM utiliza los patrones y las relaciones existentes en los datos de entrenamiento para evaluar las solicitudes. A continuación, se genera una respuesta que combina palabras y frases que se prevé que sean relevantes”.


### Referencias

[^1]: Salles, A., et al. (2020). Anthropomorphism in AI. [the-cc.io/qr22\_1](the-cc.io/qr22_1)

[^2]: Tang, X., & Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. [the-cc.io/qr22\_2](the-cc.io/qr22_2)

[^3]: Placani, A. (2024). Anthropomorphism in AI: hype and fallacy. [the-cc.io/qr22\_3](the-cc.io/qr22_2)

[^4]: Huang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. [the-cc.io/qr22\_4](the-cc.io/qr22_4)

[^5]: Williams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. [the-cc.io/qr22\_5](the-cc.io/qr22_5)

[^6]: Alabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. [the-cc.io/qr22\_6](the-cc.io/qr22_6)

[^7]: Tedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. [the-cc.io/qr22\_7](the-cc.io/qr22_7)

[^8]: Cave, S., & Dihal, K. (2020). The Whiteness of AI. [the-cc.io/qr22\_8](the-cc.io/qr22_8)

[^9]: Barau, S. (2024). Deception, discrimination, and objectification: ethical issues of female AI agents. [the-cc.io/qr22\_9](the-cc.io/qr22_9)

[Source pdf](https://static.raspberrypi.org/files/curriculum/quickreads/22-Pedagogy_Summary_Anthropomorphism_2025.pdf)
