## Efectele antropomorfizării asupra modelelor mentale ale elevilor despre AI

Ca profesori, rolul nostru este de să ajutăm tinerii să dezvolte modele mentale care să le permită să navigheze într-o lume din ce în ce mai dependentă de sistemele de inteligență artificială (AI). Sistemele AI sunt adesea prezentate ca având atribute umane, precum emoții, stări mentale și comportamente[^1]. Tendința de a **antropomorfiza** inteligența artificială este întărită de reprezentările din ficțiune — filme, seriale TV, cărți — și din mass-media. Mass-media recurge frecvent la imagini cu roboți zâmbitori, asemănători oamenilor, pentru a ilustra povești despre sisteme AI[^1]. Limbajul din acest domeniu este, de asemenea, în mod inerent antropomorf, de la denumirea de „inteligență artificială” până la termeni precum „învățare automată”, „halucinații” sau „cuvinte de trezire”.

Aceste descrieri pot fi luate ad litteram de către cei care nu au un model mental solid despre sistemele AI[^2]. Limbajul folosit pentru a descrie sistemele AI le prezintă ca fiind capabile să „gândească” sau să „raționeze”, ceea ce prezintă în mod eronat procesele utilizate de aceste sisteme, făcându-le să pară similare cu inteligența umană[^3]. Dacă crezi că sistemele AI pot gândi, atunci s-ar putea să le atribui și emoții. Asta te poate face să vezi aceste mașini ca având intenții și principii morale, ceea ce intensifică temerile și concepțiile greșite existente despre capacitățile acestor sisteme[^3]

## Riscurile antropomorfizării

Dacă tinerii percep această tehnologie ca fiind în mod inerent asemănătoare oamenilor, riscăm să   le afectăm…

- **Autonomia**: Simplitatea intenționată a utilizării AI îi poate face pe elevi să creadă că au foarte puțin, sau chiar deloc, control asupra rolului și impactului acesteia în viața și deciziile lor. Oamenii își pot ceda puterea în fața sistemelor dacă le percep ca fiind mai inteligente decât ei[^4].
- Siguranța: Când sistemele AI sunt văzute ca umane, tinerii declară că simt o conexiune emoțională cu acestea, ceea ce îi poate face vulnerabili la influență și manipulare[^5].
- Conexiunea socială: Oamenii sunt mai predispuși să antropomorfizeze atunci când conexiunea socială lipsește deja din viața lor sau dacă încearcă să înțeleagă un mediu imprevizibil[^6].
- Curiozitatea: Dacă sistemele AI sunt percepute ca fiind umane, acest lucru duce la o perspectivă de tip „cutie neagră” asupra aplicațiilor. Acest nivel de abstractizare îi poate descuraja pe oameni din a-și dori să afle cum funcționează acestea, făcându-i să aibă percepția că AI funcționează prin „magie”[^7].
- Prejudecățile: Când sistemele AI sunt percepute ca fiind asemănătoare oamenilor, ele sunt de asemenea considerate „albe”. Această perspectivă asupra AI înseamnă că multe persoane de culoare se simt descurajate de agenții AI[^8]. Multe sisteme AI sunt, de asemenea, antropomorfizate ca asistente de gen feminin, perpetuând stereotipul că femeile sunt subordonate[^9].

## Când antropomorfizarea funcționează

Antropomorfizarea sistemelor AI are beneficii pentru dezvoltatori în ceea ce privește utilizarea și nivelul de încredere. Când utilizatorii văd instrumentele ca fiind asemănătoare oamenilor, sunt mult mai receptivi la integrarea lor în   viața de zi cu zi și la utilizarea lor[^4], așa că dezvoltatorii de sisteme AI ar putea avea un interes direct ca oamenii să le privească în acest fel.

Există dovezi că antropomorfizarea îi ajută pe elevii mai mici să înțeleagă fenomene complexe din știință. De asemenea, ne permite să povestim   despre aceste sisteme, ceea ce poate fi util în învățarea unor concepte complicate.

Per ansamblu, utilitatea antropomorfizării este direct legată de cât de aproape este ceva de inteligența reală. De exemplu, ea poate fi utilă atunci când învățăm despre maree, dar când învățăm   despre maimuțe poate duce la concepții greșite[^2]. Sistemele AI sunt prezentate ca fiind extrem de apropiate de inteligența umană, ceea ce face antropomorfizarea deosebit de periculoasă.

## Cum să evităm antropomorfizarea sistemelor AI

Pentru a-i ajuta pe elevi să dezvolte modele mentale suficient de rezistente încât să vadă dincolo de prezentarea   sistemelor IA ca fiind umane, poți:

- Evita folosirea AI ca substantiv numărabil. În loc să spui „o AI”, folosește „un sistem AI”, „o aplicație” sau „un model”. Folosește termenul „AI” la fel cum ai folosi „biologie” sau „securitate cibernetică” — ca domeniu de studiu și practică, nu ca un obiect concret.
- Evită folosirea limbajului uman pentru a descrie comportamentele aplicațiilor AI. Folosește în schimb limbaj centrat pe sisteme. Înlocuiește cuvinte precum „ascultă”, „înțelege” și „creează” cu „înregistrează”, „procesează” și „generează”.
- Nu acorda prea multă putere unui sistem AI atunci când îl descrii. În loc de „sistemul AI învață” sau „modelul de învățare automată face”, includeți o persoană în ecuație. De exemplu: „dezvoltatorii de AI au antrenat sistemul să…” sau „oamenii folosesc modelul de învățare automată pentru a…”.

![Image](Image)

## Exemple

Iată câteva exemple practice de descrieri ale sistemelor AI care nu sunt antropomorfizate:

### Boxă inteligentă

„O boxă inteligentă este activată printr-o frază precum ‘Hei Google’. Aceasta înregistrează vocea ta și o trimite prin internet către un computer.\
Computerul analizează înregistrarea și prezice răspunsul la cererea ta, cum ar fi redarea de muzică sau răspunsul la o întrebare. Boxa primește răspunsul prezis și îl redă.”

### Un model de limbaj de mari dimensiuni (LLM)

„Un model de limbaj de mari dimensiuni (LLM) este un sistem AI care generează text ca răspuns la cerința unui utilizator. Când este introdus un prompt, sistemul îl fragmentează în părți mai mici și îl compară cu un set vast de date text pe care a fost antrenat. LLM-ul utilizează tipare și relații din datele de antrenament pentru a evalua promptul. Apoi se generează un răspuns prin combinarea cuvintelor și a expresiilor despre care se prezice că ar putea fi relevante.”

## Concepte-cheie

Antropomorfizarea este practica de a atribui caracteristici și comportamente umane unor obiecte care nu sunt umane[^1].

Inteligența artificială (AI) este adesea descrisă folosind un limbaj puternic centrat pe oameni.

Antropomorfizarea AI duce la concepții greșite despre cum funcționează sistemele AI și despre capacitățile lor reale și determină o pierdere a autonomiei utilizatorilor[^3].

Profesorii pot evita antropomorfizarea AI prin

- Evitarea folosirii AI ca substantiv numărabil („o AI”)
- Înlocuirea cuvintelor „ascultă”, „înțelege”, „creează” cu „înregistrează”, „analizează”, „generează”
- Folosirea termenului AI la fel ca „biologie” sau „securitate cibernetică”

### Referințe

[^1]: Salles, A., et al. (2020). Anthropomorphism in AI. [the-cc.io/qr22\_1](the-cc.io/qr22_1)

[^2]: Tang, X., & Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. [the-cc.io/qr22\_2](the-cc.io/qr22_2)

[^3]: Placani, A. (2024). Anthropomorphism in AI: hype and fallacy. [the-cc.io/qr22\_3](the-cc.io/qr22_2)

[^4]: Huang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. [the-cc.io/qr22\_4](the-cc.io/qr22_4)

[^5]: Williams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. [the-cc.io/qr22\_5](the-cc.io/qr22_5)

[^6]: Alabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. [the-cc.io/qr22\_6](the-cc.io/qr22_6)

[^7]: Tedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. [the-cc.io/qr22\_7](the-cc.io/qr22_7)

[^8]: Cave, S., & Dihal, K. (2020). The Whiteness of AI. [the-cc.io/qr22\_8](the-cc.io/qr22_8)

[^9]: Barau, S. (2024). Deception, discrimination, and objectification: ethical issues of female AI agents. [the-cc.io/qr22\_9](the-cc.io/qr22_9)

[Source pdf](https://static.raspberrypi.org/files/curriculum/quickreads/22-Pedagogy_Summary_Anthropomorphism_2025.pdf)
