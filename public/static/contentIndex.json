{"QR01":{"slug":"QR01","filePath":"QR01.md","title":"Using worked examples supports novices to develop their programming practice","links":["QR02","QR03","QR07"],"tags":[],"content":"\n\n                  \n                  Summary \n                  \n                \n\n\nHuman memory\n\nWorking memory is extremely limited\nLong-term memory has no known limits\nLearning occurs when new knowledge is transferred from working to long-term memory\nSchemas are structured collections of prior learning that can be recalled from long-term memory\nSchemas only occupy a single element in working memory\n\nCognitive Load\n\nCognitive load is a stress on a learner’s working memory, reducing their ability to acquire new learning\nIntrinsic load relates to the complexity of the learning task and the learner’s existing understanding\nExtraneous load is the additional stress placed on the learner due to the way in which the material is presented\n\nManaging intrinsic load\n\nAwareness of learners’ prior experience and understanding helps predict where cognitive overload may occur\nBreaking down the learning into suitable learning episodes helps manage cognitive load\n\nImplications for instruction\n\nPresent only information relevant to the task in a unified way\nPresent information both visually and orally as appropriate, without adding additional load\nUse worked examples to provide scaffolding for novices\nUse collaborative techniques such as pair programming, which distribute the cognitive load amongst learners\n\n\n\n\nCognitive load theory (CLT) is not a new idea, in that the challenges associated with designing effective teaching within the limit of working memory have been studied over the last two decades.12 Whilst the theory isn’t universally established, it has been applied in many settings, and offers some important insights for computing educators.\n\nA model of cognition\nCognitive load theory builds on the idea that human memory has two distinct areas, our short-term working memory and long-term memory. Whilst our long-term memory can be seen as essentially infinite, our working memory is extremely limited, with studies suggesting a processing capacity of between three and nine “information elements”. This capacity can easily become overloaded, impacting on our ability to process the information that we’re\npresented with.\nAs we learn from our experiences, new information is stored in our long-term memory for future recall. Over time, these disparate elements of information are connected with existing understanding into collections of related knowledge or schemas.\nThe goal of effective learning design should therefore be to facilitate the movement of new ideas and information from working memory into conceptually sound schemas.\nBalancing the load\nSweller’s research12 suggests that during a learning episode, there are two key stresses or cognitive loads acting on the learner.\nThe intrinsic load placed on the learner relates to the complexity (number of and interactivity of elements) of the concept(s) or skill(s) being taught, and the gap between the new learning and their existing understanding and any misconceptions they already hold. Educators should take steps to optimise intrinsic load wherever possible.\nThe manner in which new concepts are presented, explored, and applied can lead to an unnecessary extraneous load being placed on the learner. Having to juggle too much new information, or unnecessary information, from multiple sources, can place an increased load on the learner. Through considered instructional design, educators can minimise the extraneous load in their activities.\nManaging intrinsic load\nIntrinsic load stems from the gap between the learner’s existing understanding and the complexity of the new concept or skill being taught. In seeking to reduce the load placed on learners, we need to reduce this gap.\n\n\nEnsure that you are aware of prerequisite knowledge and learners’ existing understanding. When planning the progression between concepts, it can be helpful to use “Objective graphs”, which map connections and dependencies between concepts.\n\n\nBreak the learning up into smaller tasks, or even individual elements. After being taught in isolation, these elements can be revisited, making connections between them. This is useful for highly complex concepts, but a balance is needed in the classroom, where teaching time is constrained and breaking down too far could result in a lengthy and disjointed learning sequence3.\n\n\nOptimising instructional design\nEducators can reduce the extraneous load placed on learners through how they present their materials. Within cognitive load theory, there are a number of observable effects which affect the cognitive load that learners experience.\nThese are some effects that are relevant to the teaching of computing:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffectImplications for computing educatorsSplit attention effect Learners must combine information from multiple sources, which increases cognitive load* Combine diagrams with labels and related expanations  * Annotate programs using comments, in particular identifying common sections of patterns, known as subgoalsRedundancy effect Learners must process and disregard repeated or unnecessary information, which increases cognitive load* Avoid the inclusion of redundant information in diagrams and explanations  * Use accessible language  * Minimise the use of “boilerplate code”Transient information effect Information that doesn’t persist must be stored in working memory, which increases cognitive load* Provide learners with programming “cheatsheets” or reference guides  * Share or create concept maps4 with learners, and highlight concepts and their relationships, to provide scaffolding and reference materialMultimodal effect  Visual and oral information are processed separately, which reduces cognitive load* Combine static images, animations, and oral presentation to spread the load  * When modelling a process, narrate or prompt self-explanation of the thought process to make it visible to learnersWorked example effect  Worked examples provide learners with scaffolding and support to develop generalised solutions, which reduces cognitive load* Use partially or fully worked examples to provide possible solutions to problems, e.g. programming tasks, binary/denary conversions, compression algorithms, etc.  * Use worked examples to model problem-solving processes, including specifying, decomposing, prototyping, and testingCollective working memory effect  Task elements are shared between a group, which reduces cognitive load* Use techniques such as pair programming to share work between learners and thereby spread the load  * Poor communication between learners can add a “cost”, which could eliminate the benefits of this effectOnline PDF\nReferences\nFootnotes\n\n\n(Sweller, J. (1988) Cognitive Load During Problem Solving: Effects on Learning. Cognitive Science. 12, 257–285.)[the-cc.io/qr01_6] ↩ ↩2\n\n\nSweller, J., van Merriënboer, J. J. G., &amp; Paas, F. (2019) Cognitive Architecture and Instructional Design: 20 Years Later. Educational Psychology Review. ↩ ↩2\n\n\nReif, F. (2008) Applying Cognitive Science To Education: Thinking And Learning In Scientific And Other Complex Domains. Cambridge, MIT Press. ↩\n\n\nMühling, A. (2016) Aggregating concept map data to investigate the knowledge of beginning CS students. Computer Science Education. 26(3), 176–191. ↩\n\n\n","frontmatter":{"title":"Using worked examples supports novices to develop their programming practice","fileOrder":1,"displayName":"01 - Cognitive Load Theory","aliases":["Cognitive Load Theory","CLT","QR01"],"draft":null}},"QR02":{"slug":"QR02","filePath":"QR02.md","title":"Using worked examples supports novices to develop their programming practice","links":["QR01"],"tags":[],"content":"Worked examples demonstrate an ‘expert’ solution to a problem and are used in many subjects to support novices, who use the examples as blueprints for solving new but related problems. Learners who encounter worked examples in conjunction with practice problems are more likely to develop and assimilate strategies for solving similar problems1.\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nWell-designed worked examples:\n\nHelp reduce extraneous cognitive load on learners\nAid learners in assimilating new knowledge into their existing understanding\nAre especially useful for novices during the early stages of learning\n\nGood worked examples:\n\nInclude sub-goal labelling to highlight structure and common programming ‘patterns’\nPresent relevant information in an integrated manner\nCombine multiple modes of delivery, such as visual and aural explanations\nMay only be partial and require learners to complete them as part of exploration\n\nIn a learning sequence:\n\nCombine worked examples with similar practice problems\nAlternate worked examples and practice problems to keep the example in mind\nUse a least two examples for each concept or ‘pattern’ explored\nFade the use of worked examples over time\nFocus on examples that emphasise program structure over surface details\n\nIllustrating process:\n\nEducators should explicitly model their approach to solving a problem\nProcess-oriented worked examples emphasise how a solution was reached\nProduct-oriented worked examples provide a possible solution\n\n\n\n\n\nReducing cognitive load\nWorked examples help reduce the extraneous cognitive load placed on a learner’s working memory by providing a model solution for a problem, which the learner can read, understand, and adapt to solve similar problems.\nWhen a learner is given a (partial or complete) solution, they do not need to recall as much from their long-term memory2. If a concept is included in the solution, the learner can quickly retrieve and apply their existing understanding relating to that concept. Partially complete problems help focus learners on particular concepts, because learners only need to focus on the missing aspects.\nIn focussing learners’ attention on structural elements of problems, worked examples support students to organise their new knowledge into schemas.3\nProduct versus process\nThere are typically two types of worked examples3 found in literature. Both support the learner by modelling solutions to problems.\n\nProcess-oriented examples model the steps taken to reach a particular solution. They may be written down, demonstrated by an expert, or captured on video.\nProduct-oriented examples model one possible solution and allow learners to examine and apply the solution to a new context.\n\nThere is evidence that complete novices benefit from process-oriented worked examples, as they provide rationale for each aspect of the solution. Learners with some experience will then benefit more from product-oriented examples, from which they can infer the rationale.\nDesigning worked examples\nWhen designing worked examples, educators should consider the following features that may affect learners’ cognitive load and ability to follow an example.\nThe split attention effect occurs when information about a problem or example is presented separately. In order to follow the example or solve the problem, learners must first combine the separate sources of information in working memory. Where possible, educators should integrate all of the information into one clear representation.\nSimilarly, the redundancy effect occurs when information is duplicated within a problem unnecessarily, or other redundant information is included in a problem. The learner may still process the redundant information when they try to understand the problem, which results in an unnecessary cognitive burden.\nTake advantage of the multimodal effect by presenting key information both visually and aurally, as the brain will process these separately. Studies have shown that presenting the same information — and more specifically, worked examples — in another mode, either simultaneously or sequentially, can support learners in their comprehension, and therefore, their ability to solve future problems.\nIt is broadly accepted that novices (in many fields) tend to focus on the context of a problem and the surface details, rather than the underlying structure and common elements to solutions. Educators can use sub-goal labelling to identify the important components or steps in a solution and highlight them to the learner. To do this, educators could use explanatory comments or annotations, visual labels or highlights, or white space to group related instructions into ‘chunks’.1\nIntegrating worked examples within a learning sequence\nEducators should also consider how to combine worked examples with practice problems and other worked examples.\nIt is important to consider variety: presenting the same concept or programming pattern across multiple examples and problems within varied contexts. This variety helps learners to focus on structural connections between the solutions, and therefore, focus on the general concept, rather than the surface details of the problem.\nResearch suggests that the more worked examples learners experience, the more they benefit, and that learners should be exposed to at least two worked examples for each concept or pattern. Also, some studies suggest that learners should be presented with example and practice pairs,4 which require them to understand an example, then apply it in practice. Alternatively, learners could review one example problem, then complete several practice problems, which would require them to hold the example in working memory for longer.\nWorked examples are highly beneficial for novices, because they support them to build patterns for programs and procedures. However, as learners develop their expertise, they benefit more from solving new problems than from working from examples. Educators should use worked examples while a concept is new, then fade this support over time.3\n\nOnline PDF\nReferences\nFootnotes\n\n\nAtkinson, R. K., Derry, S. J., Renkl, A. &amp; Wortham, D. (2000) Learning from Examples: Instructional Principles from the Worked Examples Research. Review of Educational Research. 70 (2), 181–214. [the-cc.io/qr02_5] (the-cc.io/qr02_5) ↩ ↩2\n\n\nSweller, J., Ayres, P. &amp; Kalyuga, S. (2011) Cognitive Load Theory. New York, Springer. [the-cc.io/qr02_6] (the-cc.io/qr02_6) ↩\n\n\nSweller, J., van Merriënboer, J. J. G. &amp; Paas, F. (2019) Cognitive Architecture and Instructional Design: 20 Years Later. Educational Psychology Review. 31 (2), 261–292. Available from: doi.org/10.1007/s10648-019-09465-5. the-cc.io/qr02_7 ↩ ↩2 ↩3\n\n\nAbdul-Rahman, S. S. and du Boulay, B. (2010) Learning Programming via Worked-examples. In: Proceedings of PPIG-WIP 2010, 7–8 January 2010, Dundee. [the-cc.io/qr02_9] (the-cc.io/qr02_9) ↩\n\n\n","frontmatter":{"title":"Using worked examples supports novices to develop their programming practice","fileOrder":2,"displayName":"02 - Worked Examples","aliases":["Worked Examples","QR02"],"draft":null}},"QR03":{"slug":"QR03","filePath":"QR03.md","title":"Pair programming supports learners to produce better solutions to complex programming problems","links":[],"tags":[],"content":"Pair programming is a pedagogical approach that you can use in your classroom which involves learners working together on a problem to develop programs. This Quick Read aims to highlight the benefits of the approach, as well as factors to consider when applying pair programming in the classroom.\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nDriver/navigator:\n\nLearners take turns playing the role of the driver and the navigator, swapping roles at regular intervals\nThe driver controls the keyboard and mouse and will write the code\nThe navigator focusses on the wider aims of the task, spots errors, problem-solves, and reads out instructions to the driver\n\nBenefits:\n\nReduction in individual cognitive load via the collective working memory effect\nImproved confidence in finding solutions, particularly among female students\nImproved quality of programs (fewer errors, more efficient and elegant code)\nRetention of learners’ interest in the activities, lessons, and subject\n\nKey considerations:\n\nCommunication is key: spend time modelling, emphasising, and rewarding these skills\nSpend time ahead of the lesson carefully planning the pairings based on skills, personalities, or friendships\nEnsure that both the driver and navigator are always working on the same task at the same time\nExperiment with length of intervals to suit your learners’ needs\nEnsure that summative assessment is based on paired and individual work/tests, with a greater weighting to individual work\nCheck that both members of the pair are fulfilling their roles, and do not allow one to dominate\n\n\n\n\n\nWhat is pair programming?\nPair programming is an approach where two people work together to write a program or solve a problem whilst sharing a single computer. Pair programming is routinely used in the software industry and soon came to education as the observed benefits became clear.\nApplication of this concept is more structured than simply asking two learners to work together. Pairing learners without giving guidance as to how you want them to work together can often lead to one, or both, learners quickly losing focus. There needs to be an initial investment of time to develop effective paired work. Ideally, both learners should be engaged and contributing equally to the task. Poor communication can be detrimental to the pair’s collaboration and can cancel out the benefits of pair programming. Therefore, an essential part of making pair programming a success is spending time ensuring that learners have a good understanding of the roles that they will fulfil during the task.\nThe driver will control the keyboard, mouse, or pen, depending on the task. They will write the code or design the algorithm. These tasks have a low-level cognitive demand for the learner and allow them to concentrate on writing code accurately, rather than also having to focus on tasks such as problem-solving, deciphering the instructions, and algorithm development.\nThe navigator will support the driver, watching with a keen eye for any errors being made. The navigator will also play a strategic role by thinking of alternative solutions to problems, reading the notes from the teacher, or even walking around the class to look at what others are doing. These tasks have a higher cognitive demand than the tasks of the driver, but as the navigator doesn’t have the responsibility of having to write the code, the extraneous load on each member of the pair is reduced.\nLearners choose, or are assigned, an initial role and once the task has started, they swap roles regularly — approximately every 5 to 10 minutes (depending on the activity). This will make sure that everyone is playing an equal and active role, and they are encouraged to think in different ways and both take ownership of the problem that they are solving.\nSuggested benefits\nThere are several benefits from pair programming that have been observed through a range of studies. For example, through pair programming, the learners’ individual cognitive load is reduced, because the tasks to complete are shared between them. This is known as the collective working memory effect. Pair programming “separates tasks with low-level demands (typing, computer management and navigation) from tasks with higher cognitive demands (syntax analysis, algorithm development, problem search)”.1 However, poor communication between learners can create additional cognitive load, which could eliminate the benefits of this effect (see ‘Pairing learners’).\nAnother benefit of pair programming is the likely improvement of the quality of the programs produced by the learners. The learners support each other by debugging, spotting syntax errors as they occur, and making their code more elegant and efficient.\nAlthough most studies conducted so far have been with university students, they suggest 2 that pair programming has its biggest impact with learners with less advanced skills and lower confidence, or with groups of learners studying introductory courses in programming.\nAlthough research shows that pair programming benefits all learners, there is some evidence that suggests that the technique has a greater impact on girls. In studies conducted on learners taking foundation programming courses in higher education, Werner et al. 3 reported a significant increase in confidence levels reported by the women who were paired, compared with the women who worked independently. Similar findings by Braught et al. 4 showed that women who worked alone were more frustrated than women who worked in pairs.\nWhilst evidence shows that pair programming can benefit girls in terms of results and their perception of the subject, there is no evidence to suggest that it has a negative impact on boys. Hanks found that female students have more positive impressions of pair programming than their male counterparts, but the differences were not statistically significant.2 Allowing female learners to work together might help maximise some of the benefits of this approach.\nPractical considerations\nPairing learners\nAs an educator, you will need to use your professional judgement to choose the best pairings in order to optimise the benefits of the collective working memory effect.1 Key factors that could be considered when creating pairs include the following:\n\nThe learners’ personalities and social affinity (degree of comfort working together) should be considered for sustained or complex tasks, as the pair will benefit from their established relationship.5\nMany studies advocate focussing on the ‘skill sets’ of the learners when pairing. Whilst there is no consensus from research as to which skill-based pairings are most successful, it is good to start by pairing learners with more advanced skills with learners with less advanced skills.\n\nWhichever method of pairing you opt for, it is important to check in regularly with pairs to ensure that they are working well.\nAssessment\nLearners should be assessed on both their paired work and their individual work. It is not recommended that any summative assessment be based solely on the work that they complete as a pair. Preston5 makes two recommendations for assessment to encourage individual accountability with pair programming:\n\nAssessment should require students to develop code, interpret code, or both\nAssessment scores for individuals should be weighted more heavily than the joint project score when determining the final grade\n\nFurther advice and guidance can be found in a middle school–focused paper by Werner and Denning.6\nOnline PDF\nReferences\nFootnotes\n\n\nSands, P. (2019) Addressing cognitive load in the computer science classroom. ACM Inroads. 10 (1), 44–51. Available from: doi.org/10.1145/3210577. ↩ ↩2\n\n\nHanks, B., Fitzgerald, S., McCauley, R., Murphy, L. &amp; Zander, C. (2011) Pair programming in education: a literature review. Computer Science Education. 21 (2), 135–173. ↩ ↩2\n\n\nWerner, L., Hanks, B. &amp; McDowell, C. (2004) Pair-programming helps female computer science students. ACM Journal of Educational Resources in Computing. 4 (1). Available from: doi.org/10.1145/1060071.1060075. ↩\n\n\nBraught, G., Wahls, T. &amp; Eby, L.M. (2011) The case for pair programming in the computer science classroom. ACM Transactions on Computing Education. 11 (2). Available from: doi.org/10.1145/1921607.1921609. ↩\n\n\nPreston, D. (2005) Pair programming as a model of collaborative learning: a review of the research. Journal of Computing Sciences in Colleges. 20 (4), 39–45. ↩ ↩2\n\n\nWerner, L. &amp; Denning, J. (2009) Pair programming in middle school: What does it look like? Journal of Research on Technology in Education. 42 (1), 29–49. ↩\n\n\n","frontmatter":{"title":"Pair programming supports learners to produce better solutions to complex programming problems","fileOrder":3,"displayName":"03 - Pair Programming","aliases":["Pair Programming","QR03"],"draft":null}},"QR04":{"slug":"QR04","filePath":"QR04.md","title":"Using peer instruction in lessons helps students learn, retain, and discuss computing concepts","links":[],"tags":[],"content":"Peer instruction (PI) is an instructional technique first proposed in the 1990s by Eric Mazur,1 whose research demonstrated the benefits of focused discussion for pupils’ understanding and retention in physics. Subsequent studies have highlighted similar benefits of teaching using peer instruction in other subjects, including computing.23\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nPeer instruction can replace a traditional presentation approach by combining pre-instruction, multiple choice questions, and peer discussion, to encourage deeper engagement with the content in question.\nBenefits:\n\nIt is a straightforward approach for educators to apply in their classrooms\nIt leads to roughly double the learning gains when compared with no PI\nLearners value the PI approach – especially the discussion element\nLearners are more likely to retain key concepts and knowledge taught using PI\n\nKey considerations:\n\nPeer instructions should follow some pre-instruction stimulus, ideally before the lesson\nMake sure that learners understand the rationale and benefits of PI\nAlways encourage participation over correctness; PI is a tool for learning, not assessment\nGive learners challenging questions and time to discuss them\nDecide if you want to collect response data, and if so, how\n\n\n\n\n\nWhat is peer instruction?\nWhile the use of multiple choice questions (MCQs) is commonplace in classroom teaching, they are often only used for assessment. Peer instruction (PI) relies on carefully selected MCQs based on some pre-instruction material. In class, the MCQs are combined with peer discussion to explore and challenge student understanding.\nCrucially, peer instruction begins with some form of pre-instruction (reading, videos, etc.), where learners can study and become familiar with the material in question before the discussion is held.\nPeer instruction is carried out as follows:\n\nThe teacher poses a carefully selected MCQ. Learners have limited time to individually vote for their answer, using a\nmethod such as voting cards, clickers, or raising their hand.\nLearners then discuss the question and their answers in small groups, aiming for a consensus.\nThe teacher displays the same question, and now, learners vote according to their group consensus.\nOptionally, the teacher shares the results of both votes to highlight where responses have changed.\nFinally, the teacher leads a class discussion about the question, sharing the correct answer and exploring the distractor.\n\nThe benefits of peer instruction\nWhile most studies examining peer instruction have so far focused on its use in higher education, the practice offers\nmany benefits which should transfer to other settings:\n\nMazur 1 demonstrated that PI leads to significant learning gains for learners: those engaged with PI made up to twice as much progress as other learners. Similar effects have been found in subsequent studies,2 which also highlight the importance of the discussion element of PI.\nThe same studies indicate that using PI in teaching helps students to retain knowledge.\nOnce PI is part of the regular teaching practice, most students value the PI approach, recognise it’s benefits, value the discussion, and would recommend to PI to their other teachers 2\nPI is fairly straightforward to implement, and evidence shows that even teachers who are new to the practice can quickly see its positive effects 2\nSome researchers cite anecdotal evident that PI may encourage learners to develop a growth mindset.4\n\nWhat makes a good multiple choice question?\nGood-quality MCQs are deceptively hard to write, as teachers have to predict what misconceptions their learners are likely to hold. For some topic areas, there are lists of known misconceptions; for others, teachers need to rely on their experience.\nWhile there are no definitive rules for developing MSQs, these are some guidelines:\n\nQuestions should be clear and unambiguous\nEach question should test one concept only\nLearners should be able to answer questions quickly\nTeachers should learn something from each incorrect response\nIt shouldn’t be possible to answer correctly while still holding onto a misconception\n\nBelow is an example of a question. Can you identify the correct response and explain what might lead learners to select the incorrect responses?\n\nConsiderations for applying peer instruction\n\n\nFor many teachers and learners, classroom peer instruction represents a change in practice. It is important to be clear about the purpose of this approach and how it can benefit learners\n\n\nPi isn’t an assessment tool, but a means of instruction; educators should shift the focus away from getting the correct answers, and instead, promote the participation and discussion aspects of PI\n\n\nA Pi activity should be given as much as possible, especially the discussion step, which should last at least 2–4 minutes. This can feel like a long time\n\n\nIf using an online voting system — such as handheld clickers or web-based quizzes — the recorded data can be helpful in predicting which learners may require extra interventions.\n\n\nConsider how challenging a PI question is; questions should be challenging enough to promote discussion. Mazur suggests that best results are seen where 50% of learners get the initial question wrong.\n\n\nPre-instruction is important. With older learners, a flipped approach is best, requiring them to prepare by reading, watching a video, etc. Where home learning is not possible, peer instruction activities should build on previous lessons, or even on content studied earlier in the lesson.\n\n\nWhere to start\n\n\nReview your content and highlight opportunities for pre-instruction. Consider what learning can be moved outside the classroom to enable discussion during the lesson\n\n\nReview and trial some existing multiple choice questionsusing peer instructions to diagnose some of your learners’ misconceptions.\n\n\nWrite your own multiple choice question(s), describe the misconceptions that each answer addresses, and share the questions(s) with other educators.\n\n\nEncourage learners to deepen their understanding of a topic by writing their own MCQ.\n\n\nVisit Peer Instructions for Computer Science for more guidance and resources.\n\n\nOnline PDF\nReferences\nFootnotes\n\n\nCrouch, C. &amp; Mazur, E. (2001) Peer instruction: ten years of experience and results. American Journal of Physics. 69(9), 970–977. ↩ ↩2\n\n\nPorter, L., Bouvier, D., Cutts, Q., Grissom, S., Lee, C., McCartney, R., Zingaro, D. &amp; Simon, B. (2016) A multi-institutional study of peer instruction in introductory computing. Proceedings of the 47th ACM Technical Symposium on Computing Science Education. New York, ACM. pp. 358–363. ↩ ↩2 ↩3 ↩4\n\n\nSimon, B. &amp; Cutts, Q. I. (2012) Peer instruction: a teaching method to foster deep understanding. Communications of the ACM. 55(2), 27–29. ↩\n\n\nSimon, B., Hundhausen, C., McDowell, C., Werner, L., Hu, H. &amp; Kussmaul, C. (2019) Students As Teachers and Communicators. In: Fincher, S. &amp; Robins, A. (eds.) The Cambridge Handbook of Computing Education Research. Cambridge Handbooks in Psychology. Cambridge, Cambridge University Press, pp. 827–858. ↩\n\n\n","frontmatter":{"title":"Using peer instruction in lessons helps students learn, retain, and discuss computing concepts","fileOrder":4,"displayName":"04 - Peer Instruction","aliases":["Peer Instruction","QR04"],"draft":null}},"QR05":{"slug":"QR05","filePath":"QR05.md","title":"Live coding: using the thought processes of a programmer to bring coding to life","links":["the-cc.io/qr02"],"tags":[],"content":"When learners read static, completed programs, they aren’t exposed to the troubleshooting that has already taken place to get to that end product; this is known as being product focused. Live coding is when a teacher develops the solution to a problem in front of the class for learners to follow, which is known as being process focused.\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nBenefits:\nAccording to the literature,12 the key benefits of live coding are that it:\n\nReduces cognitive load, through collaboration\nMakes the process of learning programming easier to understand for novices\nHelps learners understand the process of debugging\nExposes learners to good programming practices\n\nGood practice when live coding:\n\nSelect an appropriate programming challenge to teach a new concept, consolidate learning, or address misconceptions\nTalk to your learners and ask them questions\nNarrate your inner monologue\nMake (and fix) mistakes, either planned or accidental\nSlow down to give your learners time to process\nShow learners that code isn’t written from top to bottom in a linear form; it moves around as it is developed\nBe visible: let learners see your face, don’t turn your back for too long\nPause to write things on the board: draw diagrams, work things out\nUse the largest font possible (without losing view of the full line of code)\nBreak the code into small chunks (decompose) and use subgoal labelling while forming the solution\n\nStrong links with worked examples:\nLive coding helps novices learn by observing an expert programmer working through a problem, and so it has strong links to the concept of worked examples. Further information can be found on our Quick Read .\n\n\n\n\nBringing programming to life\nNovice programmers can often look at a finished program and have the misconception that it has been written from top to bottom and that a skilled programmer always knows exactly what they are doing and can just write out what they need without making any mistakes. As any programmer or even a\nwriter knows, this is not the case.\nLive coding demonstrates to learners the incremental nature of programming. It shows that problems are decomposed into small sections that are programmed, tested, and debugged, before the next stage is worked upon. It models good programming practice and shows learners that a plan for a program is formulated and followed, rather than a solution formed on an ad hoc basis.\nBringing programming to life is essential to show learners that program development is non-linear. The code moves around and changes as a solution is developed. It models how programs should be frequently tested to debug them quickly. It also shows learners how to solve common errors that may occur when using a new concept.\nCognitive apprenticeships\nThe idea of cognitive apprenticeships was introduced by Collins et al.3 in 1987. They believed that “teaching methods should be designed to give students the opportunity to observe, engage in, and invent or discover expert strategies in context”.\nAt the modelling stage of cognitive apprenticeships, an expert shows learners how to carry out a task, which “requires the externalization of usually internal (cognitive) processes and activities”.3 In live coding, an educator develops a program in front of a class while highlighting their choices, decisions, mistakes, and debugging strategies.\nCoaching (an aspect of cognitive apprenticeships) is where learners are given a challenge that is slightly too much for them to handle but are supported through the solution through feedback and modelling. Live coding is a great example\nof a coaching strategy, guiding learners through a task that would usually be unattainable.\nSlowing down to get the best results\nLive coding is very different to reading solutions on a worksheet or in a textbook. Those examples show a final, polished solution without any insight into how the programmer has made  decisions about their code. The Role of Live-coding1 paper states that “when students begin to learn programming, usually they don’t have a good idea about where to start”.\nIf you write your solution in front of learners it forces you to slow down, which helps you think about what you are doing and enables learners to follow your process. It is important that you don’t simply copy and paste the solution from one tab into a new window; this defeats the purpose and your learners may get lost very quickly. You could write some notes about how you solved the problem and keep these on your desk as a prompt.\nLearners benefit from following the process of your work, as it keeps them engaged in finding the solution. This is another reason why slowing down is important. You can chunk the demonstration and have sections where learners watch and sections where they code. It is important that they don’t miss key things while they are typing, so monitor their progress as you carry out your session.\nYou can also provide video recordings of your sessions to help learners who may need a recap or learn at a different pace. If you decide to record your live coding session, make sure you stick to the live coding principles and don’t create a step-by-step tutorial instead.\nPredicting testing and debugging\nWhen carrying out a live coding session, it is important that it doesn’t become a tutorial that leads learners to the perfect solution on their first attempt. The learners are part of the journey. The best way to engage them is to ask them to make predictions about the program before it is run.\nWilson’s Teaching Tech Together4 emphasises the importance of making mistakes while live coding. Mistakes should be “embraced” because they allow learners to see that programmers don’t get it right first time and often have to review and fix their work to find a solution.\nWhen live coding, you should plan intentional mistakes but should also be confident when making unintentional mistakes. Intentional mistakes should link to common errors or learner misconceptions in order to target and alleviate them. You should also continually test your program. This helps learners see this as a natural way to program and teaches them to frequently test their own work.\nWhen making intentional mistakes, encourage learners to predict what will happen, before running the code. Doing so will help learners suggest strategies to fix those errors. Miller et al.5 discovered that “students who predict are significantly more likely to correctly report the outcome of a demonstration”. Outcomes were improved whether their prediction was correct or incorrect. Therefore, asking prediction-focused questions while live coding is an important part of the process.\nOnline PDF\nReferences\nFootnotes\n\n\nHalverson, E., Halverson, R., Patel, J., Raj, A. (2018) Role of live-coding in learning introductory programming. ACM. 13, 1–8. Available from: doi.org/10.1145/3279720.3279725 ↩ ↩2\n\n\nSands, P. (2019) Addressing cognitive load in the computer science classroom. ACM Inroads. 10 (1), 45–51. Available from: dl.acm.org/doi/10.1145/3210577 ↩\n\n\nBrown, J.S., Collins, A., Newman, S. E. (1987) Cognitive apprenticeship: teaching the craft of reading, writing and mathematics. BBN Laboratories, Cambridge, MA., Centre for the Study of Reading, University of Illinois. Report number: 403. ↩ ↩2\n\n\nWilson, G. (2009) Teaching tech together: how to create and deliver lessons that work and build a teaching community around them. Abingdon, Taylor &amp; Francis. Available from: teachtogether.tech/#s:performance-live ↩\n\n\nChu, K., Lasry, N., Mazur, E., Miller, K. (2013) Role of physics lecture demonstrations in conceptual learning. Physical review physics education research. 9 (2), 1–5. Available from: journals.aps.org/prper/pdf/10.1103/PhysRevSTPER.9.020113 ↩\n\n\n","frontmatter":{"title":"Live coding: using the thought processes of a programmer to bring coding to life","fileOrder":5,"displayName":"05 - Live Coding","aliases":["Live Coding","QR05"],"draft":null}},"QR06":{"slug":"QR06","filePath":"QR06.md","title":"Improving explanations and learning activities in computing using semantic waves","links":[],"tags":[],"content":"Semantic waves’ describe an ideal conceptual journey for novice learners to follow, shifting between expert and novice understanding, abstract and concrete context, and technical and simple meanings. It is part of Legitimation Code Theory or ‘LCT’ (Maton, 2013). Semantic waves have been successfully applied by educators across many disciplines, including computing, to plan and evaluate learning experiences. The theory also helps explain when and why metaphor and unplugged teaching works (and why sometimes, they might not).\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nFollowing a semantic wave structure:\n\nHelps make expert knowledge accessible to novices\nVaries the context of the concept to build links with concrete examples\nConnects the technical terminology used in activities with simpler\nmeanings\nHelps learners to unpack new concepts and repack them into more complex contexts, to encourage knowledge acquisition\nPromotes securing knowledge of one concept before progressing to the next\nHelps novices develop both understanding of abstract concepts\nand mastery of technical meanings\n\nConsiderations:\n\nPlan your lessons around a semantic wave structure; look for opportunities to unpack and repack concepts\nEvaluate your lesson plans and explanations in detail, drawing the\nsemantic profile\nMake sure that learning resources use both routes to expertise, varying either language or context\nAvoid ‘semantic flatlines’, i.e never unpacking or repacking concepts\nComplete each semantic wave and avoid the ‘down escalator’\nEncourage learners to write their own explanations using semantic wave\n\n\n\n\n\nFollowing a semantic wave\nComputing, and especially programming, is a subject with lots of technical terms that have precise technical meanings. To succeed, learners have to master the terminology whilst simultaneously developing a firm understanding of the concepts. A great strategy to support learners is to make your learning experiences follow a semantic wave.[^1] This involves introducing abstract concepts (with the associated terminology), but then using simpler language to explain their meaning. This is why metaphors, analogies, and unplugged computing are powerful ways to teach (provided that they are used well).[^2] However, it is important to then help students link those simpler meanings directly back to the abstract concepts and associated technical\nlanguage.\nFor example, when the educator introduces the idea of variables and assignment (using technical words and abstract concepts), learners are at the top of a semantic wave. To help learners descend the semantic wave, the educator might [explain variables using boxes](the-cc.io/qr06_4. To help them descend further, the educator might then illustrate the explanation with physical props. However, the educator shouldn’t leave learners thinking that it is just about boxes by only talking about moving values between boxes; they must help learners link it back to the technical and abstract, so that learners can surf back up the semantic wave. For example, the educator might demonstrate a sequence of assignments in Python step by step by putting values in boxes, or they might have learners follow a program fragment, to help learners repack the meanings. In traversing this wave, educators can support their learners to understand complex, abstract concepts that are underpinned by concrete and familiar ideas.\nLanguage and context\nExperts and novices understand and describe concepts differently. Whilst novices are more comfortable using concrete contexts to express concepts in simpler language, experts are far more likely to describe the same concepts in the abstract and using precise technical language. Unpacking and repacking concepts is achieved by adjusting either of these two aspects. By decreasing the complexity and precision of the terminology (‘semantic density’),[^1] educators can make the ideas more accessible to learners. Educators may start with precise terminology such as ‘iteration’ or ‘selection’, but then use less precise terms for novices (e.g. ‘repeating’, or ‘decision’). An important final step is to return to the original and precise terms that were used to introduce the concept.\nThe other approach to unpacking and repacking concepts revolves around the context through which they are presented (‘semantic gravity’).[^1] Educators do this all the time through analogy, unplugged activities, physical computing, etc. A more contextualised exploration of a concept gives learners a concrete example around which they can build their understanding. However, if learners don’t then step back from their concrete examples and view the concepts in the abstract, their understanding may become limited to the single context.\nFor both language and context, the repacking phase in the semantic wave is crucial: during this phase, learners explore the nuance of technical terms like ‘algorithm’, as well as where analogies work, and where they break down. They move their understanding from the specific and concrete to the general and abstract.\nSemantic profiles\nSemantic profiles are visual representations of changes in language and context within a learning activity, and allow educators to critique those experiences. Studies have identified some common teaching patterns that have poor semantic profiles, and therefore lead to poor explanations, and make it harder for students to learn.[^3]\n\nHigh flatlining: The educator might only explain and discuss concepts in technical language and abstract contexts. This is what experts do when talking together; they do not unpack the meanings at all, as they can assume that the other has mastery of the language and concepts. Such an explanation is incomprehensible to a learner, as they do not understand the terminology.\n\nLow flatlining: The educator might only use simpler examples and language, and never make the links to the concepts that they are trying to explain, or move out of specific contexts. For example, in a lesson about algorithms, if the educator just talks about recipes, learners may understand the explanation but never understand how recipes are like algorithms, or how they are not.\n\nDown escalators: The educator might structure an explanation or lesson so that it takes learners down the semantic wave, but not back up. The educator makes a link from a technical concept, but learners do not repack the ideas during the activity. The class moves on to the next concept before having repacked the simpler meanings into the technical meanings.\nReviewing learning activities\nA really important use of semantic waves, and semantic profiles in particular, is as a basis for reviewing learning activities. By doing this, educators can predict and monitor the challenges for their learners, and improve their learning experiences. For example, in a recent paper, Waite et al.[^4] used this methodology to review the Barefoot activity “Crazy Characters”.\nThis Pedagogy Quick Read was adapted from Paul Curzon’s blog,[^5] which is based on the work of Karl Maton applied to a computing context. We would like to thank them both for their input.\nOnline PDF\nReferences\n\nMaton, K. (2013) Making semantic waves: A key to cumulative knowledge-building. Linguistics and Education. 24(1), 8–22.\nCurzon, P., McOwan, P. W., Donohue, J., Wright, S. &amp; Mars, D. W. (2018) Teaching of concepts. In: Sentance, S., Barendsen, E. &amp; Schulte, C. (eds.) Computer Science Education: Perspectives on Teaching and Learning in School. London, Bloomsbury Publishing, pp. 91–108.\nMaton, K. (2019) Semantic waves: Context, complexity and academic discourse. In: Martin, J. R., Maton, K. &amp; Doran, Y. J. (eds) Accessing Academic Discourse: Systemic Functional Linguistics and Legitimation Code Theory. London, Routledge, pp. 59–85.\nWaite, J., Maton, K., Curzon, P. &amp; Tuttiett, L. (2019) Unplugged Computing and Semantic Waves: Analysing Crazy Characters. In: UKICER: Proceedings of the 1st UK &amp; Ireland Computing Education Research Conference. New York, Association for Computing Machinery. Available from: doi.org/10.1145/3351287.3351291.\n[Curzon, P. (2019) Tip 9: Follow Semantic Waves — Learning To Learn (To Program). Available  from: teachinglondoncomputing.org/learning-to-learn-to-program\n[an informal blog about practical ideas for teaching programming]].(the-cc.io/qr06_9)\n","frontmatter":{"title":"Improving explanations and learning activities in computing using semantic waves","fileOrder":6,"displayName":"06 - Semantic Waves","aliases":["Semantic Waves","Semantic Wave Theory","QR06"],"draft":null}},"QR07":{"slug":"QR07","filePath":"QR07.md","title":"Using concept maps to capture, communicate, construct, and assess knowledge","links":["tags/Applications","QR01"],"tags":["Applications"],"content":"Concept maps are “graphical tools for organising and representing knowledge”.1 Fundamentally, they consist of concepts and the labelled links between them, which together describe knowledge in the form of statements or propositions. In education, concept maps can capture the knowledge of subject experts, educators, and learners, so they can be used for planning, teaching, learning, and assessment.\n\n\n                  \n                  Summary \n                  \n                \n\n\nBenefits:\nComponents:\n\nConcepts, which are often arranged in a hierarchy, form the basis of concept maps.\nLinks connect the concepts to indicate a relationship between them. Cross-links are links across different branches of the hierarchy.\nLabels on the links (usually verbs) specify the relationships between the concepts.\nA focus question provides context for the concept map and guides its construction.\nPropositions or units of meaning are formed by following a link from one concept to  another, e.g. “A concept map answers a focus question”.\nExamples are instances of concepts that may be included to make concepts clearer and more concrete.\n\nConstruction:\n\nDetermine the focus question.\nList (and possibly order) the relevant concepts in a parking lot.\nConnect concepts from the parking lot to form propositions.\nRearrange and refine.\n\nApplications:\n\nInforming the planning of learning experiences\nFacilitating communication and collaboration between educators\nPresenting or summarising information for learners\nSupporting learners to connect new information to existing knowledge\nHelping educators to assess prior knowledge, misconceptions, and assimilation of new information\n\nFor concept maps to have a positive impact, they need to be a fully integrated feature of the teaching and learning process.\n\n\n\n\nWhat they are\nConcept maps are tools for representing knowledge visually, as an interconnected network of concepts. The links connecting the concepts are labelled (unlike in mind maps) to specify the relationships between them. Therefore, any transition between concepts over a labelled link forms a short proposition or unit of meaning.\nConcepts may be structured in a hierarchy. Links that span across different branches of the hierarchy are called cross-links, and uncover deeper connections. A concept map captures knowledge relevant to a focus question that provides context for the map and helps direct its construction and comprehension. Some nodes in a map may not correspond to concepts, but rather, may be concrete examples of concepts.\nConcept maps are a means for “externalising cognition, making mental models visible so that they can be compared and combined”. As such, they can be useful for representing the knowledge of both educators and learners, making them a versatile educational tool.\nHow to make concept maps\nHere at the Raspberry Pi Foundation, we use concept maps as part of our planning process. You can find examples online and a guide to constructing them below.\nDetermine the focus question: Specify what the knowledge represented in a concept map will be about. The focus question can be broad, such as “How are images represented using binary digits?” or specific, such as “How does this piece of code work?“.\nPopulate the parking lot of concepts: Determine the list of concepts, ideas, or keywords that are relevant to the focus question. If it makes sense, order them according to how general they are, or how relevant they are to the focus question. This is the first step towards structuring the concepts into a hierarchy.\nExplore the relationships between concepts: Link related concepts and label the links to specify their relationships. This essentially amounts to forming propositions that connect the concepts.\nImprove and refine: Building concept maps is always an iterative process, and concept maps should never be considered finished.\nIn education, the process of constructing a concept map (and even that of reading and interpreting it) must be demonstrated\nby the educator. Building a concept map can also be a collaborative activity.\nHow they can be used in education\nEducators can use concept maps to capture the knowledge that they aim to convey to their learners. Concept maps have a specific structure, which places restrictions on their expressive power. Therefore, in order to represent knowledge with a concept map, educators have to break that knowledge down into short propositions. This is a challenging but illuminating process of introspection and iterative refinement that will help them create a representation of their\nteaching content in a simple, distilled form.\nConcept maps that capture subject knowledge can be used by educators in a variety of ways. They can inform the planning of a lesson or sequence of lessons. They can serve as a means of communication with other educators, especially if they are drawn collaboratively. They can also be used to support teaching and assessment.\nConcept maps can be presented to learners as a supplementary way to provide or summarise information. Educators should start with a minimal skeleton map that will be iteratively extended when new knowledge is introduced, which will support learners to organise this new information and connect it to existing schemas. Concept maps can also be used as study guides and revision tools.\nConcept maps can be used for assessment in a number of ways. For example, educators could ask learners to fill in concepts or links, or to extend an existing concept map. Learners could repeat this process over several lessons: they could start with a parking lot of concepts, which they could then incorporate into their concept maps as the lessons progress. This would help identify misconceptions or unassimilated concepts in every step, as learners’ concept maps\nprovide insights into their understanding. Educators could use these activities to aid recall or assess prior knowledge, or to prompt learners to summarise new concepts whilst connecting them to form propositions.\nConcept maps should be tightly integrated into the teaching and learning process, and they should only be used for assessment if they have been consistently used in teaching.\nWhy they should be used\nThere is sufficient evidence to suggest that an integrated use of concept maps in teaching can be beneficial to learners, especially less confident learners, or learners who struggle with reading.234\nConcept maps represent knowledge visually, highlighting the structure and the connections between concepts. Their potential to enhance learning, retention, and transfer is often linked to cognitive load theory: as learners struggle to identify concepts, and as the connections between concepts place a burden on working memory, concept maps facilitate schema construction by “serving as a kind of template or scaffold to help organize knowledge and to structure it, even though the structure must be built up piece by piece”.1 This links back to the suggestion that concept maps should be developed iteratively, through “an orderly sequence of iterations between working memory and long-term memory, as new knowledge is being received and processed”.1\nOnline PDF\nReferences\nFootnotes\n\n\nNovak, J. &amp; Cañas, A. (2008) The Theory Underlying Concept Maps and How to Construct and Use Them. Florida Institute for Human and Machine Cognition. Technical Report IHMC CmapTools 2006-01 Rev 01-2008. ↩ ↩2 ↩3\n\n\nNesbit, J. &amp; Adesope, O. (2006) Learning With Concept and Knowledge Maps: A Meta-Analysis. Review of Educational Research. 76 (3), 413–448 ↩\n\n\nHorton, P., McConney, A., Gallo, M., Woods, A., Senn, G. &amp; Hamelin, D. (1993) An investigation of the effectiveness of concept mapping as an instructional tool. Science Education. 77 (1), 95–111 ↩\n\n\nCañas, A., Coffey, J., Carnot, M., Feltovich, P., Hoffman, R., Feltovich, J. &amp; Novak, J. (2003) A Summary of Literature Pertaining to the Use of Concept Mapping Techniques and Technologies for Education and Performance Support. Florida Institute for Human and Machine Cognition. Report prepared for the Chief of Naval Education and Training. ↩\n\n\n","frontmatter":{"title":"Using concept maps to capture, communicate, construct, and assess knowledge","fileOrder":7,"displayName":"07 - Concept Maps","aliases":["Concept Maps","QR07"],"draft":null,"tags":["Applications"]}},"QR08":{"slug":"QR08","filePath":"QR08.md","title":"Planning and reflecting on distance learning in the context of 'emergency remote teaching'","links":[],"tags":[],"content":"The exceptional events of 2020 have dramatically altered the way that education is delivered to students around the world. For the majority of learners in the United Kingdom, schools are not currently delivering face-to-face lessons in school buildings; instead, schools and other providers have had to adopt distance learning approaches. This first Quick Read introduces some terms, frameworks, and barriers related to distance learning, and aims to support educators as they rapidly design a remote way of working.\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nTerminology:\nDistance learning includes a range of approaches to deliver activities to learners who are not in the same space as their teacher. The terminology used to describe these approaches includes:\n\nOnline teaching: any teaching that uses online activities\nSynchronous online teaching (SOT): online teaching where the teacher and  student(s) are communicating in real time\nAsynchronous online teaching (AOT): online teaching where the teacher and student are not communicating at the same time\nOnline blended teaching: a combination of synchronous and asynchronous  online teaching\nE-learning: the use of electronic systems and applications within the learning process, including synchronous and asynchronous online teaching\nVirtual schools: schools which only provide asynchronous online teaching\nRemote teaching or remote learning: any teaching where the teacher and student are not in the same physical  location (synchronous or asynchronous)\nEmergency remote teaching: a temporary shift to remote delivery, due to crisis circumstances 1\n\nDespite a lack of robust evidence on the effectiveness of online teaching on schoolaged pupils23, schools are currently being required to rapidly implement distance learning approaches.\n\n\n\n\nEmergency remote teaching and an online learning framework\nIn March 2020, a blog post by a group of US university academics coined the term ‘emergency remote teaching’ to describe the wholesale transfer of higher education provision across the world to online delivery 1. In doing this, the authors remind us that this hurried transfer was not planned and therefore the full opportunities of online delivery cannot be reasonably expected. Instead, they highlighted the importance of providing learners with social support, the need for flexible and creative ways to deliver learning in a crisis, and acceptance that emergency teaching may not be as high quality as normal provision.\nThe authors introduce a well-regarded framework for describing online learning, which can be used in a range of educational contexts to capture many features of a learning activity2. The framework summarised above identifies five dimensions to describe an online activity and the components within each dimension. Educators can use this template, based on the complete framework, to describe and review their own online learning activities.\nDistance education pedagogies\nAnderson and Dron recognised that distance learning pedagogies have changed over time, and identified three generations that have developed as a result 3. To be successful in providing high-quality distance learning, they concluded that all three generations of pedagogy should be used, in relation to the learning content, context, and expectations.\nSummary of distance education pedagogies\n(Anderson &amp; Dron, 2011, .p 92)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneration of distance education pedagogyTechnologyLearning activitiesLearner granularityContent granularityEvaluationTeacher roleScalabilityCognitive–behaviourismMass media: print, TV, radio, one-to-one communicationRead and watchIndividualFine: scripted and designed from the ground upRecallContent creator, sage on the stageHighConstructivismConferencing (audio, video, and web), many-to-many communicationDiscuss, create, constructGroupMedium: scaffolded and arranged, teacher-guidedSynthesise: essaysDiscussion leader, guide on the sideLowConnectivismWeb 2.0: social networks, aggregation &amp; recommender systemsExplore, connect, create, and evaluateNetworkCoarse: mainly at object and person level, self-createdArtefact creationCritical friend, co-travellerMedium\nHowever, teachers need guidance on what each of these pedagogies might look like in practice, and the barriers that might be associated with them.\nBarriers to implementing online learning\nRecently, University of Reading researchers reviewed e-learning research from 1990 to 2016 to identify barriers to implementing e-learning4. The authors identified 68 barriers and grouped these into a proposed TIPEC framework of technological, individual, pedagogical, and enabling categories.\nEducators developing remote learning activities can use the TIPEC framework to help them identify barriers pertinent to their setting; they might set up training events to teach students and parents how to use new technologies, or survey families to discover their level of access to these technologies.\n\nAs educators adapt to the realities of emergency remote teaching, we encourage them to:\n\nAccept that in the context of emergencies, the quality of learning is likely to be lower that ‘normal’\nReflect upon their online learning activities and the experience they deliver for learners\nConsider the range of barriers associated with online learning and how they can be mitigated\n\nIn our next Quick Read, we will focus on the benefits and challenges associated with emergency remote teaching, including the impact on learners and their families.\nOnline PDF\nReferences\nFootnotes\n\n\nHodges, C., Moore, S., Lockee, B., Torrey Trust, T. &amp; Bond, A. (2020) The Difference Between Emergency Remote Teaching and Online Learning Available from: er.educause.edu/articles/2020/3/the-difference-between-emergency-remote-teaching-and-online-learning [Accessed 2/10/2025] ↩ ↩2\n\n\nMeans, B., Bakia, M. &amp; Murphy, R. (2014) *Learning Online: What Research Tells Us About Whether, When and How*, New York, Routledge. ↩ ↩2\n\n\nAnderson, T. &amp; Dron, J. (2011) Three generations of distance education pedagogy. The International Review of Research in Open and Distributed Learning. 12 (3), 80-97. Available from: doi.org/10.19173/irrodl.v12i3.890 ↩ ↩2\n\n\nAli, S., Uppal, M. A. &amp; Gulliver, S. (2018) A conceptual framework highlighting elearning implementation barriers. Information Technology &amp; People. 31 (1), 156-180. Available from: doi/10.1108/ITP-10-2016-0246 ↩\n\n\n","frontmatter":{"title":"Planning and reflecting on distance learning in the context of 'emergency remote teaching'","fileOrder":8,"displayName":"08 - Emergency Remote Teaching","aliases":["Emergency Remote Teaching","ERT","QR08"],"draft":null}},"QR09":{"slug":"QR09","filePath":"QR09.md","title":"Planning effective surveys and interviews for research or evaluation","links":[],"tags":[],"content":"Surveys and interviews are common tools used by researchers to understand participants’ perceptions, attitudes, and feelings.\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nSurveys:\n\nHighly structured in terms of questions, responses, and ordering\nQuick to produce and answer, meaning a large number of responses can be analysed\nPredominantly rely on closed-question types\nData is typically quantitative\nOnly capture what is asked and may lose nuanced responses\n\nPlanning considerations:\n\nClear, age-appropriate language\nAvoid ambiguity in questions\nAvoid questions that ask multiple things\nAvoid leading questions\nOnly ask sensitive or emotive questions if it’s integral to the research\n\nInterviews:\n\nLess structured by nature\nTake time to produce, conduct, and analyse\nQuestioning is generally more open\nData is predominantly qualitative\nCaptures nuance and richer responses\n\nPlanning considerations:\n\nUse neutral responses and non-verbal cues\nUse prompts and reworded questions to elicit more detail\nBegin with simpler questions to make the learner feel comfortable\nRecord and transcribe where possible to capture responses verbatim\n\n\n\n\nClassroom action research is an effective approach that teachers can use to embed evidence-based pedagogies into their practice. This approach is the subject of the online course: Improving Computing Classroom Practice Through Action Research.\nTo understand your learners’ perceptions, attitudes, and feelings, you should use direct questioning so that they can describe their own experience or ‘self-report’. Self-report measures include face-to-face interviews and written or electronic surveys. Whilst each approach is different, they both require careful planning to ensure that they are effective, reliable, and valid.\n\nInterviews and surveys\nThe choice of whether to conduct an interview or survey will depend on the research question you aim to address. It will also affect the type and scope of the data you collect:\nSurveys have a set order of questions and usually rely on a limited set of possible answers (either ‘Yes/No’, or a scale of agreement) with few (if any) open-ended questions. Surveys therefore tend to provide quantitative, or numerical, data.\nInterviews can take a number of different forms. Some are fully structured like surveys, while others allow for more open-ended responses and/or more naturalistic conversation between the interviewer and the respondent.\nInterviews tend to provide qualitative data. The more structured types of interviews have the advantage of being reliable and replicable by other researchers, and often take less time to conduct than looser interview formats. However, you may lose the richer and more nuanced data collected in less-structured interviews.\nOne of the most common approaches to interviewing is the semi-structured interview, which has a guiding outline of topics to be covered, but no standardised questions or set order in which to ask them. This allows you as the interviewer to keep the questions closely related to your research aims, but also means that there is flexibility for conversation to develop naturally before looping back to a different topic.\nLanguage and context\nThe majority of surveys that you see will consist of closed questions. Although this can reduce the detail and richness of the information you gather, it does mean that you can collect a large amount of standardised and reliable data. However, there are a number of factors to be taken into account when writing, or judging the quality of, questions:\n\nComplex sentences, technical terms, or double negatives  should be avoided as respondents may not understand the question\nQuestions should be written at an appropriate reading  age level for your respondents\nThere should not be multiple interpretations of the question\nOnly one question should be asked by any one survey item\nThe question should not be constructed to lead to a particular response\nIf there are any questions addressing emotive or sensitive issues, consider whether these items are research questions\n\nAs well as considering how you ask your questions, it is also important to think about your response options. When using scales, consider how many response options you present. Your respondents may find smiley faces or other pictorial options more accessible than a numbered or descriptive scale. Interspersing negatively worded questions can also reduce the effect of ‘response set’ when respondents get used to choosing a particular option. For example, within a scale on computing attitudes, you might include questions that produce the opposite responses.\n\n“I really enjoy debugging code”\n“Debugging code isn’t an enjoyable part of programming”\n\nIf the respondent were to choose ‘disagree’ for question 1, they should choose ‘agree’ for question 2.\nGood questioning in interviews\nThe principles for good questioning are also important when conducting interviews. However, other interpersonal factors also come into play in interview settings which can have a significant effect on the data.\nYou already have a relationship with your learners, which can be a benefit as it may mean that they are more open and honest in their responses. It can also have disadvantages if, for example, you have had less positive experiences with a particular learner.\nIn both cases, there will be a difference in power and authority between you and your interviewee, which may affect their responses. In particular, learners may respond in socially desirable ways, either purposefully to ensure you have a good opinion of them, or unconsciously.\nGiven this relationship, it is really important to show that you are neutral and non-judgemental in the interview. You can do this through your use of language and non-verbal cues. For example, responding to the interviewee by nodding and saying “I see” rather than sitting back in the chair with a puzzled expression could encourage your learners to be more open with their opinions.\nWhere learners give limited responses, you may need try the following to elicit more information:\n\nPrepare some potential prompts that help you gather more information, after a question (e.g. “Could you tell me a little more about that?”)\nReword the question if it seems that the learner has not understood, although avoid reinterpreting what they have told you or leading them to a particular answer\nCircling back to a topic later in the interview can also be beneficial as the interviewee may be more confident in expressing their opinions\nSave more complex or sensitive questions for later in the interview to make sure your learners are comfortable\n\nConclusion\nThe decision concerning whether to use a survey or a questionnaire depends on the research question you aim to address. But it also depends on the time you have available to develop your questions and collect your data. There are many validated surveys readily available to use in your research, and this method allows you to gather a lot of data quite quickly. A survey would be particularly useful if you wanted to collect data from all the learners in your class. If you develop your own semi-structured interview1, you will need to focus on a smaller number of respondents because of the time required to conduct the interview and then to code and analyse the qualitative data gathered. In both cases, the validity of the questions is vital, as is the way in which they are delivered.\nOnline PDF\nReferences\nFootnotes\n\n\nTurner III, D.W. (2010) Qualitative interview design: a practical guide for novice investigators. The Qualitative Report, 15 (3), 754–760.\nMcLeod, S. A. (2014) The interview research method. Available from: www.simplypsychology.org/interviews.html\nMcLeod, S. A. (2018) Questionnaire: definition, examples, design and types. Available from: www.simplypsychology.org/questionnaires.html ↩\n\n\n","frontmatter":{"title":"Planning effective surveys and interviews for research or evaluation","fileOrder":9,"displayName":"09 - Surveys & Interviews","aliases":["Surveys & Interviews","QR09"],"draft":null}},"QR10":{"slug":"QR10","filePath":"QR10.md","title":"Using observation techniques to record student behaviour for research or evaluation","links":["tags/Key"],"tags":["Key"],"content":"Classroom action research is an effective approach that teachers can use to embed evidence-based pedagogies into their practice. This approach is the subject of the new online course: Improving Computing Classroom Practice Through Action Research.\nTo understand behaviour and how it changes as a result of your action research, you can use different types of observation techniques. The technique chosen will depend on your research question and the type of action you are taking in your research.\n\n\n                  \n                  Summary \n                  \n                \n\n\nSummary\nKey Benefits:\nObservation approaches enable teacher-researchers to record data about the behaviours exhibited by their students\nStructured observations:\n\nInvolve coding and collecting data from live observation or recordings\nInvolve recording the frequency of particular events, or the occurrence of  behaviours within particular time intervals, to capture the prevalence or timing of specific behaviours\nRequire identification of target behaviours before you conduct observations\nEnable quick collection of lots of data, but may exclude the nuances\nDo not require learners to verbalise their thoughts\n\nUnstructured observations:\n\nInvolve reflecting on and recording observations after the lesson\nAre quicker and easier to plan than strucutured observations\nHave the potential to introduce bias into the data\n\nVerbal protocols:\n\nInvolve asking learners to verbalise  their thinking during a task, and recording these verbalisations\nProvide an insight into learners’ thinking through their behaviour (response)\nCause a smaller cognitive load for learners than participating in interviews does\nMay not be suitable for all learners or situations\n\nEach approach has advantages and disadvantages, and may be best applied in combination with other methods, including interviews and surveys.\n\n\n\n\nStructured observation schedules\nYou can collect quantitative data on behaviour by using structured observation schedules, in which you code behaviour either as it happens in a live setting, or from recordings made during lessons. You can do this by coding particular events of interest, such as when learners ask for help, or by coding the different types of behaviour that are exhibited in a particular time interval, such as the first five to ten minutes of a lesson. Examples of how you could set up an observation schedule for event or interval coding are presented in the figure.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroupAsk teacherRefer back to boardExplain concept to each other1IIIIIII2IIIIII3IIII\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime intervalGroupAsk teacherRefer back to boardExplain concept to each otherFirst 5 mins1✓✓Second 5 mins1✓Last 5 mins1✓\nObservation schedules for events (top) and intervals (bottom). For event coding, you may keep a tally of each time a particular behaviour is seen. For interval coding, you may record whether a particular behaviour occurs at different times in the lesson.\nAn advantage of using structured observations is that you can record behaviour that is occurring naturally in your classroom, and it does not rely on learners being able to verbalise their thoughts or feelings. Identifying behaviour to look for in advance of the lesson also reduces any bias that you may have developed based on your previous interactions with learners (the so-called ‘Halo Effect’)12, which could affect your interpretation of learners’ actions as an observer.\nWhile structured observations are likely to be more consistent and reliable than other types of observation, the strict coding of behaviour in this way may exclude elements of the social context and individual variability of the behaviour. For example, simply coding the number of questions asked will not capture the more detailed, and potentially enlightening, data surrounding the types of questions asked: one group may ask questions for clarification, while another group may ask questions to extend their learning, and learners may ask different types of questions at different stages of an activity.\nIt is also difficult to conduct this type of observation while continuing to participate in the lesson as the teacher. You may require additional members of staff or need lessons to be recorded, which could raise ethical issues and make the process longer.\nUnstructured observations\nYou may feel that the structured approach outlined above will not allow you to directly address your research question, but you may still be interested in the behaviour of your learners. As an active participant within your research setting (the classroom), you may wish to record observations retrospectively during breaks or after lessons, and then bring these together later to provide a snapshot of classroom interactions. Using the example of questioning, you could record the changing tone of questions over the course of the lesson, or note down any particular questions that gave you an insight into how your learners were approaching the task.\nIt is important to think about your own role in these interactions. For example, you may have changed the way that you explained something in response to a question, which may have led to learners asking fewer questions. You should also consider the potential biases that you may have when recording your observations, such as whether you may be more likely to remember questions from learners who you know find particular concepts difficult. The fact that your active role in the classroom may affect results does not mean that you should not take this approach, but you should be aware of these issues and discuss them explicitly when sharing your results with others.\nVerbal protocols\nAn indirect form of observation is through the use of verbal protocols. This involves asking learners to ‘think aloud’, i.e. to verbalise what they are thinking, while they carry out a task, and recording these verbalisations (either writing them down or using audio recordings to be transcribed later). This allows you to link their behaviour (in this case, their verbalisations) to their thought processes. This is a different process from interviewing learners about how they solved problems or what they thought about a task, as it requires a much lower cognitive load and awareness of their own thought processes. This might be a particularly useful approach when trying to understand learners’ problem-solving strategies in computing lessons. However, it is important to think about the context of these observations and the impact that this approach might have on some learners, for example, if they are not confident speaking in front of others, or if they have speech and language difficulties and find verbalisation difficult.\nConclusion\nIt is important to weigh up the advantages and disadvantages of the different methods, and to choose the observation technique that is best suited to your research question. Note that observations are useful for understanding and recording behaviour, but that you may need to combine them with interviews or surveys if you also want to understand individual learners’ thoughts and feelings about their experiences. If you plan to use a structured observation schedule, take some time to think carefully about the types of behaviour that you are targeting and how it is best to record them given your role within the classroom. Finally, make sure that you are aware of any ethical issues relating to observing your learners without their knowledge or sharing data from these observations with others.\nOnline PDF\nReferences\nFootnotes\n\n\nNeugaard, B. (2016). Halo effect | psychology. In: Encyclopædia Britannica. [online] Available at: www.britannica.com/science/halo-effect. ↩\n\n\nCoolican, H. (2017) Research Methods and Statistics in Psychology. Sixth edition. Hove, Psychology Press. ↩\n\n\n","frontmatter":{"title":"Using observation techniques to record student behaviour for research or evaluation","fileOrder":10,"displayName":"10 - Observation Techniques","aliases":["observation techniques","QR10"],"draft":null,"tags":["Key"]}},"QR11":{"slug":"QR11","filePath":"QR11.md","title":"Using PRIMM to structure programming lessons","links":[],"tags":[],"content":"PRIMM is an approach that can help teachers structure lessons in programming. PRIMM stands for Predict, Run, Investigate, Modify and Make, representing different stages of a lesson, or series of lessons. PRIMM promotes discussion between learners about how programs work, and the use of starter programs to encourage the reading of code before writing.\n\n\n\n                  \n                  Summary \n                  \n                \n\n\nPRIMM is a way of structuring programming\nlessons that focuses on\n\nReading code before you write code\nWorking collaboratively to talk about programs\nReducing cognitive load by unpacking and understanding what program code is doing\nGradually taking ownership of programs when ready\n\nThe five stages:\nPredict\n\nFocus on the function of the code\nEncourage discussion\nWork in pairs or threes\n\nRun\n\nProvide students with working code to run\nCheck against prediction\n\nInvestigate\n\nUse a variety of activities, for example, tracing, annotating, questioning, etc\nEncourage students to discuss and work in pairs or small groups with the code\n\nModify\n\nModify code in small steps to add new functionality\nApply what has been learnt about the structure of the code\nGradual increase in difficulty\n\nMake\n\nCreate a new program\nPractise the programming skills that have been learnt\nCan be a design or an open task\n\nDoes it work?\n\nA study in 2018 with 500 learners aged  11–14 showed improved learning outcomes  after 8–12 weeks of programming lessons using PRIMM1\nPRIMM has been put into practice by many teachers in primary and secondary schools around the world\n\n\n\n\n\nThe five stages of PRIMM\nPredict: Students discuss a program and predict what it might do; they can draw or write out what they think will be the output. At this level, the focus is on the function of the code.\nRun: Students run the program so that they can test their prediction and discuss in class.\nInvestigate: The teacher provides a range of activities to explore the structure of the code, such as tracing, explaining, annotating, debugging, etc.\nModify: Students edit the program to change its functionality via a sequence of increasingly more challenging exercises; the transfer of ownership moves from the code being ‘not mine’ to ‘partly mine’ as students gain confidence by extending the function of the code.\nMake: Students design a new program that uses the same structures, but solves a new problem (ie has a new function).\nYou may not be able to go through all stages in one lesson and may even focus on one stage more than another. Remembering PRIMM gives you a way of labelling what you are doing when you are teaching programming.\nThe PRIMM approach builds and draws on other research in computing education, including Use-Modify-Create2, tracing and reading code before writing3, the Abstraction Transition Taxonomy,4 and the Block Model5. The focus on language\nand talk, and the use of starter programs, draws on a sociocultural perspective to the way that children learn programming.\nEncouraging talk in the classroom\nClassroom discussion is an important aspect of the teaching of many subjects, but isn’t often referred to with respect to the teaching of programming. Many PRIMM\nactivities are carried out in pairs, and we already know that pair programming is an effective form of learning, and involves learners practising to articulate what to do\nwhen writing a program. PRIMM goes a step further and encourages Predict and Investigate activities to be carried out in pairs/small groups, away from the computer.\nThis has the following benefits:\n\n\nTalking about a program and how to works helps  learners to find the right terminology to use to  articulate their understanding. Having a common language to talk about programming constructs is important.\n\n\nActually verbalising out loud the steps of a program that are difficult to understand can help learners to focus on atomic, or smaller elements at a time.\n\n\nThrough dialogue with others, we can ask and answer questions, and learn from others\n\n\nRead before you write\nThe first activity in a PRIMM-like lesson involves predicting what a small segment of code will do when it runs. It doesn’t require stating how it will do that, just the outcome. This shouldn’t be an assessed exercise, so that all children are encouraged to have a go, and it’s important that it is low stakes. Sometimes the output can be drawn, sometimes the teacher will provide some sample inputs, all depending on what kind of code it is.\nThis aspect of PRIMM builds on decades of research that has shown that reading code before writing it is an effective way to learn programming. For example, work by Lister and colleagues over many years highlighted the importance of reading code and being able to trace what it does before  writing new code. Comparing tracing skills to code writing, they demonstrated that novices require a 50% tracing code accuracy before they can independently write code with confidence6.\n\nNot starting from scratch\nIt can be very stressful for novice programmers to write code into a blank editor window. The syntax needs to be right, or quite intimidating error messages can appear. It’s easy to be put off having a go, or for teachers to resort to getting students to copy code that they don’t yet understand.\nBy running a program that the teacher has written, the learner doesn’t have ownership of that ‘starter’ program and does not have the emotional angst when it doesn’t work. That’s why in PRIMM, the Run stage involves running a program provided on a shared drive to check the prediction. Gradually, once the student has some understanding of how the code works, they can modify the code and take ownership of the new functionality.\nDrawing on sociocultural theory\nSocial constructivism, in particular the work of the psychologist Vygotsky, can frame our understanding of novice programmers and their learning. This interpretation\nof the learning process can help us to develop effective pedagogical strategies.\nVygotsky proposed that mediated activity promotes higher mental processes, and identified three major forms of mediation: material tools, psychological tools (including language), and interaction with other human beings. Mediation allows learners to act as apprentices before internalising new ideas, and sociocultural theory (SCT) suggests that movement from the ‘social plane’ to the ‘cognitive plane’ supports the learning of skills and knowledge. With the PRIMM approach, the ‘starter\nprograms’ that are shared and discussed can be seen as being on the social plane, with a mediated progression to the cognitive plane once understood and internalised¹.\nOnline PDF\nReferences\nFootnotes\n\n\nSentance, S., Waite, J., &amp; Kallia, M. (2019) Teaching computer programming with PRIMM: a sociocultural perspective. Computer Science Education. 29 (2–3), 136–176. DOI: 10.1080/08993408.2019.1608781.85. ↩\n\n\nLee, I., Martin, F., Denner, J., Coulter, B., Allan, W., Erickson, J., Malyn-Smith, J. &amp; Werner, L. (2011) Computational thinking for youth in practice. ACM Inroads. 2(1), 32–37. ↩\n\n\nLister, R., Adams, E. S., Fitzgerald, S., Fone, W., Hamer, J., Lindholm, M., McCartney, R., Moström, J. E., Sanders, K., Seppälä, O., Simon, B. &amp; Thomas, L. (2004) A multi-national study of reading and tracing skills in novice programmers. ACM SIGCSE Bulletin. 36(4), 119–150. ↩\n\n\nCutts, Q., Esper, S., Fecho, M., Foster, S. R. &amp; Simon, B. (2012) The Abstraction Transition Taxonomy: Developing desired learning outcomes through the lens of situated cognition. In: Proceedings of the Ninth Annual International Conference on International Computing Education Research. New York, ACM. pp. 63–70. ↩\n\n\nSchulte, C. (2008) Block Model: An Educational Model of Program Comprehension as a Tool for a Scholarly Approach to Teaching. In: Proceedings of the Fourth International Workshop on Computing Education Research. New York, ACM. pp. 149–160. ↩\n\n\nVenables, A., Tan, G. &amp; Lister, R. (2009) A closer look at tracing, explaining and code writing skills in the novice programmer. In: Proceedings of the Fifth International Workshop on Computing Education Research. New York, ACM. pp. 117–128. ↩\n\n\n","frontmatter":{"title":"Using PRIMM to structure programming lessons","fileOrder":11,"displayName":"11 - PRIMM","aliases":["PRIMM","QR11"],"draft":null}},"QR12":{"slug":"QR12","filePath":"QR12.md","title":"Understanding program comprehension using the Block Model","links":[],"tags":[],"content":"In recent years, program comprehension has been recognised as an  important step in learning to program. It is a step that is easily missed as learners dive straight into writing programs before they have learnt to read them. What exactly is program comprehension, why is it so important, and how can educators develop these skills with their learners?\n\n\n\n                  \n                  Summary \n                  \n                \n\n\nLearning programming has several challenges:\n\nIt is concept-rich, leading to cognitive overload\nIt balances comprehension with coding experience\nIt demands persistence and resilience Learners need a secure mental model of computation\n\nProgram comprehension:\n\nIt allows learners to interpret, explain, adapt, debug, and create programs It supports learners to develop programming patterns or plans\nIt can be divided into 12 ‘zones’ using the Block Model\nLearners should develop knowledge in each zone and be able to move between them\n\n** Comprehension tasks:**\n\nEducators can use this Block Model to categorise tasks and identify gaps where students need support\nA range of strategies already exist that have been mapped to the Block Model\n\n\n\n\nWhy do students find programming challenging?\nAlthough programming is a valuable and rewarding skills to learn, many learners find the process challenging:\n\nEven simple programs are rich in concepts that can cause cognitive overload in learners\nLearners may rush to write programs too soon, before they have read and understood the relevant concepts Programs often don’t work first time, requiring persistence from learners\nLearners need to switch between different abstractions, the problem, the program text, and its execution, consistently moving from single lines to the program as a whole\nLearners also need a mental model or notional machine for how the computer works and will execute the program\n\nThese challenges do not mean that programming is intrinsically difficult, and recognition of these challenges can help educators identify where they can support their learners.\nProgram comprehension\nExperienced programmers demonstrate a high degree of program comprehension. As well as having a robust notional machine, they can develop programming ‘plans’ (chunks of code that perform a specific task), based on common features in programs that they have seen. They can then use these plans or patterns to interpret, explain, adapt, debug, and create programs.\nNovice programmers know of very few (if any) programming plans, and have limited awareness of how programs are executed (notional machine). Their focus may be limited to decoding individual words in a program, rather than comprehending their meaning or the meaning of the wider program. As educators we need to understand how to bridge this gap.\nComprehension tasks\nThere are already many great examples of activities that promote program comprehension, including tracing, Parson’s Problems, PRIMM, and tasks in which learners ‘explain the purpose’. A teacher-focused study1 identified more than 60 different activities that could support learners in developing program comprehension skills. It also highlighted that many of these activities were already used, to assess program comprehension, rather than support its development.\nAs program comprehension is quite broad and there are a number of activities to choose from, it can be difficult for educators to know which activities to use in which circumstances.\nThe Block Model\nA useful tool for understanding and categorising aspects of program comprehension is the Block Model 2.  This framework captures captures what level the learner is focused on:\n\nAtoms, the smallest element, are the keybords, symbols, and syntax, or a single line of code\nBlocks are small chunks of code that perform a task, eg single lines, loops, selection statements, or functions\nRelationships are the connections between blocks, and the manner in which they work together, such as function calls and return values\nMacro structure refers to the program as a whole\n\nThe framework also considers the ‘dimension’ of the program, or how the learner is viewing it:\n\n\nThe program exists as a static piece of text. This is called the text surface and is where learners need to consider the grammar and syntax of their program.\n\n\nWhen the program is executed, it becomes a dynamic object that may behave differently depending on its inputs. This dimension is known as the program execution.\n\n\nA function solely concerns the purpose of the program or code snippet.\n\n\nThe Block Model therefore comprises 12 zones of program comprehension that learners should be able to move between as they develop their understanding. The related ‘holey quilt’ theory3 suggests that learners begin with varying levels of knowledge in each zone, ranging from fragile to deep. Knowledge is deepened over time and can be supported by learning activities targeting each zone.\nMapping tasks to the Block Model\nIt is important to devise activities that develop  comprehension in each of these 12 zones, in order to support learners’ full understanding of the program. By considering each of the three dimensions in turn, we can identify tasks that may foster comprehension at each level of focus.\nComprehending the text surface can be tricky, as learners need to discern the meaning from text with unfamiliar terms, structures, and syntax. Without support, they may get stuck focusing on the program at the ‘Atoms’ level. A simple strategy that works at all levels of focus is to identify aspects of the code within the text. By identifying examples of variables, conditions, finite loops, functions, etc, educators can help learners make sense of the text, and connect it to underlying concepts.\nDuring program execution, several approaches could be used to help learners develop their understanding and their mental models. For example, learners could trace simple programs, determining the end state of variables or the inputs required to reach a specific state. Learners could also complete Parson’s Problems, which transcend the text surface and enable learners to focus on the correct sequence of instructions for a specified goal. Similarly, learners could investigate the effect of swapping two lines of code, or try to find lines that can never run. Note that many of these activities are also good examples of the ‘Investigate’ phase of the PRIMM methodology 4.\nLearners can also benefit from exploring function. Asking learners to explain the function of a line, snippet, or entire program is a great place to start. To do this, they will have to use clues within the text and observe the execution. Educators can vary the degree of challenge by the clues they leave in the programs. Also, educators can connect function back to text by asking learners to provide meaningful names for variables, functions, or entire programs. Alternatively, learners could be given a description of the purpose and identify a program that matches, or compare multiple\nprograms to find which are functionally equivalent.\nThere are lots of options for educators to choose from, but the most important step is to review our own practice, to find and fill those gaps in learners’ program comprehension.\nOnline PDF\nReferences\nFootnotes\n\n\nMaton, Izu, C., Schulte, C., Aggarwal, A., Cutts, Q., Duran, R., Gutica, M., Heinemann, B., Kraemer, E., Lonati, V., Mirolo, C. &amp; Weeda, R. (2019) Program comprehension: Identifying learning trajectories for novice programmers. In: ITiCSE ‘19: Proceedings of the 2019 ACM Conference on Innovation and Technology in Computer Science Education. New York, ACM. pp. 261–262. ↩\n\n\nSchulte, C., Clear, T., Taherkhani, A., Busjahn, T. &amp; Paterson, J. H. (2010) An introduction to program comprehension for computer science educators. In: Clear, A. &amp; Russell Dag, L. (eds.) ITiCSE-WGR ‘10: Proceedings of the 2010 ITiCSE working group reports. New York, ACM. pp. 65–86. ↩\n\n\nClear, T. (2012) The hermeneutics of program comprehension: a ‘holey quilt’ theory. ACM Inroads. 3(2), 6–7. ↩\n\n\nSentance, S. (2020) The I in PRIMM. Hello World. 14, 50–53. ↩\n\n\n","frontmatter":{"title":"Understanding program comprehension using the Block Model","fileOrder":12,"displayName":"12 - Block Model","aliases":["QR12"],"draft":null}},"QR13":{"slug":"QR13","filePath":"QR13.md","title":"Improving program comprehension through Parson’s Problems","links":["QR12"],"tags":[],"content":"An important precursor to learning to write computer programs is having the necessary program comprehension to interpret the function and structure of existing programs. One tool that can help learners develop program comprehension is Parson’s Problems, which are exercises that require learners to rearrange lines of code into the correct sequence.\n\n\n\n                  \n                  Summary \n                  \n                \n\n\nParson’s problems support learners by:\n\nDeveloping learners’ understanding of how the program is executed (notional machine)\nReducing cognitive load\nFocusing on blocks of code rather than syntax\nProviding all the correct code within an engaging challenge\nPromoting dialogue and discussion about code\n\nBenefits of Parson’s Problems:\n\nConstrain the logic\nAvoid common syntax errors that can be barriers to learning to code Model good programming practices Provide the potential for immediate feedback\nMake it easier to identify common misconceptions\nIncrease engagement of learners\n\nAdvice for writing Parson’s Problems:\n\nShare problems with only a single solution\nAllow learners to manipulate actual code blocks\nProvide a clear description of the problem Clearly show the desired logic Share multiple similar problems over time\n\n\n\n\nWhat is a Parson’s Problem?\nA Parson’s Problem is a task in which learners are given all of the blocks or\nlines of code needed to solve a problem, however, the lines have been jumbled\nso that they are no longer in the correct order. Learners are asked to reorganise\nthe code into the correct order to perform a specific task.\nThe short example above shows some jumbled lines of code (in Python and Scratch), and sets out the task that needs to be completed. Why not see if you can solve the problems in the example?\nParson’s Problems can be applied to both text- and block-based programming and can vary in difficulty, to accommodate learners’ existing understanding. For example, when you feel that learners are ready, they could be provided with lines of code and be expected to work out the indentation themselves (known as 2D Parson’s Problems).\nThere are many ways in which Parson’s Problems can be presented to learners. They make for an excellent offline or paper-based activity that could be done individually, in pairs, or in small groups. You may choose to create problems directly in the development environment to allow learners to immediately test their solutions. Alternatively, there are online tools such as js-parsons that allow you to create your own interactive problems.\nParson’s Problems can be used to support formative assessment, as classroom discussion following the activity plays an important part in learners’ development. Immediate feedback also avoids any misconceptions being committed to long-term memory.\nThe benefits of Parson’s Problems\nThe main benefit of Parson’s Problems is that the learner is focusing on the structure and logic of blocks of code, rather than the syntax of individual text elements (atoms). The process reduces the cognitive load experienced by learners, allowing them to practise sequencing and problem-solving with code. This experience is particularly helpful in the early stages of learning to program, when learners may be easily frustrated and put off by repeated unsuccessful attempts to solve a problem. Parson’s Problems also expose learners to logic and syntax that they may not be fully familiar with.\nDenny et al. 1 suggest that learners’ solutions to a Parson’s Problem “make clear what students don’t know (specifically in both syntax and logic)”. These solutions can allow for an easier analysis of the common errors that learners make, whereas “the open-ended nature of code-writing questions makes identifying such errors difficult”. For example, when using a Parson’s Problem, we can be sure that an error was not caused by a typing mistake.\nParson’s Problems can promote some higher-order thinking in learners than simple code tracing (reading code and identifying its purpose or output). Parson’s Problems can act as a stepping stone between the lowest and highest categories — being able to read and interpret code and being able to write original code, which involves evaluation and creation (the highest categories in Bloom’s).\nIzu et al. 2 place Parson’s Problems in the ‘Blocks’ row of the Block Model proposed by Schulte. They state that “novice programmers should develop program comprehension skills as they learn to code so that they are able both to read and reason about code created by others, and to reflect on their code when writing, debugging or extending it”. They also state that Parson’s Problems support learners in developing their understanding of the notional machine.\nDistractors\nSome Parson’s Problems include distractors. Distractors are incorrect blocks or lines of code that are included in the set of provided code, meaning that learners need to be selective about which blocks they use.\nRearrange the lines of code to create a program that outputs the total cost\nto the customer. Be aware that there are two lines of code that will cause\nerrors in your program if used.\n\nThe inclusion of distractors can add an additional level of challenge 3 for more confident learners. However, care should be taken, as they may unnecessarily increase the cognitive load or the time spent on a task, or even result in a misconception or error being committed to long-term memory.\nAdvice for writing Parson’s Problems\nProvide learners with a clear explanation of what the program should do when correctly sequenced — doing so reduces their cognitive load. Additionally, Denny et al. 1 recommend making sure that there is a unique answer for each question, ie there should only be one order of the lines that achieves the goal.\nEnsure that learners manipulate the actual lines of code, rather than using letters or numbers as a shorthand. Working with real lines of code helps to develop their familiarity with the syntax and the construction of the code.\nIn theory, it is possible for learners to guess the correct answer to a simple Parson’s Problem without fully understanding the construct or logic being tested. Asking more than one question over time that tests the same logic or construct can reduce this concern.\nProviding structure (eg braces, colons, indentation) can make a question more accessible, as learners can use these visual clues to develop their solution. Providing this structure can also make problems including more complex programming concepts possible.\nOnline PDF\nReferences\nFootnotes\n\n\nDenny, P., Luxton-Reilly, A. &amp; Simon, B. (2008) Evaluating a New Exam Question: Parsons Problems. In: ICER ‘08: Proceedings of the Fourth International Workshop on Computing Education Research. New York, ACM. pp. 113–124. ↩ ↩2\n\n\nIzu, C., Schulte, C., Aggarwal, A., Cutts, Q., Duran, R., Gutica, M., Heinemann, B., Kraemer, E., Lonati, V., Mirolo, C. &amp; Weeda, R. (2019) Fostering Program Comprehension in Novice Programmers - Learning Activities and Learning Trajectories. In: ITiCSE-WGR ‘19: Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education. New York, ACM. pp. 27–52. ↩\n\n\nHarms, K. J., Chen, J. &amp; Kelleher, C. L. (2016) Distractors in Parsons Problems Decrease Learning Efficiency for Young Novice Programmers. In: ICER ‘16: Proceedings of the 2016 ACM Conference on International Computing Education Research. New York, ACM. pp. 241–250. ↩\n\n\n","frontmatter":{"title":"Improving program comprehension through Parson’s Problems","fileOrder":13,"displayName":"13 - Parson's Problems","aliases":["QR13"],"draft":null}},"QR14":{"slug":"QR14","filePath":"QR14.md","title":"Code tracing","links":["QR12"],"tags":[],"content":"Developed in the early 2000s, code tracing is a well-established approach to help learners develop their program comprehension. Put simply, it involves reading and analysing code, before running it to predict its outcome. Novice programmers should be competent in code tracing before they can confidently write programs of their own.\n\n\n\n                  \n                  Summary \n                  \n                \n\n\nTracing involves:\n\nReading the code\nInterpreting the meaning\nRecording the flow and/or outputs\n\nBenefits of tracing:\n\nFosters program comprehension\nImproves code writing\nSupports learners to be able to analyse and explain code\nExposes misconceptions\nReduces cognitive load\nHelps learners develop a consistent notional machine\n\n\n\n\n\nWhat is code tracing?\nIt is widely understood that young learners should ideally have developed some reading skills before they begin learning to write. Similarly, in computing, there is a body of evidence to suggest that code tracing, a form of code reading, is an effective precursor to code writing and independent programming.\nWhen tracing code, learners review chunks of code, or whole programs, and record its expected behaviour and execution flow at various stages. This can be captured through annotation as well as recording the program output at each stage. The Teach Computing Curriculum ‘Programming’ units include examples of code tracing tasks. Learners may be asked to trace a piece of code, predict the outcome, and then be guided through the code, line by line to test their prediction. Typically, prediction is done away from the computer to ensure learners focus on reading rather than executing the code. Learners could also be given short sections of code in the form of worked examples, or complete trace tables, where some values are provided and learners use code tracing to record the missing values. With this secure understanding, learners can then be given the opportunity to create their own program featuring the concepts they have traced. While there is no single approach to tracing, there are some clearly defined methods such as TRACS1 which may be useful for learners to follow.\nHere, we explore the benefits of code tracing, how it fits in with the concept of the notional machine, strategies to employ to lighten cognitive load, and how code tracing can be used in the classroom.\nThe benefits of code tracing\nHarrington identified that when learning programming, learners build their understanding in a hierarchical way, with tracing at the most basic level, then explaining the code, before they progress on to writing. Many other studies have been completed based on this theory. Hertz and Jump, who developed the ‘trace-based-teaching’ model, found that starting a class with 20 to 30 minutes of tracing increased attainment and decreased drop-out rates2. A 2004 study found that learners who could trace effectively less than 50% of the time could also not explain it effectively3. If we accept there is a broad consensus advocating code tracing as an effective strategy with a broad range of evidence to support the claim, what should we consider when using it in the classroom?\nThe notional machine\nTo trace code effectively, learners must have some understanding of the notional machine. This concept was first introduced by Benedict du Boulay and describes the conceptual model that learners have about how a computer processes instructions and data 4.\nThe notional machine can look very different depending on the type of programming language being used. In Scratch, it is simple to run more than one process concurrently (threading), whereas in most text-based languages (including Python) this is more complex. This has implications for how we begin to teach programming in Scratch. Learners may demonstrate that they can use threads but may not understand how the machine handles them. This gap in their notional machine understanding can lead to gaps in their knowledge or to misconceptions.  Encouraging learners to use threads in Scratch without addressing the notional machine may lead to later problems for teachers when learners find threading more difficult to achieve in Python.\nLightening the load\nCode tracing can contribute to a reduction of the cognitive load placed on learners.\nIn focusing learners’ efforts on existing and working programs, and answering specific questions, educators can avoid unnecessary extraneous load being placed on their learners. By giving learners the opportunity to trace code, they can comprehend the code and its function before they see it in action. This approach also helps develop their understanding of the notional machine — how the code is executed. Many other areas of the curriculum explore similar ideas, such as Talk for Writing in literacy and progressing from concrete objects to abstract\nnumerals in mathematics.\nIn context application\nCode tracing can be incorporated in the classroom as a stand-alone activity or as part of a wider approach.\n\nThe PRIMM (Predict, Run, Investigate, Modify, Make)5 approach is ideally suited to it as it required learners to Predict in its first step, which involves reading and tracing. - Begin a programming activity or project by providing learners with an existing project or snippet of code.\nTracing is also a good way to check learners’ understanding of the capabilities of the notional machine. Using examples where specific misconceptions may lead to an incorrect solution, the act of tracing can expose and help address this misconception.\n\nThis Pedagogy Quick Read was adapted from Paul Curzon’s blog, which is based on the work of Karl Maton applied to a computing context. We would like to thank them both for their input.\nOnline PDF\nReferences\nFootnotes\n\n\nDonaldson, P. and Cutts, Q., 2018, October. Flexible low-cost activities to develop novice code comprehension skills in schools. In Proceedings of the 13th Workshop in Primary and Secondary Computing Education (pp. 1-4). ↩\n\n\nHertz, M. and Jump, M., 2013, March. Trace-based teaching in early programming courses. In Proceeding of the 44th ACM Technical Symposium on Computer Science Education (pp. 561-566). ↩\n\n\nLister, R., Adams, E.S., Fitzgerald, S., Fone, W., Hamer, J., Lindholm, M., McCartney, R., Moström, J.E., Sanders, K., Seppälä, O. and Simon, B., 2004. A multi-national study of reading and tracing skills in novice programmers. ACM SIGCSE Bulletin, 36(4), pp. 119-150. ↩\n\n\nDu Boulay, B., 1986. Some difficulties of learning to program. Journal of Educational Computing Research, 2(1), pp. 57-73. ↩\n\n\nRaspberry Pi Foundation, * Pedagogy Quick Reads: Using PRIMM to structure programming lessons *. Available from: the-cc.io/qr11 ↩\n\n\n","frontmatter":{"title":"Code tracing","fileOrder":14,"displayName":"14 - Code Tracing","aliases":["QR14"],"draft":null}},"QR17":{"slug":"QR17","filePath":"QR17.md","title":"Variety in teaching and assessment of programming activities","links":[],"tags":[],"content":"Computing is a broad discipline with deep roots in engineering, mathematics, and science, as well as applications and connections to many other subjects. Appreciating these varied perspectives and the variety of teaching approaches and assessment strategies available allows educators to tailor their teaching to suit their learners’ experiences, needs, and the subject matter in question.\n\n\n                  \n                  Summary \n                  \n                \n\n\nPerspectives on computing:\nComputing is a broad discipline rooted in three main traditions:\n\nComputing as engineering is concerned with design and development\nMaths is integral to computing systems, software, and how we describe them\nMost scientific fields apply computing to model and explore the physical world\n\nClassroom strategies:\nA holistic approach to teaching computing reflects each of these perspectives, their priorities, and practices:\n\nAn engineering perspective leads to more project-based learning with scaffolding to support individual learners\nA maths perspective focuses on acquisition and construction of knowledge, using representations to explore abstract concepts, and regular recall and practice\nof facts and processes\nA science perspective leads to a more inquiry-based approach where explanations, demonstrations, and practical activities develop learners’ understanding and they predict and experiment\n\n\n\n\n\nComputing as a broad discipline\nAccording to the work of Tedre,1computing is a broad discipline built principally on three traditions, each bringing its own perspectives. Those involved in the field of computing tend to see it as being concerned with either engineering and design, as a branch of mathematics and logic, or as a science. Each tradition has a different focus, prioritises different knowledge and skills, and invites different teaching approaches. However, all form part of computing as a whole:\n\nComputing is engineering: This view prioritises the design and development of artefacts including software and systems. It incorporates user research, prototyping, testing, and evaluation.\nComputing is maths: Logic and mathematics are present throughout computing. Our software and systems are built on mathematical principles and we use mathematical techniques to describe and reason about programs.\nComputing is science: Computing is pervasive across almost every field of science. We use computers to explore and model the physical world, and to make predictions and discoveries.\n\nBeyond these three traditions, computing is connected to other areas such as the arts, where computing is applied as a medium, or philosophy and ethics where the application of computing provides rich materials for discussion.\nDepending on our experience, we’re each likely to favour one or more of these perspectives, which may impact how we present computing to our learners. By understanding these traditions\nand the wider connections, educators can provide their learners with a complete and holistic experience of computing. This enables them to provide a variety of meaningful entry points to the discipline supported by appropriate pedagogy.\nExpanding your strategies toolkit\nTo expand the range of strategies you are able to employ in the classroom, reflect on your perspective of computing. Does your perspective impact the approaches you favour? What new practices could you try that could increase entry points for your students and enhance their experience? How else could you capture and assess your learners’ understanding?\nVariety within teaching approaches\nWhether during a single lesson or an entire course, computing educators need to be able to apply a variety of pedagogical strategies. These will vary depending on the subject matter, the\nlearners, and the aims of each learning experience.\n\n\nMaths concerns understanding, applying, and connecting abstract concepts. The same is true for areas of computing with links to maths, where learners need to understand abstract\n\n\nconcepts, recall facts, and practise calculations and processes. In these situations, educators adopt approaches that focus on the acquisition and construction of understanding. For example:\n\n\nRepresentation is a key part of a mastery approach to maths, which uses different modes of representation, including physical objects, pictorial representations, and eventually symbols and language. This approach may be a successful way to teach learners about binary number systems, for example.\n\n\nVaried and regular recall of concepts and processes is used to secure existing understanding, challenge misconceptions, and form connections and develop a coherent understanding.\n\n\nEngineering concerns making an artefact that solves a problem or addresses a user need and can link computing to other areas of the curriculum. In computing, an artefact could be a program, system, or digital media. Physical computing, in particular, is an obvious way to learn about computing through an engineering lens. For example:\nProject-based learning is closely associated with this  perspective. Learners apply their prior knowledge to a problem, focusing on one or more aspects of the design process.\nSpecifically when programming, you can adjust the scaffolding  and support you provide to learners depending on their needs and your focus.2\nA science-based view of computing involves more inquiry-based practices where  understanding is constructed through prediction, exploration, and observation. Simulations, practical demonstrations, and experiments are also used to develop skills and understanding. 3For example:\n\n\nLearners develop their inquiry skills when programming with the PRIMM methodology; they predict and validate their predictions, as well as investigating and asking questions of the code.\n\n\nTopics like computer systems or networks 4 contain plenty of substantive ideas or facts that can be explored through a combination of explanation, demonstration, or experimentation. Educators have to select the best balance of approaches to suit each new concept and their learners’ needs.\n\n\nAnother lens through which to understand computing is its role in society and the ethical and personal implications of the use of technology. Offering learners the opportunity to discuss ideas and engage in meaningful classroom talk, whether with the teacher or their peers, can support a rich understanding of concepts.5\nDiscussion and debate are particularly relevant to computing as the reach and impact of technology is fertile ground for legal, moral, and ethical discussions. The social and cultural\nconnections educators draw upon have an impact on how learners engage with a topic. Rooting your practice in the lived experiences, cultural knowledge, and background of your students makes their learning more relevant and accessible.\nVariety within assessment\nThere is still much work needed to create reliable assessment approaches for all teachers and for all students. However, there is general agreement amongst researchers that using a variety of assessment approaches helps give teachers a much better picture — a holistic view\n— of student progress.\nClassroom talk is an important assessment tool, providing teachers with an opportunity to assess student understanding in depth and provide feedback. Using design scenarios where students can discuss and adapt example programs highlights their skills as well as knowledge. Code reviews and showcases for students to talk about their work can6 provide peer and teacher\nassessment opportunities.\nIncorporating assessment activities into lessons embeds assessment. For example, portfolio creation and analysis or reflection journals, which require students to answer key questions during project development, encourage continuous self-assessment. Using entry and exit tickets, where students quickly record knowledge or confidence about current learning topics before and after lessons, can be a quick and regular assessment approach.\nMore traditional assessment tasks, such as multiple-choice questions (MCQs) and free-text questions, provide formative and summative assessment opportunities[^7]. Although effective MCQs can be challenging to create and offer limited feedback, they can be a quick and low effort way to discover student understanding.\nOnline PDF\nReferences\nFootnotes\n\n\nPapert, Tedre, M., (2014). The science of computing: shaping a discipline. CRC Press. ↩\n\n\nWaite, J., Liebe, C., (2021, March). Computer Science Student-Centered Instructional Continuum. In Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, online (p. 1246). Association for Computing Machinery. ↩\n\n\nGOV.UK (2021). Research review series: science. [online] Available at: www.gov.uk/government/publications/research-review-series-science/research-review-series-science#practical-work [Accessed 23 August 2021]. ↩\n\n\nNational Centre for Computing Education (2021). Computer Systems and Networking Within the Computing Curriculum. Teaching and Learning Reports. [online] Available at: blog.teachcomputing.org/computer-systems-and-networking-within-the-computing-curriculum/ [Accessed 24 August 2021]. ↩\n\n\nSentance, S., Waite, J. (2021, August). Teachers’ Perspectives on Talk in the Programming Classroom: Language as a Mediator. In Proceedings of the 17th ACM Conference on International Computing Education Research, online (pp. 266–280). Association for Computing Machinery. ↩\n\n\nGrover, S., Sedgwick, V., Powers, K. (2020). Feedback through formative check-ins. In S. Grover (Ed.), Computer Science in K-12: An A to Z Handbook on Teaching Programming. Edfinity. ↩\n\n\n","frontmatter":{"title":"Variety in teaching and assessment of programming activities","fileOrder":17,"displayName":"17 - Variety in teaching","aliases":["Variety","Variety in teaching","Add variety","QR17"],"draft":null}},"QR18":{"slug":"QR18","filePath":"QR18.md","title":"Teaching computing through culturally relevant pedagogy can engage more diverse groups of students and support learning","links":[],"tags":[],"content":"For computing to be relevant, engaging, and accessible to all, educators should reflect on their curriculum, materials, and teaching practices. Educators can draw on the breadth of students’ experiences and cultural knowledge, facilitate projects that have personal meaning for learners, and discuss issues of bias and social justice.\n\n\n                  \n                  Summary \n                  \n                \n\n\nCulturally relevant pedagogy emphasises valuing all learners’:\n\nKnowledge\nHeritage\nWays of learning\n\nCulturally responsive teaching includes:\n\nOpportunities for personally meaningful projects\nCurricula that draw on learners’ cultural knowledge and experience\nExploration of ethics, social justice, and bias\n\nBenefits of culturally responsive teaching are that it:\n\nImproves learners’ attitudes towards the subject\nEncourages more learners to continue with computer science\nImproves understanding of core concepts\n\n\n\n\n\nWhat is culturally relevant pedagogy?\nCulturally relevant pedagogy[^1] is a teaching framework that emphasises the importance of incorporating and valuing all learners’ knowledge, ways of learning, and heritage. It lets learners address issues that are important to them and discuss ethics, power, privilege, and social justice.\nCulturally responsive teaching1 builds on this framework to identify teaching practices for the classroom. These include:\n\nDrawing on learners’ cultural knowledge and experiences to inform the curriculum\nAllowing learners to choose personally meaningful projects and to express their own cultural identities\nExploring issues of social justice and bias\n\nIt’s important when using the term ‘culture’ not to focus on only one characteristic, a person’s cultural identity is based on a range of influences, including their age, gender, where they live, their family income, and their religious beliefs. Making computing responsive to different elements of learners’ cultural identities — including youth culture, a key influence on learners’ interests and attitudes — will engage a wider range of learners.\nIn computing, taking this approach has been demonstrated to:\n\nImprove learners’ attitudes towards the subject, including engagement, confidence, and feelings of belonging23\nEncourage more learners to select computer science as a qualification2\nLead to learning gains in computational thinking and core computing concepts45\n\nProviding authentic and meaningful contexts for learning computing and identifying different applications of computer science outside of school can help more learners see the relevance of computing to their lives and their communities.\nHow do you implement culturally relevant pedagogy in the computing classroom?\nThe Raspberry Pi Foundation’s ‘Culturally relevant and responsive computing in the classroom: A guide for curriculum design and teaching’ identifies three main focus areas: curriculum, teaching approaches, and learning materials. The guidelines provide practical suggestions and links to resources that will help you develop your culturally relevant approach. Some key elements are outlined below:\nTo keep learners engaged, contextualise computing and make connections with other aspects of learners’ lives by including the social, historical, or political context of a particular development in technology or making cross-curricular links to other subjects, or to specific times in the school calendar (e.g. Black History Month, Internet Safety Day).\nAllow student choice in projects as this can encourage them to persist when facing difficulties. Provide tasks that are open-ended, inquiry-led, and require problem-solving. Promote collaboration and discussion, which allows learners to share expertise and knowledge and challenges stereotypes about computing as a career.\nEnsuring your learning materials are accessible and providing inclusive representations of people, places, and cultures is important for engaging and inspiring learners. E.g. using and translating video captions can support those with English as an additional language or avoiding computing stereotypes by showing diverse groups of people.\nConsiderations for designing and implementing a culturally relevant computing curriculum\nFor culturally relevant pedagogy to work, teachers must understand and embrace its principles. Adding a few ‘add-on’ activities to regular teaching will not have the same impact as incorporating the approach throughout your lessons. To do this, you may need to reflect on your own cultural identity and how this affects the way you experience the world, and computing as a subject.\nAuditing your current teaching\n\nIt is vital that teachers understand their current teaching and identify areas where changes could be made.\nIt is useful to work on this activity with a team of teachers, where possible. This will bring together different ideas and cultural identities between teachers, and ensure consistency across different classes.\nIt is even better if teachers can work across disciplines to incorporate culturally relevant pedagogy in a cross-curricular way to embed the approach within the school\n\nPreparing for uncomfortable conversations\n\nYou may have to have some uncomfortable conversations with both colleagues and learners as part of the process of uncovering unconscious biases and discussing meaningful, complex topics. It is important to model how to deal with these conversations sensitively.\nIt is vital that learners and teachers are able to speak openly and feel that their opinions and experiences are being heard and valued. This will take time, and opportunities should be built in throughout the curriculum to develop trust in the process.\n\nThe Raspberry Pi Foundation’s guidelines can help you improve your understanding of the approach and its core principles, and links to some suggested professional development resources.\nOnline PDF\nReferences\n[^1:] Ladson-Billings, G. (1995). Toward a theory of culturally relevant pedagogy. American educational Research Journal, 32(3), 465–491.\nFootnotes\n\n\nGay, G. (2000). Culturally responsive teaching: Theory, research, and practice. New York: Teachers College Press. ↩\n\n\nDiSalvo, B., Guzdial, M., Bruckman, A., &amp; McKlin, T. (2014). Saving face while geeking out: Video game testing as a justification for learning computer science. Journal of the Learning Sciences, 23(3), 272–315. ↩ ↩2\n\n\nAshcraft, C., Eger, E.K., &amp; Scott, K.A. (2017). Becoming technosocial change agents: Intersectionality and culturally responsive pedagogies as vital resources for increasing girls’ participation in computing. Anthropology &amp; Education Quarterly, 48(3), 233–251. DOI: 10.1111/aeq.12197 ↩\n\n\nDavis, J., Lachney, M., Zatz, Z., Babbitt, W., &amp; Eglash, R. (2019, February). A cultural computing curriculum. In Proceedings of the 50th ACM Technical Symposium on Computer Science Education, online (pp.1171–1175). Association for Computing Machinery. ↩\n\n\nMcGee, S., McGee-Tekula, R., Duck, J., McGee, C., Dettori, L., Greenberg, R. I., Snow, E., Rutstein, et al. (2018). Equal outcomes 4 all: A study of student learning in ECS. In Proceedings of the 49th ACM Technical Symposium on Computer Science Education, online (pp.50–55). Association for Computing Machinery. ↩\n\n\n","frontmatter":{"title":"Teaching computing through culturally relevant pedagogy can engage more diverse groups of students and support learning","fileOrder":18,"displayName":"18 - Culturally Relevant Pedagogy","aliases":["Culturally Relevant Pedagogy","CRP","QR18"],"draft":null}},"QR19":{"slug":"QR19","filePath":"QR19.md","title":"Addressing learners’ alternate conceptions in computing","links":["QR07"],"tags":[],"content":"Alternate conceptions (often referred to as misconceptions) are learners’\nbeliefs about a concept that are overly simplified or inaccurate. When\nthese beliefs contradict with reality or accepted scientific understanding,\nthey can cause confusion for learners and affect their understanding and\nperformance.1\n\n\n                  \n                  Summary \n                  \n                \n\n\nAlternate conceptions can develop when new knowledge conflicts with a learner’s existing mental models.\nAlternate conceptions can be categorised as:\n\nPreconceived notions.\nNon-scientific beliefs.\nConceptual misunderstandings.\nVernacular misconceptions.\nFactual misconceptions.\n\nTo become familiar with commonly occurring misconceptions, educators should:\nReview existing research into alternate conceptions in computing.\n\nReflect on their own experience.\nShare common alternate conceptions among peers and within the community.\n\nEducators can identify alternate conceptions through:\n\nVaried opportunities for classroom talk.\nMultiple choice questions.\n\nEffective ways to address alternate conceptions include:\n\nConstructing individual or group concept maps.\nReaching consensus around a concept using peer instruction.\n\n\n\n\nAlternate conceptions in computing\nWe suspect there are a number of alternate conceptions around computing, though there is currently only limited research in this area. However, there is some research specifically related to programming, where a number of common alternate conceptions have been identified.\nWe have looked at research into alternate conceptions in other subjects that form the traditions that underpin computing, in particular maths, science, and engineering.\nSome psychologists claim that alternate conceptions can be very persistent2. In presenting learners with accurate conceptions that challenge their existing understanding, a state of “cognitive disequilibrium”3 is reached where learners must reconcile the conflicting information. While this creates an opportunity to replace an alternate conception, learners may choose to discard information that doesn’t fit their existing mental models, regardless of its accuracy. It is important for educators to be aware of common alternate conceptions that their learners may pass through. Educators should develop a range of strategies to support learners through their alternate conceptions and to encourage them without labelling learners’ understanding as ‘wrong’.\n\nOrigins of alternate conceptions\nAccording to Piaget3, learners build new understanding by combining experience with existing mental models. An alternate conception can arise when learners’ experiences\nand existing mental models interact.\nResearch4 from science education proposes five categories of alternate conceptions:\n\n\nPreconceived notions involve learners making intuitive conceptual leaps based on their everyday experience.  They use their pre-existing experience to fill in the gaps in their understanding. For example, learners who are used to programming in Scratch, may  expect a text based language to handle concurrency for them.\n\n\nNon-scientific beliefs can arise when learners’ mental models have been informed by non-authoritative sources. These beliefs are counter to accepted science. An example from programming is the superbug,5 a belief that a computer possesses innate intelligence, which can cause the learner to have unrealistic expectations of the machine.\n\n\nConceptual misunderstandings occur when the instruction learners experience is insufficient in its depth. The experience fails to challenge existing mental models and confront conflicts, leaving learners to resolve them independently. In computing, we regularly use analogies to unpack and explain abstract concepts. Learners may only develop a surface understanding unless educators spend time distinguishing between the concept and analogy (see our Quick Read about semantic waves).\n\n\nVernacular misconceptions occur when terminology and symbols have multiple meanings. This causes new knowledge to conflict with existing mental models. Computing shares many terms and symbols with mathematics, for example, variables, graphs, etc.\n\n\nFactual misconceptions derive from false facts or information that have been assimilated into memory without being challenged. In science, an example is the idiom “lightning never strikes the same place twice” which may be believed despite being false. A similar example in computing is the common belief that “Apple Mac computers are immune to viruses”.\n\n\nHow to identify alternate conceptions\nThe first step in minimising alternate conceptions is identification. Before teaching new material, educators should reflect on alternate conceptions in computing that their learners might develop. They could review existing research into common alternate conceptions. For computing, this is largely limited to programming67 here are some examples:\n\nA variable can store multiple values; it may store the history of values assigned.\nBoth then and else branches (in a selection statement) are always executed.\n\nFor alternate conceptions in other areas of computing, educators should reflect on the alternate conceptions they have seen occur in computing lessons, sharing these and learning with their peers. Computing educator communities are great places to discuss alternate conceptions, along with blogs, books,8 and other publications. Examples taken from other areas of computing\ninclude:\n\n\nThe internet and the World Wide Web are the same thing, rather than being a network and an example of a service that runs on that network.\n\n\nBinary numbers can only represent numbers up to 255 in denary.\n\n\nBeyond awareness of potential alternate conceptions, educators also need strategies to spot them as they occur. There are a number of techniques that can be used to help identify alternate conceptions (but aren’t limited to):\n\nClassroom talk and discussion. Both are useful methods to reveal alternate conceptions.\nCarefully designed multiple choice questions (MCQs). MCQs can probe learners’ understanding and emphasise alternate conceptions\n\nHow to challenge alternate conceptions\nMany alternate conceptions, particularly vernacular and factual misconceptions, can be addressed during instruction. However, others require more work as the learner already holds a model, albeit flawed, which they may be reluctant to replace. To address these persistent alternate conceptions, learners need the opportunity to construct (or reconstruct) an accurate model. Educators can provide this opportunity by:\n\nConstructing concept maps to help externalise learners’ understanding and emphasise their alternate conceptions so that an accurate model is adopted.\nUsing peer instruction to let learners explore and challenge their own mental models.\n\nIn approaching alternate conceptions, there is no singular approach that will work for all learners, all of the time. However, educators who are able to identify their learners’ common alternate conceptions are better equipped to support their learners’ understanding,9 development, and confidence.\nOnline PDF\nReferences\nFootnotes\n\n\nKallia, M. &amp; Sentance, S. (2019, February) Learning to use functions: The relationship between misconceptions and self-efficacy. In Proceedings of the 50th ACM technical symposium on computer science education (pp. 752–758). ↩\n\n\nEggen, P. &amp; Kauchak, D. (2001) Educational Psychology: Windows on Classrooms. 8th. Upper Saddle River, NJ: Pearson. ↩\n\n\nMcLeod, S. (2018) Jean Piaget’s theory of cognitive development. Simply Psychology, pp.1-9. ↩ ↩2\n\n\nDavis, B. G. (1997) Misconceptions as barriers to understanding science. In Science teaching reconsidered: A handbook. Washington, DC: National Academy, 27–32. ↩\n\n\nPea, R. D. (1986) Language-independent conceptual “bugs” in novice programming. Journal of educational computing research, 2(1), 25–36. ↩\n\n\nSorva, J. (2018) Misconceptions and the beginner programmer. Computer science education: Perspectives on teaching and learning in school, 171. ↩\n\n\nSwidan, A., Hermans, F. &amp; Smit, M. (2018, August) Programming misconceptions for school students. In Proceedings of the 2018 ACM Conference on International Computing Education Research (pp. 151–159). ↩\n\n\nHarrison, A., 2021. How to Teach Computer Science. Melton, Suffolk, UNITED KINGDOM: John Catt Educational, Limited. ↩\n\n\nSadler, P. M., Sonnert, G., Coyle, H. P., Cook-Smith, N. &amp; Miller, J. L. (2013) The influence of teachers’ knowledge on student learning in middle school physical science classrooms. American Educational Research Journal, 50(5), 1020–1049. ↩\n\n\n","frontmatter":{"title":"Addressing learners’ alternate conceptions in computing","fileOrder":19,"displayName":"19 - Alternate Conceptions","aliases":["Alternate Conceptions","Misconceptions","QR19"],"draft":null}},"Quick-Reads/QR21":{"slug":"Quick-Reads/QR21","filePath":"Quick Reads/QR21.md","title":"Computational Thinking 2.0","links":["Quick-Reads/the-cc.io/qr21_1","Quick-Reads/the-cc.io/qr21_2","Quick-Reads/the-cc.io/qr21_3"],"tags":[],"content":"Computational Thinking (CT) has become a cornerstone of computing education. CT2.0 has recently been introduced by Matti Tedre and his team1 to help learners distinguish between traditional rule-based approaches (CT1.0) to problem solving, and the data-driven approaches (CT2.0) used by AI systems. As systems increasingly include both rule-based and data-driven elements, it is essential for learners to understand the differences and to be able to work with both paradigms.\n\n\n                  \n                  Summary \n                  \n                \n\n\nKey concepts\nProblem solving\n\nCT1.0 applies rules-based approaches to problem solving, like those used in Scratch and Python.\nCT2.0 presents a shift towards a data-driven approach to problem solving.\nModel evaluation, data quality, and bias become important in CT2.0, as flawed data can lead to unfair outcomes.\n\nCorrectness\n\nCT1.0 typically teaches correctness as binary, where programs do or don’t produce correct outcomes.\nCT2.0 measures correctness by degree, where ML models generate predictions and levels of confidence.\n\nDebugging\n\nIn CT1.0, debugging is structured and transparent. Errors are addressed by tracking the program execution step by step.\nIn CT2.0, ML models are opaque black boxes. Problems are found through analyses of the input and output data.\nThis requires a shift in the debugging mindset, focusing on improving training data, tuning parameters, and testing with a diverse range of data.\n\n\n\n\n\n\nProblem solving\nCT is a framework for understanding problem solving using computation. Traditional CT1.0 emerged from early computing concepts, using a rulebased approach where computer programs follow precise instructions: with a well-defined input, instructions are followed step by step to produce a predictable output. When teaching with CT1.0, learners learn to break down the task into subtasks and write clear instructions for each step before implementing these instructions in tools like Scratch and languages like Python. In contrast, problem solving in CT2.0 shifts to a data-driven approach¹. Rather than writing explicit instructions, learners learn to collect, clean, label, and organise large amounts of relevant data. Learners then use this data to train machine learning (ML) systems to identify patterns and produce models that generate predictions and solve problems. For example, in CT1.0, learners could create a tool that classifies cats using If…Then rules about whiskers and pointy ears. However, in CT2.0, they would use many images of cats to train a model with sufficient accuracy. Because data is central to this process, data quality, evaluation, and bias become critical concepts: flawed or biased datasets can lead to unreliable or unfair outcomes. Modern applications combine both rulebased and data-driven approaches — from AI-generated text and images, to face recognition software and social media recommendations. Understanding both CT1.0 and CT2.0 empowers learners not only to work effectively with these tools, but also to be active participants and creators rather than passive consumers in our increasingly data-driven societies2.\nUnderstanding correctness\nCorrectness is an important concept in computing and determines whether a program functions as intended. In CT1.0, we often teach learners that correctness involves a program being either correct or incorrect. This approach emphasises precision, where instructions must be syntactically correct, written logically, and produce the expected outcome. Rule-based programs characterised by CT1.0 assume a high level of transparency: every instruction is explicitly written and can be traced back, errors can be pinpointed, and corrections can be tested and implemented. In CT2.0, correctness is no longer a fixed correct-or-incorrect. Outcomes in many ML models are probabilitybased predictions with varying levels of confidence1. For example, an ML model might classify a picture of a cat with a 95% confidence score. Even well-trained ML models, despite being trained on large amounts of data, could produce errors, especially with new inputs. For example, an image of a cat could be incorrectly classified as a dog with a 60% confidence score. Developers define acceptable levels of correctness when designing and building ML models. This requires developers to carefully tune the training process and set appropriate confidence thresholds to determine whether a prediction is acceptable for a specific context. For educators, this shift in understanding correctness requires helping young people to develop critical thinking skills around data-driven tools and AI systems. We could guide learners to ask deeper questions: “How reliable is this prediction with new data?” or “What biases might be in the training data?” By framing correctness or suitability in CT2.0 as an ongoing process of evaluation and continuously refining models to improve their reliability in realworld applications rather than a fixed outcome, we prepare learners not just to use AI tools, but to recognise system limitations and potential harms caused by system outputs.\nDebugging\nDebugging is another practice that takes on different forms in CT1.0 and CT2.0. For example, if a rule-based program implemented in either Scratch or Python doesn’t work as expected, learners can display variable values, set breakpoints, or trace the code line by line to find where things went wrong. Because of the high level of transparency in such programs, we can use systematic and structured debugging practices. However, ML models are often seen as black boxes3, and this opacity makes debugging in CT2.0 less straightforward. ML models are complicated, interconnected networks with billions of parameters that determine outcomes and predictions in ways that are impossible to trace step by step. When an image classifier incorrectly labels an image of a cat as a dog, learners can’t simply find the line of code causing the error because there isn’t one. Instead, debugging in CT2.0 involves examining and improving the quality of the training data, tuning variables and parameters, and testing with a range of diverse inputs to identify patterns in errors (e.g. cats with pointy ears are more likely to be misclassified as dogs). Debugging now requires educators to shift from finding bugs and error correction to focusing on how changes to data and parameters can affect overall performance.\nWhy CT2.0 matters\nWithout CT2.0, today’s learners will remain passive consumers rather than informed participants in a world increasingly shaped by data-driven AI technologies. Integrating CT2.0 alongside traditional computational thinking provides learners with an accurate understanding of computing systems, including how problem solving, correctness, and debugging differ in data-driven systems. This will empower learners to critically evaluate ML models, understand how data is used to train models, identify potential biases, and even create their own ML projects. Embracing CT2.0 makes computing more realistic and representative of the real world, offering learners pathways beyond traditional programming and towards future careers where AI literacy is crucial.\nReferences\nSource pdf\nFootnotes\n\n\nTedre, M., et al. (2021). CT 2.0. qr21_1 ↩ ↩2\n\n\nVartiainen, H., et al. (2021). Machine learning for middle schoolers: Learning through data-driven design. qr21_2 ↩\n\n\nHitron, T., et al. (2019). Can children understand machine learning concepts? The effect of uncovering black boxes. qr21_3 ↩\n\n\n","frontmatter":{"title":"Computational Thinking 2.0","fileOrder":21,"displayName":"21 - Computational Thinking 2.0","aliases":["Computational Thinking 2.0","CT2","CT2.0","QR21"],"draft":null}},"Quick-Reads/QR21_el":{"slug":"Quick-Reads/QR21_el","filePath":"Quick Reads/QR21_el.md","title":"Υπολογιστική Σκέψη 2.0","links":["Quick-Reads/the-cc.io/qr21_1","Quick-Reads/the-cc.io/qr21_2","Quick-Reads/the-cc.io/qr21_3"],"tags":[],"content":"Η Υπολογιστική Σκέψη (ΥΣ) έχει γίνει ακρογωνιαίος λίθος της εκπαίδευσης στην πληροφορική. Η ΥΣ2.0 εισήχθη πρόσφατα από τον Matti Tedre και την ομάδα του1 για να βοηθήσει τους εκπαιδευόμενους να διακρίνουν μεταξύ των παραδοσιακών, βάσει κανόνα ( rule-based) προσεγγίσεων (ΥΣ1.0) στην επίλυση προβλημάτων και των προσεγγίσεων βάσει δεδομένων (data-driven) (ΥΣ2.0) και χρησιμοποιούνται από συστήματα AI. Καθώς τα συστήματα περιλαμβάνουν ολοένα και περισσότερο τόσο βάσει κανόνα (rule-based) όσο και βάσει δεδομένων (data-driven) στοιχεία, είναι απαραίτητο οι εκπαιδευόμενοι να κατανοούν τις διαφορές και να μπορούν να εργάζονται και με τα δύο παραδείγματα.\n\n\n                  \n                  Summary \n                  \n                \n\n\nΒασικές έννοιες\nΕπίλυση προβλημάτων\n\nΗ ΥΣ1.0 εφαρμόζει προσεγγίσεις βάσει κανόνων στην επίλυση προβλημάτων, όπως αυτές που χρησιμοποιούνται στο Scratch και την Python.\nΗ ΥΣ2.0 εισάγει μια μετατόπιση προς μια προσέγγιση βάσει δεδομένων (data-driven) στην επίλυση προβλημάτων.\nΗ αξιολόγηση μοντέλου, η ποιότητα των δεδομένων και οι προκαταλήψεις αποκτούν σημασία στην ΥΣ2.0, καθώς τα ελαττωματικά δεδομένα μπορεί να οδηγήσουν σε άδικα αποτελέσματα.\n\nΟρθότητα\n\nΗ ΥΣ1.0 διδάσκει συνήθως την ορθότητα ως δυαδική, όπου τα προγράμματα παράγουν ή δεν παράγουν σωστά αποτελέσματα.\nΗ ΥΣ2.0 μετρά την ορθότητα κατά βαθμό, όπου τα μοντέλα ML παράγουν προβλέψεις και επίπεδα εμπιστοσύνης.\n\nΕντοπισμός σφαλμάτων\n\nΣτην ΥΣ1.0, ο εντοπισμός σφαλμάτων είναι δομημένος και διαφανής. Τα σφάλματα αντιμετωπίζονται με την ανίχνευση της εκτέλεσης του προγράμματος βήμα προς βήμα.\nΣτην ΥΣ2.0, τα μοντέλα ML είναι αδιαφανή μαύρα κουτιά. Τα προβλήματα εντοπίζονται μέσω αναλύσεων των δεδομένων εισόδου και εξόδου.\nΑυτό απαιτεί μια αλλαγή νοοτροπίας στον εντοπισμό σφαλμάτων, με έμφαση στη βελτίωση των δεδομένων εκπαίδευσης, στη ρύθμιση παραμέτρων και στον έλεγχο με ένα ευρύ φάσμα δεδομένων.\n\n\n\n\n\nΕπίλυση προβλημάτων\nΗ ΥΣ είναι ένα πλαίσιο για την κατανόηση της επίλυσης προβλημάτων με τη χρήση υπολογισμού. Η παραδοσιακή ΥΣ1.0 προέκυψε από τις πρώιμες έννοιες της πληροφορικής, χρησιμοποιώντας μια βάσει κανόνα προσέγγιση όπου τα προγράμματα υπολογιστών ακολουθούν ακριβείς οδηγίες: με σαφώς καθορισμένα δεδομένα εισόδου, οι οδηγίες ακολουθούνται βήμα προς βήμα για να παραχθούν προβλέψιμα δεδομένα εξόδου. Όταν διδάσκονται με την ΥΣ.0, οι εκπαιδευόμενοι μαθαίνουν να αναλύουν την εργασία σε υποεργασίες και να γράφουν σαφείς οδηγίες για κάθε βήμα πριν υλοποιήσουν αυτές τις οδηγίες σε εργαλεία όπως το Scratch και σε γλώσσες όπως η Python. Αντίθετα, η επίλυση προβλημάτων στην ΥΣ2.0 μετατοπίζεται σε μια προσέγγιση βάσει δεδομένων (data-driven)¹. Αντί να γράφουν ρητές οδηγίες, οι εκπαιδευόμενοι μαθαίνουν να συλλέγουν, να καθαρίζουν, να επισημαίνουν και να οργανώνουν μεγάλες ποσότητες σχετικών δεδομένων. Στη συνέχεια, οι εκπαιδευόμενοι χρησιμοποιούν αυτά τα δεδομένα για να εκπαιδεύσουν συστήματα μηχανικής μάθησης (ML), ώστε να αναγνωρίζουν πρότυπα και να παράγουν μοντέλα που δημιουργούν προβλέψεις και επιλύουν προβλήματα. Για παράδειγμα, στην ΥΣ1.0, οι εκπαιδευόμενοι θα μπορούσαν να δημιουργήσουν ένα εργαλείο που ταξινομεί γάτες χρησιμοποιώντας κανόνες Εάν…Τότε σχετικά με τα μουστάκια και τα μυτερά αυτιά. Ωστόσο, στην ΥΣ2.0, θα χρησιμοποιούσαν πολλές εικόνες γατών για να εκπαιδεύσουν ένα μοντέλο με επαρκή ακρίβεια. Επειδή τα δεδομένα βρίσκονται στο επίκεντρο αυτής της διαδικασίας, η ποιότητα των δεδομένων, η αξιολόγηση και οι προκαταλήψεις γίνονται κρίσιμες έννοιες: ελαττωματικά ή προκατειλημμένα σύνολα δεδομένων μπορεί να οδηγήσουν σε αναξιόπιστα ή άδικα αποτελέσματα. Οι σύγχρονες εφαρμογές συνδυάζουν τόσο βάσει κανόνα όσο και βάσει δεδομένων (data-driven ) προσεγγίσεις, από κείμενο και εικόνες που παράγονται από AI, έως λογισμικό αναγνώρισης προσώπου και προτάσεις στα μέσα κοινωνικής δικτύωσης. Η κατανόηση τόσο της ΥΣ1.0 όσο και της ΥΣ2.0 δίνει τη δυνατότητα στους εκπαιδευόμενους όχι μόνο να εργάζονται αποτελεσματικά με αυτά τα εργαλεία, αλλά και να είναι ενεργοί συμμετέχοντες και δημιουργοί αντί για παθητικοί καταναλωτές στις ολοένα και πιο βάσει δεδομένων ( data-driven) κοινωνίες μας2.\nΚατανόηση της ορθότητας\nΗ ορθότητα είναι μια σημαντική έννοια στην πληροφορική και καθορίζει το αν ένα πρόγραμμα λειτουργεί όπως προοριζόταν. Στην ΥΣ1.0, συχνά διδάσκουμε στους εκπαιδευόμενους ότι η ορθότητα σημαίνει πως ένα πρόγραμμα είναι είτε σωστό είτε λανθασμένο. Αυτή η προσέγγιση δίνει έμφαση στην ακρίβεια, όπου οι οδηγίες πρέπει να είναι συντακτικά σωστές, να είναι γραμμένες με λογικό τρόπο και να παράγουν το αναμενόμενο αποτέλεσμα. Τα βάσει κανόνα (Rule-based) προγράμματα που χαρακτηρίζονται από την ΥΣ1.0 προϋποθέτουν υψηλό επίπεδο διαφάνειας: κάθε οδηγία είναι ρητά γραμμένη και μπορεί να ανιχνευθεί, τα σφάλματα μπορούν να εντοπιστούν με ακρίβεια και οι διορθώσεις να δοκιμαστούν και να εφαρμοστούν. Στην ΥΣ2.0, η ορθότητα δεν είναι πλέον μια σταθερή διάκριση σωστού ή λανθασμένου. Τα αποτελέσματα σε πολλά μοντέλα ML είναι προβλέψεις βασισμένες σε πιθανότητες με διαφορετικά επίπεδα εμπιστοσύνης1. Για παράδειγμα, ένα μοντέλο ML μπορεί να ταξινομήσει μια εικόνα γάτας με βαθμό εμπιστοσύνης 95%. Ακόμη και καλά εκπαιδευμένα μοντέλα ML, παρά την εκπαίδευσή τους σε μεγάλα σύνολα δεδομένων, μπορεί να παράγουν σφάλματα, ιδιαίτερα με νέα δεδομένα εισόδου. Για παράδειγμα, μια εικόνα γάτας θα μπορούσε να ταξινομηθεί εσφαλμένα ως σκύλος με βαθμό εμπιστοσύνης 60%. Οι προγραμματιστές καθορίζουν αποδεκτά επίπεδα ορθότητας κατά τον σχεδιασμό και την κατασκευή μοντέλων ML. Αυτό απαιτεί από τους προγραμματιστές να ρυθμίζουν προσεκτικά τη διαδικασία εκπαίδευσης και να θέτουν κατάλληλα κατώφλια εμπιστοσύνης, ώστε να καθορίζεται αν μια πρόβλεψη είναι αποδεκτή για ένα συγκεκριμένο πλαίσιο. Για τους εκπαιδευτικούς, αυτή η μετατόπιση στην κατανόηση της ορθότητας απαιτεί να βοηθήσουν τους νέους να αναπτύξουν δεξιότητες κριτικής σκέψης γύρω από τα εργαλεία και συστήματα AI βάσει δεδομένων (data-driven). Θα μπορούσαμε να καθοδηγήσουμε τους εκπαιδευόμενους ώστε να θέτουν βαθύτερες ερωτήσεις: «Πόσο αξιόπιστη είναι αυτή η πρόβλεψη με νέα δεδομένα;» ή «Ποιες προκαταλήψεις μπορεί να υπάρχουν στα δεδομένα εκπαίδευσης;» Ορίζοντας την ορθότητα ή την καταλληλότητα της ΥΣ2.0 ως μια συνεχή διαδικασία αξιολόγησης και διαρκούς βελτίωσης των μοντέλων ώστε να ενισχύεται η αξιοπιστία τους σε εφαρμογές του πραγματικού κόσμου αντί ως ένα σταθερό αποτέλεσμα, προετοιμάζουμε τους εκπαιδευόμενους όχι μόνο να χρησιμοποιούν εργαλεία AI, αλλά και να αναγνωρίζουν τους περιορισμούς των συστημάτων και τις πιθανές βλάβες που μπορεί να προκαλέσουν τα δεδομένα εξόδου τους.\nΕντοπισμός σφαλμάτων\nΟ εντοπισμός σφαλμάτων είναι μια ακόμη πρακτική που παίρνει διαφορετικές μορφές στην ΥΣ1.0 και στην ΥΣ2.0. Για παράδειγμα, αν ένα βάσει κανόνα (rule-based) πρόγραμμα που υλοποιείται είτε στο Scratch είτε στην Python δε λειτουργεί όπως αναμένεται, οι εκπαιδευόμενοι μπορούν να εμφανίσουν τις τιμές των μεταβλητών, να ορίσουν σημεία διακοπής ή να ανιχνεύσουν τον κώδικα γραμμή προς γραμμή για να βρουν πού συνέβη το σφάλμα. Λόγω του υψηλού επιπέδου διαφάνειας σε τέτοια προγράμματα, μπορούμε να εφαρμόζουμε συστηματικές και δομημένες πρακτικές εντοπισμού και διόρθωσης σφαλμάτων. Ωστόσο, τα μοντέλα ML συχνά θεωρούνται μαύρα κουτιά3, και αυτή η αδιαφάνεια καθιστά τον εντοπισμό σφαλμάτων στην ΥΣ2,0 λιγότερο απλό. Τα μοντέλα ML είναι περίπλοκα, διασυνδεδεμένα δίκτυα με δισεκατομμύρια παραμέτρους που καθορίζουν τα αποτελέσματα και τις προβλέψεις με τρόπους που είναι αδύνατον να ανιχνευθούν βήμα προς βήμα. Όταν ένας ταξινομητής εικόνων επισημαίνει εσφαλμένα μια εικόνα γάτας ως σκύλο, οι εκπαιδευόμενοι δεν μπορούν απλώς να βρουν τη γραμμή κώδικα που προκαλεί το σφάλμα, γιατί τέτοια γραμμή δεν υπάρχει. Αντίθετα, ο εντοπισμός σφαλμάτων στην ΥΣ2.0 περιλαμβάνει την εξέταση και τη βελτίωση της ποιότητας των δεδομένων εκπαίδευσης, τη ρύθμιση μεταβλητών και παραμέτρων, καθώς και τη δοκιμή με ένα εύρος διαφορετικών δεδομένων εισόδου για τον εντοπισμό μοτίβων στα σφάλματα (π.χ. οι γάτες με μυτερά αυτιά είναι πιο πιθανό να ταξινομηθούν εσφαλμένα ως σκύλοι). Ο εντοπισμός σφαλμάτων απαιτεί πλέον από τους εκπαιδευτικούς να μετατοπιστούν από τον εντοπισμό σφαλμάτων και τη διόρθωσή τους στην εστίαση στο πώς οι αλλαγές στα δεδομένα και στις παραμέτρους μπορούν να επηρεάσουν τη συνολική απόδοση.\nΓιατί έχει σημασία η ΥΣ2.0\nΧωρίς την ΥΣ2.0, οι σημερινοί εκπαιδευόμενοι θα παραμείνουν παθητικοί καταναλωτές αντί για ενημερωμένοι συμμετέχοντες σε έναν κόσμο που διαμορφώνεται ολοένα και περισσότερο από τεχνολογίες AI βάσει δεδομένων (data-driven). Η ενσωμάτωση της ΥΣ2.0 παράλληλα με την παραδοσιακή υπολογιστική σκέψη παρέχει στους εκπαιδευόμενους μια ακριβή κατανόηση των υπολογιστικών συστημάτων, συμπεριλαμβανομένου του τρόπου με τον οποίο η επίλυση προβλημάτων, η ορθότητα και ο εντοπισμός σφαλμάτων διαφέρουν στα συστήματα βάσει δεδομένων (data-driven). Αυτό θα ενδυναμώσει τους εκπαιδευόμενους ώστε να αξιολογούν κριτικά τα μοντέλα ML, να κατανοούν πώς χρησιμοποιούνται τα δεδομένα για την εκπαίδευση μοντέλων, να αναγνωρίζουν πιθανές προκαταλήψεις και ακόμη και να δημιουργούν τα δικά τους έργα ML. Η υιοθέτηση της ΥΣ2.0 καθιστά την πληροφορική πιο ρεαλιστική και αντιπροσωπευτική του πραγματικού κόσμου, προσφέροντας στους εκπαιδευόμενους διαδρομές πέρα από τον παραδοσιακό προγραμματισμό και προς μελλοντικές σταδιοδρομίες όπου ο ψηφιακός γραμματισμός AI είναι καθοριστικός.\nΒιβλιογραφικές αναφορές\nΑρχείο-πηγή σε μορφή pdf\nFootnotes\n\n\nTedre, M., et al. (2021). CT 2.0. qr21_1 ↩ ↩2\n\n\nVartiainen, H., et al. (2021). Machine learning for middle schoolers: Learning through data-driven design. qr21_2 ↩\n\n\nHitron, T., et al. (2019). Can children understand machine learning concepts? Η επίδραση της αποκάλυψης των μαύρων κουτιών. qr21_3 ↩\n\n\n","frontmatter":{"title":"Υπολογιστική Σκέψη 2.0","lang":"Greek","translatedFrom":"[QR21](QR21.md)","aliases":["QR21_el"],"draft":null}},"Quick-Reads/QR21_es":{"slug":"Quick-Reads/QR21_es","filePath":"Quick Reads/QR21_es.md","title":"Pensamiento computacional 2.0","links":["Quick-Reads/the-cc.io/qr21_1","Quick-Reads/the-cc.io/qr21_2","Quick-Reads/the-cc.io/qr21_3"],"tags":[],"content":"El pensamiento computacional (CT) se ha convertido en la piedra angular de la educación informática. Matti Tedre y su equipo1 presentaron recientemente el concepto CT2.0 para ayudar a los y las estudiantes a distinguir entre los enfoques tradicionales basados en reglas (CT1.0) para la resolución de problemas, y los enfoques basados en datos (CT2.0) que utilizan los sistemas de IA. A medida que los sistemas incluyen cada vez más elementos basados en reglas y en datos, es muy importante que el alumnado comprenda las diferencias y que sea capaz de trabajar con ambos paradigmas.\n\n\n                  \n                  Summary \n                  \n                \n\n\nConceptos clave\nSolución de problemas\n\nEl marco CT1.0 aplica enfoques basados en reglas para la resolución de problemas, como los que se utilizan en Scratch y Python.\nEl marco CT2.0 presenta un cambio hacia un enfoque de la resolución de problemas basado en datos.\nLa evaluación del modelo, la calidad de los datos y el sesgo se vuelven importantes en CT2.0, ya que los datos incorrectos pueden dar lugar a resultados injustos.\n\nCorrección\n\nEn CT1.0, la corrección se entiende como una cualidad como binaria, donde los programas producen o no resultados correctos.\nCT2.0 mide la corrección por grados, donde los modelos de aprendizaje automático generan predicciones y niveles de confianza.\n\nDepuración\n\nEn CT1.0, la depuración es estructurada y transparente. Los errores se solucionan siguiendo la ejecución del programa paso a paso.\nEn CT2.0, los modelos de aprendizaje automático son cajas negras opacas. Los problemas se detectan mediante el análisis de los datos de entrada y salida.\nEsto requiere un cambio en la mentalidad de depuración, centrándose en mejorar los datos de entrenamiento, ajustar los parámetros y probar con una gama diversa de datos.\n\n\n\n\n\nSolución de problemas\nCT es un marco para comprender la resolución de problemas mediante la computación. El marco CT1.0 tradicional surgió a partir de los primeros conceptos informáticos utilizando un enfoque basado en reglas, en el que los programas informáticos siguen instrucciones precisas: con una entrada bien definida, se siguen instrucciones paso a paso para producir una salida predecible. En la enseñanza con CT1.0, el alumnado aprende a dividir la tarea en subtareas y a escribir instrucciones claras para cada paso antes de implementar dichas instrucciones en herramientas como Scratch y lenguajes como Python. Por el contrario, la resolución de problemas con CT2.0 cambia a un enfoque basado en datos¹. En lugar de escribir instrucciones explícitas, los y las estudiantes aprenden a recopilar, depurar, etiquetar y organizar grandes cantidades de datos relevantes. A continuación, los datos se utilizan para entrenar sistemas de aprendizaje automático (ML) con el fin de identificar patrones y producir modelos que generen predicciones y resuelvan problemas. Por ejemplo, en CT1.0, los y las estudiantes podrían crear una herramienta que clasifique gatos mediante reglas del tipo Si… Entonces aplicadas a bigotes y orejas puntiagudas. Sin embargo, con el marco CT2.0, utilizarían numerosas imágenes de gatos para entrenar un modelo con suficiente precisión. Dado que los datos son fundamentales para este proceso, la calidad de los datos, la evaluación y el sesgo se convierten en conceptos de vital importancia: los conjuntos de datos defectuosos o sesgados pueden dar lugar a resultados poco fiables o injustos. Las aplicaciones modernas combinan enfoques basados en reglas y datos: desde texto e imágenes generados mediante IA hasta software de reconocimiento facial y recomendaciones de redes sociales. Comprender las diferencias entre el marco CT1.0 y el marco CT2.0 permite al alumnado no solo trabajar de manera eficaz con estas herramientas, sino también ser participantes activos y creadores en lugar de consumidores pasivos en una sociedad cada vez más basada en datos2.\nConcepto de corrección\nLa corrección es un concepto importante en informática y determina si un programa funciona según lo previsto. En CT1.0, a menudo enseñamos a los y las estudiantes que la corrección implica que un programa sea correcto o incorrecto. Este enfoque enfatiza la precisión, donde las instrucciones deben ser sintácticamente correctas, deben estar escritas de manera lógica y producir el resultado esperado. Los programas basados en reglas, característicos del marco CT1.0, suponen un alto nivel de transparencia: cada instrucción está escrita explícitamente y puede rastrearse, los errores se pueden identificar con precisión y se pueden probar e implementar correcciones. Con el marco CT2.0, la corrección ya no es una cuestión fija de correcto o incorrecto. Los resultados de muchos modelos de aprendizaje automático son predicciones basadas en probabilidades con distintos niveles de fiabilidad1. Por ejemplo, un modelo de aprendizaje automático podría clasificar la imagen de un gato con una puntuación de fiabilidad del 95 %. Incluso los modelos de aprendizaje automático bien entrenados, a pesar de estar entrenados con grandes cantidades de datos, pueden producir errores, sobre todo con nuevas entradas. Por ejemplo, una imagen de un gato podría clasificarse incorrectamente como un perro con una puntuación de fiabilidad del 60 %. Los desarrolladores definen niveles aceptables de corrección en el diseño y el desarrollo de modelos de aprendizaje automático. Esto requiere ajustar el proceso de entrenamiento al detalle y establecer umbrales de confianza apropiados para determinar si una predicción es aceptable para un contexto específico. Para el personal docente, este cambio en la comprensión del concepto de corrección requiere ayudar a los y las adolescentes a desarrollar habilidades de pensamiento crítico en torno a herramientas basadas en datos y sistemas de inteligencia artificial. Podríamos guiar al alumnado para plantear preguntas más profundas: “¿Qué fiabilidad ofrece esta predicción con datos nuevos?” o “¿Qué sesgos puede haber en los datos de entrenamiento?” Al enmarcar la corrección o idoneidad en CT2.0 como un proceso continuo de evaluación y depuración continua de modelos para mejorar su fiabilidad en aplicaciones del mundo real en lugar de un resultado fijo, preparamos al alumnado no solo para usar herramientas de IA, sino también para reconocer las limitaciones del sistema y los posibles daños causados por los resultados del sistema.\nDepuración\nLa depuración es otra práctica que adopta diferentes formas en CT1.0 y CT2.0. Por ejemplo, si un programa basado en reglas implementado en Scratch o Python no funciona como se espera, los y las estudiantes pueden mostrar valores de variables, establecer puntos de interrupción o rastrear el código línea por línea hasta encontrar la raíz del problema. Debido al alto nivel de transparencia de dichos programas, podemos utilizar prácticas de depuración sistemáticas y estructuradas. Sin embargo, los modelos de aprendizaje automático a menudo se consideran como cajas negras3, y esta opacidad hace que la depuración en CT2.0 no sea tan sencilla. Los modelos de aprendizaje automático son redes complejas e interconectadas con miles de millones de parámetros que determinan los resultados y las predicciones de maneras que son imposibles de rastrear paso a paso. Cuando un clasificador de imágenes etiqueta incorrectamente una fotografía de un gato como un perro, los y las estudiantes no pueden simplemente buscar la línea de código responsable del error simplemente porque no existe ninguna. En su lugar, la tarea de depuración en el marco CT2.0 implica examinar y mejorar la calidad de los datos de entrenamiento, ajustar variables y parámetros, así como probar con una variedad de entradas diferentes para identificar patrones en los errores (por ejemplo, los gatos con orejas puntiagudas tienen más probabilidades de ser clasificados como perros). Ahora la depuración requiere que los docentes pasen de buscar errores y corregirlos a centrarse en cómo los cambios en los datos y los parámetros pueden afectar al rendimiento general.\nImportancia del marco CT2.0\nSin el marco CT2.0, los y las estudiantes de hoy seguirán siendo consumidores pasivos en lugar de participantes informados en un mundo cada vez más moldeado por tecnologías de inteligencia artificial basadas en datos. La integración del marco CT2.0 en el pensamiento computacional tradicional proporciona al alumnado una comprensión precisa de los sistemas informáticos y de las diferencias que existen en la resolución de problemas, la corrección y la depuración con respecto a los sistemas basados en datos. Esto permitirá a los y las estudiantes evaluar críticamente los modelos de aprendizaje automático, comprender cómo se utilizan los datos para entrenar modelos, identificar posibles sesgos e incluso crear sus propios proyectos de aprendizaje automático. La adopción del concepto CT2.0 hace que la informática sea más realista y representativa del mundo real, ofreciendo al alumnado oportunidades más allá de la programación tradicional y hacia futuras carreras donde la alfabetización en IA es fundamental.\nReferencias\nSource pdf\nFootnotes\n\n\nTedre, M., et al. (2021). CT 2.0. qr21_1 ↩ ↩2\n\n\nVartiainen, H., et al. (2021). Machine learning for middle schoolers: Learning through data-driven design. qr21_2 ↩\n\n\nHitron, T., et al. (2019). Can children understand machine learning concepts? The effect of uncovering black boxes. qr21_3 ↩\n\n\n","frontmatter":{"title":"Pensamiento computacional 2.0","lang":"Spanish","translatedFrom":"[QR21](QR21.md)","aliases":["QR21_el"],"draft":null}},"Quick-Reads/QR21_lt":{"slug":"Quick-Reads/QR21_lt","filePath":"Quick Reads/QR21_lt.md","title":"Informatinis mąstymas 2.0","links":["Quick-Reads/the-cc.io/qr21_1","Quick-Reads/the-cc.io/qr21_2","Quick-Reads/the-cc.io/qr21_3"],"tags":[],"content":"Informatinis mąstymas (angl. Computational thinking, CT) tapo kompiuterių mokslo kertiniu akmeniu. Matti Tedre ir jo komanda neseniai pristatė CT2.01, kad padėtų besimokantiesiems atskirti tradicinius taisyklėmis pagrįstus problemų sprendimo metodus (CT1.0) nuo duomenimis pagrįstų metodų (CT2.0), kuriuos naudoja DI sistemos. Kadangi sistemose vis dažniau naudojami ir taisyklėmis, ir duomenimis pagrįsti elementai, besimokantiesiems labai svarbu suprasti jų skirtumus ir mokėti dirbti su abiem paradigmomis.\n\n\n                  \n                  Summary \n                  \n                \n\n\nPagrindinės sąvokos\nProblemų sprendimas\n\nCT1.0 taiko taisyklėmis pagrįstus problemų sprendimo metodus, panašius į tuos, kurie naudojami „Scratch“ ir „Python“.\nCT2.0 pereina prie duomenimis pagrįsto požiūrio į problemų sprendimą.\nModelio vertinimas, duomenų kokybė ir šališkumas tampa svarbūs CT2.0, nes ydingi duomenys gali lemti nesąžiningus rezultatus.\n\nTeisingumas\n\nCT1.0 paprastai moko, kad teisingumas yra dvejetainis, o programos arba generuoja, arba negeneruoja teisingų rezultatų.\nCT2.0 matuoja tikslumo laipsnį, o MM modeliai generuoja prognozes ir patikimumo lygius.\n\nTrikdžių šalinimas\n\nCT1.0 atveju trikdžių šalinimas yra struktūrizuotas ir skaidrus. Klaidos sprendžiamos stebint programos vykdymą žingsnis po žingsnio.\nCT2.0 atveju MM modeliai primena neskaidrias juodąsias dėžes. Problemos nustatomos analizuojant įvesties ir išvesties duomenis.\nTam reikia pakeisti trikdžių šalinimo mąstyseną, daugiausia dėmesio skiriant mokymo duomenų tobulinimui, parametrų derinimui ir testavimui su įvairiais duomenimis.\n\n\n\n\n\nProblemų sprendimas\nCT yra sistema, skirta suprasti problemų sprendimą naudojant skaičiavimus. Tradicinis CT1.0 atsirado iš ankstyvųjų skaičiavimo sąvokų, naudojant taisyklėmis pagrįstą metodą, pagal kurį kompiuterinės programos vykdo tikslius nurodymus: esant gerai apibrėžtai įvesties informacijai, nurodymai yra vykdomi žingsnis po žingsnio, kad būtų gautas nuspėjamas rezultatas. Mokymui naudojant CT1.0, besimokantieji išmoksta suskaidyti užduotį į dalis ir parašyti aiškius nurodymus kiekvienam žingsniui, prieš įgyvendinant šiuos nurodymus tokiose priemonėse, kaip „Scratch“ ir tokiose kalbose, kaip „Python“. Priešingai, problemų sprendimas taikant CT2.0 naudoja duomenimis pagrįstus metodus¹. Užuot rašę aiškius nurodymus, besimokantieji išmoksta rinkti, valyti, žymėti ir tvarkyti didelius kiekius svarbių duomenų. Tada besimokantieji naudoja šiuos duomenis mašininio mokymosi (MM) sistemoms apmokyti, kad jos atpažintų modelius ir generuotų prognozes bei išspręstų problemas. Pavyzdžiui, pagal CT1.0 metodą, klasėje besimokantieji galėtų sukurti įrankį, kuris klasifikuotų kates pagal „If…Then“ taisykles apie ūsus ir smailias ausis. Tačiau pagal CT2.0 modelį, jie naudotų daug kačių atvaizdų, kad pakankamai tiksliai apmokytų modelį. Kadangi duomenys yra šio proceso pagrindas, duomenų kokybė, vertinimas ir šališkumas tampa itin svarbiomis sąvokomis: ydingi arba šališki duomenų rinkiniai gali lemti nepatikimus arba nesąžiningus rezultatus. Šiuolaikinės programos derina ir taisyklėmis, ir duomenimis pagrįstus metodus – nuo DI generuojamo teksto ir vaizdų iki veido atpažinimo programinės įrangos ir socialinių tinklų rekomendacijų. Suprasdami ne tik CT1.0, bet ir CT2.0, besimokantieji gali ne tik efektyviai dirbti su šiais įrankiais, bet ir būti aktyviais dalyviais bei kūrėjais, o ne pasyviais vartotojais mūsų vis labiau duomenimis pagrįstoje visuomenėje2.\nTeisingumo suvokimas\nTeisingumas yra svarbi skaičiavimo sąvoka, lemianti, ar programa veikia taip, kaip numatyta. Pagal CT1.0 metodą dažnai mokome besimokančiuosius, kad teisingumas reiškia, jog programa yra arba teisinga, arba neteisinga. Šis metodas pabrėžia tikslumą, kai nurodymai turi būti sintaksiškai taisyklingi, parašyti logiškai ir duoti laukiamą rezultatą. CT1.0 būdingos taisyklėmis pagrįstos programos reikalauja didelio skaidrumo – kiekvienas nurodymas yra parašytas aiškiai ir atsekamas, todėl galima nustatyti klaidas, išbandyti ir įdiegti pataisymus. Pagal CT2.0 metodą, teisingumas nereiškia tik „teisingas“ arba „neteisingas“. Daugelio MM modelių rezultatai yra paremti tikimybe pagrįstomis prognozėmis, kurių patikimumo lygis gali būti skirtingas1. Pavyzdžiui, MM modelis gali klasifikuoti katės nuotrauką 95 % patikimumu. Net ir gerai apmokyti MM modeliai, nepaisant to, kad jie apmokyti dirbti su dideliais duomenų kiekiais, gali generuoti klaidas, ypač naudojant naujus įvesties duomenis. Pavyzdžiui, katės atvaizdas gali būti neteisingai klasifikuojamas kaip šuns kai patikimumo rodiklis yra 60 %. Kūrėjai apibrėžia priimtinus teisingumo lygius projektuodami ir kurdami MM modelius. Tam reikia, kad kūrėjai atidžiai suderintų apmokymo procesą ir nustatytų tinkamas patikimumo ribas, nustatančias, ar prognozė yra priimtina konkrečiame kontekste. Pasikeitus teisingumo sąvokai pedagogai turi padėti jauniems žmonėms lavinti kritinio mąstymo įgūdžius, susijusius su duomenimis pagrįstais įrankiais ir DI sistemomis. Galėtume padėti besimokantiesiems užduoti gilesnius klausimus: „Kiek patikima ši prognozė remiantis naujais duomenimis?“ arba „Kokie šališkumai gali būti mokymo duomenyse?“ Pagal CT2.0 metodą, apibrėždami teisingumą ar tinkamumą kaip nuolatinį vertinimo procesą ir nuolatinį modelių tobulinimą, siekiant pagerinti jų patikimumą realiose taikomosiose programose, o ne gauti fiksuotą rezultatą, mes ruošiame besimokančiuosius ne tik naudoti DI įrankius, bet ir atpažinti sistemos apribojimus bei galimą žalą, kurią daro sistemos išvediniai.\nTrikdžių šalinimas\nTrikdžių šalinimu vadinama dar viena praktika, kuri CT1.0 ir CT2.0 metoduose įgauna skirtingas formas. Pavyzdžiui, jei taisyklėmis pagrįsta programa, įdiegta „Scratch“ arba „Python“, neveikia taip, kaip tikėtasi, besimokantieji gali matyti kintamąsias reikšmes, nustatyti lūžio taškus arba atsekti kodą eilutė po eilutės, kad surastų, kur įvyko klaida. Dėl didelio tokių programų skaidrumo galime naudoti sistemingas ir struktūrizuotas trikdžių šalinimo praktikas. Tačiau MM modeliai dažnai laikomi juodosiomis dėžėmis3 ir jų neskaidrumas apsunkina trikdžių šalinimą taikant CT2.0 metodą. MM modeliai yra sudėtingi, tarpusavyje susiję tinklai su milijardais parametrų, kurie lemia rezultatus ir prognozes tokiais būdais, kurių neįmanoma atsekti žingsnis po žingsnio. Kai vaizdų klasifikatorius neteisingai pažymi katės vaizdą kaip šuns, besimokantieji negali tiesiog rasti klaidą sukeliančios kodo eilutės, nes tokios nėra. Vietoj to, CT2.0 trikdžių šalinimas apima mokymo duomenų kokybės tikrinimą ir gerinimą, kintamųjų ir parametrų derinimą bei testavimą su įvairiais įvesties duomenimis, siekiant nustatyti klaidų modelius (pvz., katės su smailiomis ausimis dažniau klaidingai klasifikuojamos kaip šunys). Trikdžių šalinimas nuo šiol reikalauja, kad pedagogai susitelktų ne į klaidų paieškas ir taisymą, o į tai, kaip duomenų ir parametrų pakeitimai gali paveikti bendrą rezultatą.\nKuo svarbus CT2.0\nBe CT2.0, šiandieniniai besimokantieji liks pasyvūs vartotojai, o ne informuoti dalyviai pasaulyje, kurį vis labiau formuoja duomenimis pagrįstos DI technologijos. Sujungdami CT2.0 su tradiciniu informatiniu mąstymu, besimokantieji įgyja tikslų supratimą apie skaičiavimo sistemas, įskaitant tai, kuo duomenimis pagrįstose sistemose skiriasi problemų sprendimas, teisingumas ir trikdžių šalinimas. Tai suteikia besimokantiesiems galimybę kritiškai vertinti MM modelius, suprasti, kaip duomenys yra naudojami modeliams mokyti, nustatyti galimus šališkumus ir netgi kurti savo mašininio mokymosi projektus. CT2.0 diegimas daro kompiuteriją realistiškesne ir labiau atspindinčia tikrąjį pasaulį, siūlydamas besimokantiesiems kelius, peržengiančius tradicinio programavimo ribas, link būsimų karjeros galimybių, kuriose gebėjimas naudotis DI yra labai svarbus.\nŠaltiniai\nŠaltinio pdf\nFootnotes\n\n\nTedre, M., et al. (2021). CT 2.0. qr21_1 ↩ ↩2\n\n\nVartiainen, H., et al. (2021). Machine learning for middle schoolers: Learning through data-driven design. qr21_2 ↩\n\n\nHitron, T., et al. (2019). Can children understand machine learning concepts? The effect of uncovering black boxes. qr21_3 ↩\n\n\n","frontmatter":{"title":"Informatinis mąstymas 2.0","lang":"Lithuaniun","translatedFrom":"[QR21](QR21.md)","aliases":["QR21_it"],"draft":null}},"Quick-Reads/QR21_lv":{"slug":"Quick-Reads/QR21_lv","filePath":"Quick Reads/QR21_lv.md","title":"Datordomāšana 2.0","links":["Quick-Reads/the-cc.io/qr21_1","Quick-Reads/the-cc.io/qr21_2","Quick-Reads/the-cc.io/qr21_3"],"tags":[],"content":"Datordomāšana (DT) ir kļuvusi par datorzinātņu izglītības stūrakmeni. Mati Tedre un viņa komanda nesen ieviesa CT2.01, lai palīdzētu studentiem atšķirt tradicionālās uz noteikumiem balstītās problēmu risināšanas pieejas (CT1.0) no datu vadītajām pieejām (CT2.0), ko izmanto mākslīgā intelekta sistēmas. Tā kā sistēmās arvien vairāk ir iekļauti gan uz noteikumiem balstīti, gan uz datiem balstīti elementi, ir svarīgi, lai studenti izprastu atšķirības un spētu strādāt ar abām paradigmām.\n\n\n                  \n                  Summary \n                  \n                \n\n\nGalvenie jēdzieni\nProblēmu risināšana\n\nCT1.0 problēmu risināšanā izmanto uz noteikumiem balstītas pieejas, piemēram, tās, kas tiek izmantotas Scratch un Python.\nCT2.0 piedāvā pāreju uz uz datiem balstītu pieeju problēmu risināšanā.\nModeļa novērtēšana, datu kvalitāte un neobjektivitāte kļūst svarīga CT2.0, jo kļūdaini dati var izraisīt negodīgus rezultātus.\n\nPareizība\n\nCT1.0 parasti māca pareizību kā bināru sistēmu, kur programmas ģenerē vai neģenerē pareizus rezultātus.\nCT2.0 mēra pareizību pēc pakāpes, kur ML modeļi ģenerē prognozes un ticamības līmeņus.\n\nAtkļūdošana\n\nCT1.0 versijā atkļūdošana ir strukturēta un caurredzama. Kļūdas tiek novērstas, soli pa solim izsekojot programmas izpildi.\nCT2.0 versijā ML modeļi ir necaurredzamas melnas kastes. Problēmas tiek atklātas, analizējot ievades un izvades datus.\nLai to izdarītu, ir jāmaina atkļūdošanas domāšanas veids, koncentrējoties uz apmācības datu uzlabošanu, parametru regulēšanu un testēšanu ar dažādu datu klāstu.\n\n\n\n\n\nProblēmu risināšana\nCT ir sistēma problēmu risināšanas izpratnei, izmantojot aprēķinus. Tradicionālā CT1.0 versija radās no agrīnajām skaitļošanas koncepcijām, izmantojot uz noteikumiem balstītu pieeju, kur datorprogrammas izpilda precīzas instrukcijas: ar precīzi definētu ievadi instrukcijas tiek izpildītas soli pa solim, lai iegūtu paredzamu rezultātu. Mācot ar CT1.0, studenti iemācās sadalīt uzdevumu apakšuzdevumos un uzrakstīt skaidras instrukcijas katram solim, pirms šīs instrukcijas tiek ieviestas tādos rīkos kā Scratch un tādās valodās kā Python. Turpretī problēmu risināšana CT2.0 versijā pāriet uz datu vadītu pieeju¹. Tā vietā, lai rakstītu skaidrus norādījumus, audzēkņi mācās vākt, tīrīt, marķēt un kārtot lielus attiecīgo datu apjomus. Pēc tam studenti izmanto šos datus, lai apmācītu mašīnmācīšanās (ML) sistēmas, lai identificētu modeļus un izveidotu modeļus, kas ģenerē prognozes un risina problēmas. Piemēram, CT1.0 vidē skolēni varētu izveidot rīku, kas klasificē kaķus, izmantojot “Ja…Tad” noteikumus par ūsām un smailām ausīm. Tomēr CT2.0 versijā viņi izmantotu daudzus kaķu attēlus, lai apmācītu modeli ar pietiekamu precizitāti. Tā kā dati ir šī procesa centrālais elements, datu kvalitāte, novērtēšana un neobjektivitāte kļūst par kritiski svarīgiem jēdzieniem: kļūdaini vai neobjektīvi datu kopumi var novest pie neuzticamiem vai netaisnīgiem rezultātiem. Mūsdienu lietojumprogrammas apvieno gan uz noteikumiem balstītas, gan uz datiem balstītas pieejas — sākot ar mākslīgā intelekta ģenerētu tekstu un attēliem un beidzot ar sejas atpazīšanas programmatūru un sociālo mediju ieteikumiem. Izpratne gan par CT1.0, gan CT2.0 dod studentiem iespēju ne tikai efektīvi strādāt ar šiem rīkiem, bet arī būt aktīviem dalībniekiem un radītājiem, nevis pasīviem patērētājiem mūsu arvien vairāk uz datiem balstītajās sabiedrībās2.\nPareizības izpratne\nPareizība ir svarīgs jēdziens skaitļošanā un nosaka, vai programma darbojas, kā paredzēts. CT1.0 vidē mēs bieži mācām studentiem, ka pareizība nozīmē, ka programma ir vai nu pareiza, vai nepareiza. Šī pieeja uzsver precizitāti, kur instrukcijām jābūt sintaktiski pareizām, loģiski uzrakstītām un tām jārada paredzētais rezultāts. CT1.0 raksturotās uz noteikumiem balstītās programmas pieņem augstu caurspīdīguma līmeni: katra instrukcija ir skaidri uzrakstīta un to var izsekot, kļūdas var precīzi noteikt, un labojumus var pārbaudīt un ieviest. CT2.0 versijā pareizība vairs nav fiksēta “pareizi” vai “nepareizi”. Daudzu mašīnmācīšanās modeļu rezultāti ir uz varbūtību balstītas prognozes ar dažādu ticamības līmeni1. Piemēram, mašīnmācīšanās modelis varētu klasificēt kaķa attēlu ar 95 % ticamības pakāpi. Pat labi apmācīti mašīnmācīšanās modeļi, neskatoties uz to, ka tie ir apmācīti darbam ar lielu datu apjomu, var radīt kļūdas, īpaši ar jauniem ievades datiem. Piemēram, kaķa attēls varētu tikt nepareizi klasificēts kā suns ar 60% ticamības rādītāju. Izstrādātāji, projektējot un veidojot mašīnmācīšanās modeļus, nosaka pieņemamos pareizības līmeņus. Tas prasa izstrādātājiem rūpīgi pielāgot apmācības procesu un noteikt atbilstošus ticamības sliekšņus, lai noteiktu, vai prognoze ir pieņemama konkrētā kontekstā. Pedagogiem šī izpratnes maiņa par pareizību liek palīdzēt jauniešiem attīstīt kritiskās domāšanas prasmes, izmantojot uz datiem balstītus rīkus un mākslīgā intelekta sistēmas. Mēs varētu mudināt studentus uzdot dziļākus jautājumus: “Cik ticama ir šī prognoze, ņemot vērā jaunus datus?” vai “Kādas neobjektivitātes varētu būt apmācības datos?” Formulējot pareizību vai piemērotību CT2.0 kā nepārtrauktu novērtēšanas procesu un nepārtraukti pilnveidojot modeļus, lai uzlabotu to uzticamību reālās pasaules lietojumprogrammās, nevis kā fiksētu rezultātu, mēs sagatavojam studentus ne tikai mākslīgā intelekta rīku lietošanai, bet arī sistēmas ierobežojumu un sistēmas izvades radīto iespējamo kaitējumu atpazīšanai.\nAtkļūdošana\nAtkļūdošana ir vēl viena prakse, kas CT1.0 un CT2.0 versijās izpaužas dažādās formās. Piemēram, ja uz noteikumiem balstīta programma, kas ieviesta vai nu Scratch, vai Python valodā, nedarbojas, kā paredzēts, studenti var parādīt mainīgo vērtības, iestatīt pārtraukuma punktus vai izsekot kodam pa rindām, lai atrastu, kur kaut kas nogāja greizi. Tā kā šādās programmās ir augsts caurredzīguma līmenis, mēs varam izmantot sistemātiskas un strukturētas atkļūdošanas prakses. Tomēr ML modeļi bieži tiek uzskatīti par melnajām kastēm3, un šī necaurredzamība apgrūtina atkļūdošanu CT2.0. ML modeļi ir sarežģīti, savstarpēji savienoti tīkli ar miljardiem parametru, kas nosaka rezultātus un prognozes veidos, kurus nav iespējams izsekot soli pa solim. Ja attēlu klasifikators nepareizi apzīmē kaķa attēlu kā suni, apguvēji nevar vienkārši atrast koda rindiņu, kas izraisa kļūdu, jo tādas nav. Tā vietā atkļūdošana CT2.0 ietver apmācības datu kvalitātes pārbaudi un uzlabošanu, mainīgo un parametru regulēšanu, kā arī testēšanu ar dažādiem ievades datiem, lai identificētu kļūdu modeļus (piemēram, kaķi ar smailām ausīm, visticamāk, tiks nepareizi klasificēti kā suņi). Tagad, lai veiktu atkļūdošanu, skolotājiem ir jāpāriet no kļūdu atrašanas un kļūdu labošanas, lai koncentrētos uz to, kā izmaiņas datos un parametros var ietekmēt vispārējo veiktspēju.\nKāpēc CT2.0 ir svarīgs\nBez CT2.0 mūsdienu studenti paliks pasīvi patērētāji, nevis informēti dalībnieki pasaulē, ko arvien vairāk veido uz datiem balstītas mākslīgā intelekta tehnoloģijas. CT2.0 integrēšana ar tradicionālo skaitļošanas domāšanu sniedz studentiem precīzu izpratni par skaitļošanas sistēmām, tostarp par to, kā problēmu risināšana, pareizība un atkļūdošana atšķiras datu vadītās sistēmās. Tas dos studentiem iespēju kritiski izvērtēt mašīnmācīšanās modeļus, izprast, kā dati tiek izmantoti modeļu apmācībai, identificēt iespējamās neobjektivitātes un pat izveidot savus mašīnmācīšanās projektus. CT2.0 ieviešana padara skaitļošanu reālistiskāku un atbilstošāku reālajai pasaulei, piedāvājot studentiem ceļus ārpus tradicionālās programmēšanas un uz nākotnes karjeru, kurā mākslīgā intelekta pratība ir izšķiroša.\nAtsauces\nAvota pdf fails\nFootnotes\n\n\nTedre, M., et al. (2021). CT 2.0. qr21_1 ↩ ↩2\n\n\nVartiainen, H., et al. (2021). Mašīnmācība vidusskolēniem: mācīšanās, izmantojot datu vadītu dizainu. qr21_2 ↩\n\n\nHitron, T., et al. (2019). Vai bērni var saprast mašīnmācīšanās koncepcijas? Melno kastu atklāšanas efekts. qr21_3 ↩\n\n\n","frontmatter":{"title":"Datordomāšana 2.0","lang":"Latvian","translatedFrom":"[QR21](QR21.md)","aliases":["QR21_lv"],"draft":null}},"Quick-Reads/QR21_ro":{"slug":"Quick-Reads/QR21_ro","filePath":"Quick Reads/QR21_ro.md","title":"Gândire Computațională 2.0","links":["Quick-Reads/the-cc.io/qr21_1","Quick-Reads/the-cc.io/qr21_2","Quick-Reads/the-cc.io/qr21_3"],"tags":[],"content":"Gândirea computațională (Computational Thinking - CT), a devenit o piatră de temelie a educației în domeniul informaticii. Conceptul de gândire computațională 2.0 (CT2.0) a fost introdus recent de Matti Tedre și echipa sa1 pentru a-i ajuta pe elevi să distingă între abordările tradiționale bazate pe reguli (CT1.0) pentru a rezolva probleme și abordările bazate pe date (CT2.0) folosite de sistemele de inteligență artificială. Pe măsură ce sistemele includ din ce în ce mai mult atât elemente bazate pe reguli, cât și elemente bazate pe date, este esențial ca elevii să înțeleagă diferențele și să poată lucra cu ambele paradigme.\n\n\n                  \n                  Summary \n                  \n                \n\n\nConcepte-cheie\nRezolvarea de probleme\n\nCT1.0 aplică abordări bazate pe reguli pentru a rezolva probleme, precum cele utilizate în Scratch și Python.\nCT2.0 aduce o schimbare spre o abordare bazată pe date pentru rezolvarea de probleme.\nEvaluarea modelelor, calitatea datelor și prejudecățile din date devin importante în CT2.0, întrucât datele eronate pot duce la rezultate inechitabile.\n\nCorectitudinea\n\nÎn CT1.0 învățăm despre corectitudine că este binară – programele produc sau nu produc rezultate corecte.\nÎn CT2.0 corectitudinea este măsurată pe niveluri – modelele de învățare automată generează predicții și scoruri de încredere.\n\nDepanarea\n\nÎn CT1.0, depanarea este structurată și transparentă. Erorile sunt remediate prin urmărirea execuției programului pas cu pas.\nÎn CT2.0, modelele de învățare automată sunt ca niște „cutii negre” opace. Problemele sunt identificate prin analiza datelor de intrare și a rezultatelor.\nAcest lucru necesită o schimbarea de mentalitate în ceea ce privește depanarea: trebuie să ne concentrăm pe îmbunătățirea datelor de antrenament, reglarea parametrilor și testarea cu seturi diverse de date.\n\n\n\n\n\nRezolvarea de probleme\nGândirea computațională este un cadru pentru înțelegerea rezolvării de probleme prin calcul. Gândirea computațională tradițională (CT1.0) a apărut din conceptele informaticii timpurii, folosind o abordare bazată pe reguli, în care programele de calculator urmează instrucțiuni precise: cu date de intrare bine definite, instrucțiunile sunt urmate pas cu pas pentru a produce un rezultat previzibil. Atunci când predăm despre CT1.0, elevii învață să împartă problema în mai multe părți și să scrie instrucțiuni clare pentru fiecare pas, înainte de a le implementa în aplicații precum Scratch sau în limbaje precum Python. În schimb, rezolvarea de problemele în CT2.0 se mută către o abordare bazată pe date¹. În loc să scrie instrucțiuni explicite, elevii învață să colecteze, să curețe, să eticheteze și să organizeze cantități mari de date relevante. Apoi folosesc aceste date pentru a antrena sisteme de învățare automată (Machine Learning - ML), care identifică tipare și creează modele capabile să genereze predicții și să rezolve probleme. De exemplu, în CT1.0, elevii ar putea crea un instrument care clasifică pisici folosind reguli de tipul „Dacă… atunci…” despre mustăți și urechi ascuțite. În CT2.0, ei ar folosi mai multe imagini cu pisici pentru a antrena un model care să le clasifice cu acuratețe. Deoarece datele sunt centrale în acest proces, calitatea datelor, evaluarea lor și prejudecățile din ele devin concepte critice: seturile de date defectuoase sau părtinitoare pot duce la rezultate care nu sunt de încredere sau sunt inechitabile. Aplicațiile moderne combină ambele abordări, și cea bazată pe reguli și cea bazată pe date — de la textele și imaginile generate cu IA, la aplicațiile de recunoaștere facială și recomandările de pe rețele sociale. Înțelegerea atât a CT1.0, cât și a CT2.0 le oferă elevilor încrederea de a lucra eficient cu aceste instrumente și de a fi participanți activi și creatori, nu doar consumatori pasivi, în societățile noastre tot mai bazate pe date2.\nÎnțelegerea corectitudinii\nCorectitudinea este un concept important în informatică și determină dacă un program funcționează așa cum s-a intenționat. În CT1.0, îi învățăm adesea pe elevi că această corectitudine se referă la faptul că un program este fie corect, fie incorect. Această abordare pune accent pe precizie: instrucțiunile trebuie să fie corecte, logice și să producă rezultatul așteptat. În CT1.0, programele bazate pe reguli presupun un nivel ridicat de transparență: fiecare instrucțiune este scrisă explicit și poate fi urmărită de la un capăt la altul, erorile pot fi identificate, iar corecțiile pot fi testate și implementate. În CT2.0, corectitudinea nu mai este definită rigid, un program nu mai poate fi catalogat doar ca fiind corect sau incorect. Rezultatele multor modele de învățare automată sunt predicții bazate pe probabilități, cu scoruri variabile de încredere1. De exemplu, un model de învățare automată ar putea clasifica o imagine a unei pisici cu un scor de încredere de 95%. Chiar și modelele de învățare automată bine antrenate, în ciuda faptului că sunt antrenate pe cantități mari de date, ar putea produce erori, în special cu date de intrare noi. De exemplu, o imagine cu o pisică ar putea fi clasificată greșit drept câine, cu un scor de încredere de 60%. Dezvoltatorii definesc care sunt nivelurile acceptabile de corectitudine atunci când proiectează și construiesc modele de învățare automată. Acest lucru presupune ca dezvoltatorii să ajusteze cu atenție procesul de antrenament și să stabilească praguri de încredere adecvate pentru a determina dacă o predicție este acceptabilă într-un anumite context. Pentru profesori, această schimbare în înțelegerea corectitudinii necesită dezvoltarea gândirii critice în rândul tinerilor în legătură cu instrumentele bazate pe date și sistemele AI. I-am putea îndruma pe elevi să pună întrebări mai profunde precum: „Cât de fiabilă este această predicție cu date noi?” sau „Ce prejudecăți ar putea exista în datele de antrenament?” Astfel, corectitudinea în CT2.0 nu se mai referă la un rezultat fix, ci devine un proces continuu de evaluare și rafinare a modelelor pentru a le îmbunătăți rezultatele în aplicațiile din viața reală. Această perspectivă asupra corectitudinii îi pregătește pe elevi nu doar să utilizeze IA, ci să și recunoască limitările și potențialele efecte negative ale rezultatelor generate de aceste sisteme.\nDepanarea\nDepanarea (debugging), este o altă practică ce ia forme diferite în CT1.0 și CT2.0. De exemplu, dacă un program bazat pe reguli, implementat în Scratch sau Python, nu funcționează cum trebuie, elevii pot afișa valorile variabilelor, pot seta puncte de oprire sau pot parcurge codul linie cu linie pentru a identifica eroarea. Datorită nivelului de transparență ridicat în astfel de programe, putem utiliza practici de depanare sistematice și structurate. Pe de altă pare, modelele de învățare automată sunt adesea văzute ca niște „cutii negre”3, iar această opacitate face depanarea mult mai dificilă. Modelele de învățare automată sunt rețele complicate, interconectate, cu miliarde de parametri care determină rezultatele și predicțiile, iar asta face imposibilă urmărirea lor pas cu pas. De exemplu, dacă un clasificator de imagini etichetează greșit o pisică drept câine, elevii pur și simplu nu au cum să găsească linia de cod care cauzează eroarea, deoarece nu există una. În schimb, depanarea în CT2.0 presupune analizarea și îmbunătățirea calității datelor de antrenament, reglarea variabilelor și a parametrilor și testarea cu un set divers de date pentru a identifica tipare în erori (de exemplu, pisicile cu urechi ascuțite sunt mai des clasificate greșit drept câini). Asta înseamnă că, în ceea ce privește depanarea, profesorii trebuie să treacă de la căutarea și identificarea erorilor din cod la a se concentra pe modul în care schimbările din date și parametrii pot afecta performanța sistemului.\nDe ce gândirea computațională 2.0 este importantă\nFără CT2.0, elevii de azi vor rămâne consumatori pasivi, în loc să fie participanți informați într-o lume tot mai influențată de AI și tehnologiile bazate pe date. Integrarea CT2.0 alături de gândirea computațională tradițională le oferă elevilor o înțelegere corectă a sistemelor informatice, inclusiv a diferențelor în modul în care sunt abordate rezolvarea de probleme, corectitudinea și depanarea. Acest lucru le va da încrederea să evalueze critic modelele de învățare automată, să înțeleagă cum sunt folosite datele de antrenament, să identifice potențialele prejudecăți din date și chiar să-și creeze propriile lor proiecte de învățare automată. Adoptarea CT2.0 face ca informatica să fie mai realistă și mai conectată la lumea reală, oferindu-le elevilor căi către viitoare cariere dincolo de programarea tradițională, în care literația AI este crucială.\nConcepte-cheie\nRezolvarea de probleme\n\nCT1.0 aplică abordări bazate pe reguli pentru a rezolva probleme, precum cele utilizate în Scratch și Python.\nCT2.0 aduce o schimbare spre o abordare bazată pe date pentru rezolvarea de probleme.\nEvaluarea modelelor, calitatea datelor și prejudecățile din date devin importante în CT2.0, întrucât datele eronate pot duce la rezultate inechitabile.\n\nCorectitudinea\n\nÎn CT1.0 învățăm despre corectitudine că este binară – programele produc sau nu produc rezultate corecte.\nÎn CT2.0 corectitudinea este măsurată pe niveluri – modelele de învățare automată generează predicții și scoruri de încredere.\n\nDepanarea\n\nÎn CT1.0, depanarea este structurată și transparentă. Erorile sunt remediate prin urmărirea execuției programului pas cu pas.\nÎn CT2.0, modelele de învățare automată sunt ca niște „cutii negre” opace. Problemele sunt identificate prin analiza datelor de intrare și a rezultatelor.\nAcest lucru necesită o schimbarea de mentalitate în ceea ce privește depanarea: trebuie să ne concentrăm pe îmbunătățirea datelor de antrenament, reglarea parametrilor și testarea cu seturi diverse de date.\n\nReferințe\nSource pdf\nFootnotes\n\n\nTedre, M., et al. (2021). CT 2.0. qr21_1 ↩ ↩2\n\n\nVartiainen, H., et al. (2021). Machine learning for middle schoolers: Learning through data-driven design. qr21_2 ↩\n\n\nHitron, T., et al. (2019). Can children understand machine learning concepts? The effect of uncovering black boxes. qr21_3 ↩\n\n\n","frontmatter":{"title":"Gândire Computațională 2.0","lang":"Romanian","translatedFrom":"[QR21](QR21.md)","aliases":["QR21_ro"],"draft":null}},"Quick-Reads/QR22":{"slug":"Quick-Reads/QR22","filePath":"Quick Reads/QR22.md","title":"The effects of anthropomorphisation on students' mental models of AI","links":["Quick-Reads/the-cc.io/qr22_1","Quick-Reads/the-cc.io/qr22_2","Quick-Reads/the-cc.io/qr22_4","Quick-Reads/the-cc.io/qr22_5","Quick-Reads/the-cc.io/qr22_6","Quick-Reads/the-cc.io/qr22_7","Quick-Reads/the-cc.io/qr22_8","Quick-Reads/the-cc.io/qr22_9"],"tags":[],"content":"As educators, our role is to help young people develop mental models that will let them navigate a world increasingly reliant on artificial intelligence (AI) systems. AI systems are often given human attributes, such as feelings, mental states, and behaviours1. The anthropomorphisation of AI is cemented by depictions in fiction — in movies, TV, and books — and news media. Media outlets often default to images of smiling human-like robots to illustrate stories of AI systems1. The language of the field is also inherently anthropomorphic, from the name artificial intelligence, to machine learning, having hallucinations, and wake words.\nThese descriptions may be taken literally if learners lack a robust established mental model about AI systems2. The language used to describe AI systems portrays them as capable of ‘thinking’ or ‘reasoning’, which misrepresents the processes used by these systems as being similar to human-like intelligence3. If you believe that AI systems can think, then you might also ascribe emotions to them. This leads to you viewing these machines as having intention and a moral character — further intensifying existing fears and misconceptions about the capabilities of these systems3\n\n\n                  \n                  Key concepts \n                  \n                \n\n\nAnthropomorphisation is the practice of assigning human-like characteristics and behaviours to non-human objects1.\nArtificial intelligence (AI) is often described using very humanfocused language.\nAnthropomorphising AI leads to misconceptions about how AI systems work and their current\ncapabilities, and creates a loss of agency from users3.\nEducators can avoid anthropomorphising AI systems by\n\nNot using AI as a countable noun as in “an AI”\nSwapping words like “listens”, “understands”, and “creates” with “records”, “analyses”, and “generates”\nUsing the term AI in the same way you would use “biology” or “cybersecurity”\n\n\n\n\nThe risks of anthropomorphisation\nIf young people see this technology as innately human-like, we run the risk of\nimpacting their…\n\nSense of agency: The intentional simplicity of AI use may lead students to think they have little or no control over its role and impact on their lives and choices. People may defer to the systems if they perceive them as smarter than they are4.\nSafety: When AI systems are seen as human, young people report feeling emotionally connected to them, which can open them up to influence and manipulation5.\nSocial connection: People are already more likely to anthropomorphise if they lack social connection in their lives or want to make sense of an unpredictable environment6.\nCuriosity: If AI systems are seen as human, it leads to a ‘black-box’ view of applications. This level of abstraction can put people off wanting to learn about how they work, making them perceive AI as ‘magic’7.\nBiases: When AI systems are perceived as human-like, then they are also viewed as ‘white’. This view of AI means many people of colour feel put off by AI agents8. Many AI systems are also anthropomorphised as female assistants, perpetuating stereotypes of women as subservient9.\n\nWhen anthropomorphisation works\nAnthropomorphising AI systems has benefits for developers in terms of adoption and trust. When users view tools as humanlike, they are far more receptive to integrating them into their\nlives and using them4, so developers of AI systems may have a vested interest in people viewing them that way.\nThere is evidence that anthropomorphising helps younger learners understand complex phenomena in science. Making systems more human than they are also allows us to tell\nstories about them, which can be helpful when learning complex concepts.\nOverall, the usefulness of anthropomorphisation is directly related to how close something is to actual intelligence. For example, it is helpful when learning about the tides, but when\nlearning about monkeys, it might lead to misconceptions2. AI systems are presented as extremely close to human intelligence, so anthropomorphisation is particularly dangerous.\nHow to avoid anthropomorphising AI systems\nTo help students develop mental models resilient enough to see through how AI systems are presented\nas human-like, you can:\n\nAvoid using AI as a countable noun. Instead of calling something “an AI”, use a qualifier like “an AI system”, “application”, or “model”. When using the term “AI”, use it in the same way you would use “biology” or “cybersecurity” — as a field of study and practice rather than a thing you can point at.\nAvoid using human language to describe the behaviour of AI applications. Use system based language instead. Replace words like “listens”, “understands”, and “creates” with “records”, “ processes”, and “generates”.\nDon’t give too much agency to an AI system when describing\nit. Instead of “the AI system learns” or “the machine learning (ML) model does”, put a human in the equation. For example, “AI developers trained the system to…” or “people use the ML model to…”.\n\n\nExamples\nHere are some practical examples of de-anthropomorphised descriptions of AI systems:\nSmart speaker\n“A smart speaker is activated with a phrase like ‘Hey Google’. It then records your voice and sends it to a computer over the internet.\nThis computer analyses the recording and predicts the response to your request, such as playing music or answering a question. The speaker receives the predicted answer, and plays it back to you.”\nA large language model (LLM)\n“A large language model (LLM) is an AI system that generates text in response to a user’s prompt. When a prompt is entered, the system breaks it down into smaller pieces and compares it to a vast dataset of text the LLM has been trained on. The LLM uses patterns and relationships within the training data to evaluate the prompt. A response is then generated by combining words and phrases predicted to be relevant.”\nReferences\nSource pdf\nFootnotes\n\n\nSalles, A., et al. (2020). Anthropomorphism in AI. qr22_1 ↩ ↩2 ↩3\n\n\nTang, X., &amp; Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. qr22_2 ↩ ↩2\n\n\nPlacani, A. (2024). Anthropomorphism in AI: hype and fallacy. qr22_3 ↩ ↩2 ↩3\n\n\nHuang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. qr22_4 ↩ ↩2\n\n\nWilliams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. qr22_5 ↩\n\n\nAlabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. qr22_6 ↩\n\n\nTedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. qr22_7 ↩\n\n\nCave, S., &amp; Dihal, K. (2020). The Whiteness of AI. qr22_8 ↩\n\n\nBarau, S. (2024). Deception, discrimination, and objectification: ethical issues of female AI agents. qr22_9 ↩\n\n\n","frontmatter":{"title":"The effects of anthropomorphisation on students' mental models of AI","fileOrder":22,"displayName":"22 - Anthropomorphisation","aliases":["Anthropomorphisation","QR22"],"draft":null}},"Quick-Reads/QR22_el":{"slug":"Quick-Reads/QR22_el","filePath":"Quick Reads/QR22_el.md","title":"Οι επιδράσεις του ανθρωπομορφισμού στα νοητικά μοντέλα των μαθητών σχετικά με το AI","links":["Quick-Reads/the-cc.io/qr22_1","Quick-Reads/the-cc.io/qr22_2","Quick-Reads/the-cc.io/qr22_4","Quick-Reads/the-cc.io/qr22_5","Quick-Reads/the-cc.io/qr22_6","Quick-Reads/the-cc.io/qr22_7","Quick-Reads/the-cc.io/qr22_8","Quick-Reads/the-cc.io/qr22_9"],"tags":[],"content":"Ως εκπαιδευτικοί, ο ρόλος μας είναι να βοηθήσουμε τους νέους να αναπτύξουν νοητικά μοντέλα που θα τους επιτρέπουν να πλοηγούνται σε έναν κόσμο που βασίζεται ολοένα και περισσότερο σε συστήματα τεχνητής νοημοσύνης (AI). Στα συστήματα AI αποδίδονται συχνά ανθρώπινα χαρακτηριστικά, όπως συναισθήματα, νοητικές καταστάσεις και συμπεριφορές1. Ο ανθρωπομορφισμός του AI εδραιώνεται μέσα από τις απεικονίσεις στη λογοτεχνία, σε ταινίες, τηλεόραση και βιβλία καθώς και στα ειδησεογραφικά μέσα. Τα μέσα συχνά καταφεύγουν σε εικόνες χαμογελαστών, ανθρωπόμορφων ρομπότ για να εικονογραφήσουν ιστορίες σχετικές με συστήματα AI1. Η γλώσσα του πεδίου είναι επίσης εκ φύσεως ανθρωπομορφική, από τον όρο τεχνητή νοημοσύνη μέχρι τη μηχανική μάθηση, τις παραισθήσεις και τις λέξεις αφύπνισης.\nΑυτές οι περιγραφές μπορεί να κατανοηθούν κυριολεκτικά αν οι εκπαιδευόμενοι δε διαθέτουν ένα ισχυρό και εδραιωμένο νοητικό μοντέλο για τα συστήματα AI2. Η γλώσσα που χρησιμοποιείται για να περιγράψει τα συστήματα AI τα παρουσιάζει ως ικανά να «σκέφτονται» ή να «συλλογίζονται», γεγονός που παραποιεί τις διαδικασίες που χρησιμοποιούν αυτά τα συστήματα παρουσιάζοντάς τες ως παρόμοιες με την ανθρώπινη νοημοσύνη3. Αν πιστεύετε ότι τα συστήματα AI μπορούν να σκέφτονται, τότε ίσως να τους αποδίδετε και συναισθήματα. Αυτό οδηγεί στο να θεωρείτε ότι αυτές οι μηχανές έχουν πρόθεση και ηθικό χαρακτήρα εντείνοντας περαιτέρω τους υπάρχοντες φόβους και τις παρανοήσεις σχετικά με τις ικανότητες αυτών των συστημάτων AI3\n\n\n                  \n                  Βασικές έννοιες \n                  \n                \n\n\nΟ ανθρωπομορφισμός είναι η πρακτική της απόδοσης ανθρώπινων χαρακτηριστικών και συμπεριφορών σε μη ανθρώπινα αντικείμενα1.\nΗ τεχνητή νοημοσύνη (AI) συχνά περιγράφεται με γλώσσα που εστιάζει έντονα στον άνθρωπο.\nΟ ανθρωπομορφισμός του AI οδηγεί σε παρανοήσεις σχετικά με το πώς λειτουργούν τα συστήματα AI και τις τρέχουσες ικανότητές τους, ενώ παράλληλα δημιουργεί απώλεια αυτενέργειας από τους χρήστες3.\nΟι εκπαιδευτικοί μπορούν να αποφύγουν τον ανθρωπομορφισμό των συστημάτων AI με το\n\nΝα μη χρησιμοποιούν το AI ως αριθμήσιμο ουσιαστικό, όπως «ένα AI»\nΝα αντικαθιστούν λέξεις όπως «ακούει», «κατανοεί» και «δημιουργεί» με τις λέξεις «καταγράφει», «αναλύει» και «παράγει»\nΝα χρησιμοποιούν τον όρο AI με τον ίδιο τρόπο που θα χρησιμοποιούσαν τον όρο «βιολογία» ή «κυβερνοασφάλεια»\n\n\n\n\nΟι κίνδυνοι του ανθρωπομορφισμού\nΑν οι νέοι αντιλαμβάνονται αυτήν την τεχνολογία ως εγγενώς ανθρώπινη, διατρέχουμε τον κίνδυνο να επηρεαστεί η…\n\nΑίσθηση αυτενέργειας: Η εσκεμμένη απλότητα στη χρήση του AI μπορεί να οδηγήσει τους μαθητές(-τριες) να πιστεύουν ότι έχουν μικρό ή καθόλου έλεγχο στον ρόλο και την επίδρασή του στη ζωή και στις επιλογές τους. Οι άνθρωποι μπορεί να υποτάσσονται στα συστήματα αν τα αντιλαμβάνονται ως εξυπνότερα από τους ίδιους4.\nΑσφάλεια: Όταν τα συστήματα AI εκλαμβάνονται ως ανθρώπινα, οι νέοι αναφέρουν ότι αισθάνονται συναισθηματικά δεμένοι μαζί τους, γεγονός που μπορεί να τους καταστήσει ευάλωτους σε επιρροή και χειραγώγηση5.\nΚοινωνική σύνδεση: Οι άνθρωποι είναι ήδη πιο πιθανό να καταφεύγουν στον ανθρωπομορφισμό αν τους λείπει κοινωνική σύνδεση στη ζωή τους ή αν επιδιώκουν να κατανοήσουν ένα απρόβλεπτο περιβάλλον6.\nΠεριέργεια: Αν τα συστήματα AI εκλαμβάνονται ως ανθρώπινα, αυτό οδηγεί σε μια αντίληψη «λειτουργίας των εφαρμογών με αδιαφανή ή ακατανόητο τρόπο». Αυτό το επίπεδο αφαίρεσης μπορεί να αποθαρρύνει τους ανθρώπους από το να θέλουν να μάθουν πώς λειτουργούν, κάνοντάς τους να αντιλαμβάνονται το AI ως «μαγεία» 7.\nΠροκαταλήψεις: Όταν τα συστήματα AI εκλαμβάνονται ως ανθρωπόμορφα, τότε συχνά αντιμετωπίζονται και ως «λευκά» (φυλετική ταυτότητα του λευκού). Αυτή η αντίληψη για την AI σημαίνει ότι πολλοί έγχρωμοι άνθρωποι αισθάνονται αποξενωμένοι από τους πράκτορες AI8. Πολλά συστήματα AI διαθέτουν ανθρωπομορφικές ιδιότητες επίσης ως γυναίκες βοηθοί, διαιωνίζοντας τα στερεότυπα των γυναικών ως υποτακτικών όντων9.\n\nΌταν ο ανθρωπομορφισμός λειτουργεί\nΟ ανθρωπομορφισμός των συστημάτων AI έχει οφέλη για τους προγραμματιστές όσον αφορά την υιοθέτηση και την εμπιστοσύνη. Όταν οι χρήστες βλέπουν τα εργαλεία ως ανθρωπόμορφα, είναι πολύ πιο δεκτικοί στο να τα εντάξουν στη ζωή τους και να τα χρησιμοποιήσουν4, οπότε οι προγραμματιστές συστημάτων AI μπορεί να έχουν συμφέρον να τα αντιλαμβάνονται οι άνθρωποι με αυτόν τον τρόπο.\nΥπάρχουν ενδείξεις ότι ο ανθρωπομορφισμός βοηθά τους νεότερους εκπαιδευόμενους να κατανοήσουν πολύπλοκα φαινόμενα στις επιστήμες. Το να παρουσιάζουμε τα συστήματα ως πιο ανθρώπινα απ’ ό,τι είναι μας επιτρέπει επίσης να αφηγούμαστε ιστορίες γι’ αυτά, κάτι που μπορεί να αποδειχθεί χρήσιμο κατά την εκμάθηση πολύπλοκων εννοιών.\nΣυνολικά, η χρησιμότητα του ανθρωπομορφισμού σχετίζεται άμεσα με το πόσο κοντά βρίσκεται κάτι στην πραγματική νοημοσύνη. Για παράδειγμα, είναι χρήσιμο κατά την εκμάθηση για τις παλίρροιες, αλλά όταν πρόκειται για την εκμάθηση σχετικά με τους πιθήκους, μπορεί να οδηγήσει σε παρανοήσεις2. Τα συστήματα AI παρουσιάζονται ως εξαιρετικά κοντά στην ανθρώπινη νοημοσύνη, επομένως ο ανθρωπομορφισμός είναι ιδιαίτερα επικίνδυνος.\nΠώς να αποφύγουμε τον ανθρωπομορφισμό των συστημάτων AI\nΓια να βοηθήσετε τους μαθητές να αναπτύξουν νοητικά μοντέλα αρκετά ανθεκτικά ώστε να διαβλέπουν τον τρόπο με τον οποίο τα συστήματα AI παρουσιάζονται ως ανθρωπόμορφα, μπορείτε να:\n\nΑποφεύγετε να χρησιμοποιείτε το AI ως αριθμήσιμο ουσιαστικό. Αντί να αποκαλείτε κάτι «AI», χρησιμοποιήστε έναν προσδιορισμό όπως «σύστημα AI», «εφαρμογή» ή «μοντέλο». Όταν χρησιμοποιείτε τον όρο «AI», να τον χρησιμοποιείτε με τον ίδιο τρόπο που θα χρησιμοποιούσατε τον όρο «βιολογία» ή «κυβερνοασφάλεια», ως πεδίο μελέτης και πρακτικής και όχι ως κάτι, το οποίο μπορείτε να δείξετε με το δάχτυλο.\nΑποφεύγετε να χρησιμοποιείτε ανθρώπινη γλώσσα για να περιγράψετε τη συμπεριφορά των εφαρμογών AI. Χρησιμοποιείτε αντ’ αυτού γλώσσα βασισμένη στο σύστημα. Αντικαταστήστε λέξεις όπως «ακούει», «κατανοεί» και «δημιουργεί» με τις λέξεις «καταγράφει», «επεξεργάζεται» και «παράγει».\nΜην αποδίδετε υπερβολική αυτενέργεια σε ένα σύστημα AI όταν το περιγράφετε. Αντί για «το σύστημα AI μαθαίνει» ή «το μοντέλο μηχανικής μάθησης (ML) κάνει», βάλτε έναν άνθρωπο στην εξίσωση. Για παράδειγμα, «οι προγραμματιστές AI εκπαίδευσαν το σύστημα να…» ή «οι άνθρωποι χρησιμοποιούν το μοντέλο ML για να…».\n\n\n\nΠαραδείγματα\nΑκολουθούν ορισμένα πρακτικά παραδείγματα αποανθρωπομορφοποιημένων περιγραφών των συστημάτων AI:\nΈξυπνο ηχείο\n«Ένα έξυπνο ηχείο ενεργοποιείται με μια φράση όπως «Hey Google».» Στη συνέχεια, καταγράφει τη φωνή σας και τη στέλνει σε έναν υπολογιστή μέσω του διαδικτύου.\nΑυτός ο υπολογιστής αναλύει την ηχογράφηση και προβλέπει την απόκριση στο αίτημά σας, όπως η αναπαραγωγή μουσικής ή η απάντηση σε μια ερώτηση. Το ηχείο λαμβάνει την προβλεπόμενη απάντηση και την αναπαράγει σε εσάς.»\nΈνα μεγάλο γλωσσικό μοντέλο (LLM)\n«Ένα μεγάλο γλωσσικό μοντέλο (LLM) είναι ένα σύστημα AI που παράγει κείμενο ως απόκριση στην ερώτηση ενός χρήστη.» Όταν εισάγεται μια ερώτηση, το σύστημα τη διασπά σε μικρότερα τμήματα και τη συγκρίνει με ένα τεράστιο σύνολο δεδομένων κειμένου στο οποίο έχει εκπαιδευτεί το LLM. Το LLM χρησιμοποιεί πρότυπα και συσχετίσεις μέσα στα δεδομένα εκπαίδευσης για να αξιολογήσει την ερώτηση. Στη συνέχεια παράγεται μια απάντηση με τον συνδυασμό λέξεων και φράσεων που προβλέπεται ότι είναι σχετικές.»\nΒιβλιογραφικές αναφορές\nΑρχείο-πηγή σε μορφή pdf\nFootnotes\n\n\nSalles, A., et al. (2020). Anthropomorphism in AI. qr22_1 ↩ ↩2 ↩3\n\n\nTang, X., &amp; Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. qr22_2 ↩ ↩2\n\n\nPlacani, A. (2024). Ανθρωπομορφισμός στο AI: υπερβολική διαφήμιση και πλάνη. qr22_3 ↩ ↩2 ↩3\n\n\nHuang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. qr22_4 ↩ ↩2\n\n\nWilliams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. qr22_5 ↩\n\n\nAlabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. qr22_6 ↩\n\n\nTedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. qr22_7 ↩\n\n\nCave, S., &amp; Dihal, K. (2020). The Whiteness of AI. qr22_8 ↩\n\n\nBarau, S. (2024). Deception, discrimination, and objectification: ethical issues of CMake qr22_9 ↩\n\n\n","frontmatter":{"title":"Οι επιδράσεις του ανθρωπομορφισμού στα νοητικά μοντέλα των μαθητών σχετικά με το AI","lang":"Greek","translatedFrom":"[QR22](../QR22.md)","aliases":["QR22_el"],"draft":null}},"Quick-Reads/QR22_es":{"slug":"Quick-Reads/QR22_es","filePath":"Quick Reads/QR22_es.md","title":"Efectos de la antropomorfización en los modelos mentales de los estudiantes acerca de la IA","links":["Quick-Reads/the-cc.io/qr22_1","Quick-Reads/the-cc.io/qr22_2","Quick-Reads/the-cc.io/qr22_4","Quick-Reads/the-cc.io/qr22_5","Quick-Reads/the-cc.io/qr22_6","Quick-Reads/the-cc.io/qr22_7","Quick-Reads/the-cc.io/qr22_8","Quick-Reads/the-cc.io/qr22_9"],"tags":[],"content":"Como docentes, nuestro papel es ayudar a los y las adolescentes a desarrollar modelos mentales que les permitan navegar en un mundo que depende cada vez más de los sistemas de inteligencia artificial (IA). A menudo, a los sistemas de IA se les asignan atributos humanos, como sentimientos, estados mentales y comportamientos1. La antropomorfización de la IA está consolidada por las representaciones de obras de ficción (películas, televisión y libros) y de los medios de comunicación. Los medios de comunicación suelen utilizar imágenes de robots sonrientes con apariencia humana para ilustrar historias relacionadas con los sistemas de IA1. El lenguaje que se emplea en este campo también es inherentemente antropomórfico, desde el nombre de inteligencia artificial hasta términos como aprendizaje automático, alucinaciones o palabras de activación.\nEstas descripciones pueden interpretarse de forma literal si el alumnado carece de un modelo mental sólido y establecido sobre los sistemas de IA2. El lenguaje utilizado para describir los sistemas de IA los retrata como si fueran capaces de “pensar” o “razonar”, lo cual tergiversa los procesos que utilizan estos sistemas, haciéndolos parecer similares a la inteligencia humana3. Si creemos que los sistemas de IA pueden pensar, entonces también podríamos atribuirles emociones. Esto nos lleva a ver a estas máquinas como si tuvieran intención y un carácter moral, lo que intensifica aún más los miedos y conceptos erróneos existentes sobre las capacidades de estos sistemas.3\n\n\n                  \n                  Conceptos clave \n                  \n                \n\n\nLa antropomorfización es la práctica de asignar características y comportamientos propios de los seres humanos a objetos no humanos1.\nLa inteligencia artificial (IA) a menudo se describe utilizando un lenguaje muy centrado en lo humano.\nLa antropomorfización de la inteligencia artificial genera conceptos erróneos sobre cómo funcionan\nlos sistemas de IA y sus capacidades actuales, además de provocar una pérdida de capacidad de decisión por parte de los usuarios3.\nEstas son las acciones que pueden llevar a cabo los docentes para evitar la antropomorfización de los sistemas de IA:\n\nNo usar IA como sustantivo contable, como en la frase “una IA”.\nReemplazar palabras como “escucha”, “entiende” y “crea” por “registra”, “procesa” y “genera”.\nUtilizar el término IA de la misma manera que utilizarías “biología” o “ciberseguridad”.\n\n\n\n\nRiesgos de la antropomorfización\nSi los y las adolescentes perciben esta tecnología como intrínsecamente similar a los seres humanos, corremos el riesgo de que ello afecte a su…\n\nSentido de capacidad de decisión: la simplicidad intencional del uso de la IA puede llevar al alumnado a pensar que tienen poco o ningún control sobre su función y su impacto en sus vidas y decisiones. Las personas pueden someterse a los sistemas si los perciben como más inteligentes de lo que son4.\nSeguridad: cuando los sistemas de IA son vistos como humanos, los y las adolescentes crean conexiones emocionales hacia ellos, lo que puede aumentar la exposición a influencias y manipulaciones5.\nConexión social: las personas son más propensas a antropomorfizar estos sistemas si carecen de conexión social en sus vidas o quieren darle sentido a un entorno impredecible6.\nCuriosidad: la percepción de los sistemas de IA como humanos puede llevar a una falta de compresión sobre su funcionamiento y sus aplicaciones. Este nivel de abstracción puede disuadir a las personas de querer aprender sobre su funcionamiento y fomentar su percepción como “magia”7.\nSesgos: cuando los sistemas de IA se perciben como similares a los seres humanos, también suelen ser vistos como “blancos”. Esta percepción de la IA hace que muchas personas de color sientan rechazo por parte de los agentes de IA8. Muchos sistemas de IA también están antropomorfizados como asistentes femeninas, lo que perpetúa el estereotipo de la sumisión de la mujer9.\n\nCasos en los que la antropomorfización funciona\nLa antropomorfización de los sistemas de IA tiene beneficios para los desarrolladores en términos de adopción y confianza. Cuando los usuarios perciben las herramientas como similares a los seres humanos, son mucho más receptivos a integrarlas en sus vidas y utilizarlas4, por lo que los desarrolladores de sistemas de IA pueden tener un interés particular en lograr que la gente los vea de esa manera.\nExisten evidencias de que la antropomorfización ayuda a los y las estudiantes a comprender fenómenos complejos en la ciencia. Hacer que los sistemas parezcan más humanos de lo que realmente son también\nnos permite contar historias sobre ellos, lo cual puede resultar útil para aprender conceptos complejos.\nEn general, la utilidad de la antropomorfización está directamente relacionada con lo cerca que está algo de la inteligencia real. Por ejemplo, es útil para aprender sobre las mareas, pero\npuede llevar a malosentendidos en el aprendizaje sobre los monos2. Los sistemas de IA se presentan como extremadamente cercanos a la inteligencia humana, por lo que la antropomorfización es particularmente peligrosa.\nCómo evitar la antropomorfización de los sistemas de IA\nPara ayudar al alumnado a desarrollar modelos mentales lo suficientemente sólidos que les permitan\nidentificar cómo se presentan los sistemas de IA como similares a los seres humanos, puedes hacer lo siguiente:\n\nEvitar utilizar IA como sustantivo contable. En lugar de decir “una IA”, utiliza calificadores como “sistema de IA”, “aplicación” o “modelo”. Cuando uses el término “IA”, hazlo de la misma manera que los términos “biología” o “ciberseguridad”: como un campo de estudio y práctica, en lugar de como algo tangible.\nEvita utilizar lenguaje humano para describir el comportamiento de las aplicaciones de IA. Utiliza en su lugar un lenguaje propio de los sistemas. Reemplaza palabras como “escucha”, “entiende” y “crea” por “registra”, “procesa” y “genera”.\nNo atribuyas demasiada capacidad de acción o control a los sistemas de IA cuando\nlos describas. En lugar de decir “el sistema de IA aprende” o “el modelo de aprendizaje automático (ML) lo hace”, coloca a un humano en la ecuación. Por ejemplo, “los desarrolladores de IA entrenaron el sistema para…” o “las personas usan el modelo de aprendizaje automático para…”.\n\n\n\nEjemplos\nA continuación se presentan algunos ejemplos prácticos de descripciones de sistemas de IA desantropomorfizadas:\nAltavoz inteligente\n“Los altavoces inteligentes se activan con frases como ‘Hola Google’. A continuación, graban nuestra voz y la envían a un equipo informático a través de Internet.\nEste equipo analiza la grabación y predice la respuesta a nuestras solicitudes, como, por ejemplo, reproducir música o responder una pregunta. A continuación, el altavoz recibe la respuesta prevista y la reproduce”.\nModelos de lenguaje de gran tamaño (LLM)\n“Un modelo de lenguaje de gran tamaño (LLM) es un sistema de IA que genera texto en respuesta a las instrucciones de los usuarios. Cuando se introduce una instrucción, el sistema la divide en partes más pequeñas y las compara con un amplio conjunto de datos de texto con el que se entrenó el LLM. El LLM utiliza los patrones y las relaciones existentes en los datos de entrenamiento para evaluar las solicitudes. A continuación, se genera una respuesta que combina palabras y frases que se prevé que sean relevantes”.\nReferencias\nSource pdf\nFootnotes\n\n\nSalles, A., et al. (2020). Anthropomorphism in AI. qr22_1 ↩ ↩2 ↩3\n\n\nTang, X., &amp; Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. qr22_2 ↩ ↩2\n\n\nPlacani, A. (2024). Anthropomorphism in AI: hype and fallacy. qr22_3 ↩ ↩2 ↩3\n\n\nHuang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. qr22_4 ↩ ↩2\n\n\nWilliams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. qr22_5 ↩\n\n\nAlabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. qr22_6 ↩\n\n\nTedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. qr22_7 ↩\n\n\nCave, S., &amp; Dihal, K. (2020). The Whiteness of AI. qr22_8 ↩\n\n\nBarau, S. (2024). Deception, discrimination, and objectification: ethical issues of female AI agents. qr22_9 ↩\n\n\n","frontmatter":{"title":"Efectos de la antropomorfización en los modelos mentales de los estudiantes acerca de la IA","lang":"Spanish","translatedFrom":"[QR22](../QR22.md)","aliases":["QR22_el"],"draft":null}},"Quick-Reads/QR22_lt":{"slug":"Quick-Reads/QR22_lt","filePath":"Quick Reads/QR22_lt.md","title":"Antropomorfizacijos poveikis mokinių mąstymo DI modeliams","links":["Quick-Reads/the-cc.io/qr22_1","Quick-Reads/the-cc.io/qr22_2","Quick-Reads/the-cc.io/qr22_4","Quick-Reads/the-cc.io/qr22_5","Quick-Reads/the-cc.io/qr22_6","Quick-Reads/the-cc.io/qr22_7","Quick-Reads/the-cc.io/qr22_8","Quick-Reads/the-cc.io/qr22_9"],"tags":[],"content":"Mūsų, kaip pedagogų, vaidmuo yra padėti jauniems žmonėms susikurti mąstymo modelius, kurie leistų jiems orientuotis pasaulyje, vis labiau priklausančiame nuo dirbtinio intelekto (DI) sistemų. Dirbtinio intelekto sistemoms dažnai priskiriamos žmogiškos savybės, pvz., jausmai, psichinė būsena ir elgesys1. DI antropomorfizaciją įtvirtina jo vaizdavimas grožinėje literatūroje – filmuose, televizijoje ir knygose – bei žiniasklaidoje. Žiniasklaidos priemonės dažnai iliustruoja istorijas apie dirbtinio intelekto sistemas, naudodamos besišypsančių, į žmones panašių robotų vaizdus1. Šios srities kalba taip pat yra iš esmės antropomorfinė – nuo dirbtinio intelekto pavadinimo iki mašininio mokymosi, haliucinacijų ir „woke“ kultūrai būdingų žodžių.\nŠie apibūdinimai gali būti suprantami pažodžiui, jei besimokantieji neturi tvirto nusistovėjusio mąstymo modelio apie dirbtinio intelekto sistemas2. Dirbtinio intelekto sistemoms apibūdinti vartojama kalba vaizduoja jas kaip gebančias „mąstyti“ arba „samprotauti“, o tai klaidingai pristato šių sistemų pasitelkiamus procesus kaip panašius į žmogaus intelektą3. Jei tikite, kad DI sistemos gali mąstyti, tuomet galite joms priskirti ir emocijas. Dėl to galite pradėti laikyti šias mašinas turinčiomis tikslus ir moralinš charakterį – tai dar labiau sustiprina egzistuojančias baimes ir klaidingas nuomones apie šių sistemų galimybes3\n\n\n                  \n                  Pagrindinės sąvokos \n                  \n                \n\n\nAntropomorfizacija – tai praktika, kai nežmogiškiems objektams priskiriamos žmogui būdingos savybės ir elgesys1.\nDirbtinio intelekto (DI) sąvoka dažnai apibūdinama kaip labai orientuota į žmogų.\nAntropomorfizuojant DI susidaro klaidingas supratimas apie DI sistemų veikimą ir jų dabartines\ngalimybes, taip pat prarandama vartotojų veiksmų laisvė3.\nPedagogai gali išvengti DI sistemų antropomorfizavimo:\n\nNenaudojami DI kaip skaičiuotinio daiktavardžio\nKeisdami tokius žodžius, kaip „klausosi“, „supranta“ ir „kuria“, į „įrašo“, „apdoroja“ ir „generuoja“\nVartodami sąvoką DI taip pat, kaip ir sąvoką „biologija“ arba „kibernetinis saugumas“\n\n\n\n\nAntropomorfizacijos rizika\nJei jaunuoliai šią technologiją laiko iš prigimties žmogiška, rizikuojame paveikti jų…\n\nVeiksmų laisvę. Sąmoningas DI naudojimo paprastumas gali sudaryti mokiniams įspūdį, kad jie mažai arba visai nekontroliuoja jo vaidmens ir poveikio savo gyvenimui bei pasirinkimams. Žmonės gali nusileisti sistemoms manydami, kad jos yra protingesnės nei yra iš tikrųjų4.\nSaugumą. Kai DI sistemos prilyginamos žmonėms, jaunuoliai teigia jaučiantys su jomis emocinį ryšį, o tai gali padaryti juos pažeidžiamus įtakai ir manipuliavimui5.\nSocialiniai ryšiai. Žmonės yra labiau linkę antropomorfizuoti, jei jiems trūksta socialinio ryšio gyvenime arba jie nori suprasti aplinką, kuri yra mažai nuspėjama6.\nSmalsumą. Jei DI sistemos prilyginamos žmonėms, tai veda prie „juodosios dėžės“ požiūrio į programas. Toks apibendrinimas gali atgrasyti žmones nuo noro sužinoti, kaip DI veikia, ir suvokti DI kaip „magiją“7.\nŠališkumą. Kai DI sistemos prilyginamos žmonėms, laikoma, kad jos yra „baltaodės“. Toks požiūris į DI reiškia, kad daugelis spalvotųjų žmonių jaučiasi atstumti DI priemonių8. Daugelis DI sistemų taip pat yra antropomorfizuojamos kaip moterys asistentės, taip įtvirtinant stereotipus, jog moterys iš prigimties yra pavaldžios9.\n\nKada antropomorfizacija yra naudinga\nDI sistemų antropomorfizavimas yra naudingas kūrėjams dėl sistemų diegimo ir pasitikėjimo. Kai vartotojai įrankius vertina kaip panašius į žmones, jie yra daug labiau linkę juos įtraukti į savo\ngyvenimą ir naudotis4, todėl DI sistemų kūrėjai gali būti suinteresuoti, kad žmonės į juos žiūrėtų būtent taip.\nEgzistuoja įrodymų, kad antropomorfizavimas padeda jaunesniems besimokantiesiems suprasti sudėtingus mokslo reiškinius. Prilygindami sistemas žmonėms labiau nei yra iš tikrųjų, taip pat galime papasakoti apie jas\nistorijų, kurios gali būti naudingos mokantis sudėtingų sąvokų.\nApskritai antropomorfizacijos nauda yra tiesiogiai susijusi su tuo, kiek tam tikras reiškinys yra artimas tikrajam intelektui. Pavyzdžiui, tai naudinga mokantis apie potvynius ir atoslūgius, bet mokantis apie beždžiones, tai gali suklaidinti2. DI sistemos pateikiamos kaip itin artimos žmogaus intelektui, todėl antropomorfizacija yra ypač pavojinga.\nKaip išvengti DI sistemų antropomorfizavimo\nNorėdami padėti mokiniams sukurti pakankamai atsparius mąstymo modelius, leisiančius suprasti, kaip DI sistemos tapatinamos\nsu žmonėmis:\n\nVenkite vartoti DI kaip skaičiuotinį daiktavardį. Užuot vadinę ką nors „DI“, naudokite tokį apibrėžimą, kaip „DI sistema“, „programa“ arba „modelis“. Sąvoką „DI“ vartokite taip pat, kaip ir sąvoką „biologija“ ar „kibernetinis saugumas“ – kaip mokslo ir praktikos sritį, o ne kaip dalyką, į kurį galite parodyti pirštu.\nApibūdindami DI programų veikimą venkite kalbos, kuria apibūdinami žmogaus veiksmai. Vietoj to naudokite sistemoms būdingą kalbą. Tokius žodžius, kaip „klausosi“, „supranta“ ir „kuria“, pakeiskite žodžiais „įrašo“, „apdoroja“ ir „generuoja“.\nApibūdindami DI sistemą, nesuteikite jai per daug laisvės. Užuot sakę „DI sistema mokosi“ arba „mašininio mokymosi (ML) modelis atlieka“ nepamirškite paminėti ir žmogaus. Pavyzdžiui, sakykite: „DI kūrėjai apmokė sistemą…“ arba „žmonės naudoja MM modelį, kad…“.\n\n\n\nPavyzdžiai\nŠtai keletas praktinių deantropomorfizuotų DI sistemų aprašymų pavyzdžių:\nIšmanusis garsiakalbis\n„Išmanusis garsiakalbis aktyvuojamas ištarus tokią frazę, kaip „Ei, Google“. Tada jis įrašo jūsų balsą ir internetu siunčia jį į kompiuterį.\nŠis kompiuteris analizuoja įrašą ir numato atsakymą į jūsų užklausą, pavyzdžiui, groti muziką ar atsakyti į klausimą. Garsiakalbis gauna numatomą atsakymą ir jį jums atkuria.“\nDidysis kalbos modelis (DKM)\n„Didysis kalbos modelis (DKM) yra DI sistema, kuri generuoja tekstą reaguodama į vartotojo užklausą. Įvedus užklausą sistema ją suskaido į mažesnes dalis ir palygina su dideliu teksto duomenų rinkiniu, kuriuo buvo apmokytas DKM. DKM naudoja apmokymo duomenų modelius ir jų ryšius, kad įvertintų užklausą. Tada atsakymas generuojamas derinant žodžius ir frazes, kurios, kaip numanoma, yra aktualios.“\nŠaltiniai\nŠaltinio pdf\nFootnotes\n\n\nSalles, A., et al. (2020). Anthropomorphism in AI. qr22_1 ↩ ↩2 ↩3\n\n\nTang, X., Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. qr22_2 ↩ ↩2\n\n\nPlacani, A. (2024). Anthropomorphism in AI: hype and fallacy. qr22_3 ↩ ↩2 ↩3\n\n\nHuang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. qr22_4 ↩ ↩2\n\n\nWilliams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. qr22_5 ↩\n\n\nAlabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. qr22_6 ↩\n\n\nTedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. qr22_7 ↩\n\n\nCave, S., Dihal, K. (2020). The Whiteness of AI. qr22_8 ↩\n\n\nBarau, S. (2024). Deception, discrimination, and objectification: ethical issues of female AI agents. qr22_9 ↩\n\n\n","frontmatter":{"title":"Antropomorfizacijos poveikis mokinių mąstymo DI modeliams","lang":"Lithuaniun","translatedFrom":"[QR22](../QR22.md)","aliases":["QR22_it"],"draft":null}},"Quick-Reads/QR22_lv":{"slug":"Quick-Reads/QR22_lv","filePath":"Quick Reads/QR22_lv.md","title":"Antropomorfizācijas ietekme uz studentu mentālajiem mākslīgā intelekta modeļiem","links":["tags/Liels","Quick-Reads/the-cc.io/qr22_1","Quick-Reads/the-cc.io/qr22_2","Quick-Reads/the-cc.io/qr22_4","Quick-Reads/the-cc.io/qr22_5","Quick-Reads/the-cc.io/qr22_6","Quick-Reads/the-cc.io/qr22_7","Quick-Reads/the-cc.io/qr22_8","Quick-Reads/the-cc.io/qr22_9"],"tags":["Liels"],"content":"Kā pedagogiem, mūsu uzdevums ir palīdzēt jauniešiem attīstīt mentālos modeļus, kas viņiem ļaus orientēties pasaulē, kas arvien vairāk paļaujas uz mākslīgā intelekta (MI) sistēmām. Mākslīgā intelekta sistēmām bieži tiek piešķirtas cilvēciskas īpašības, piemēram, jūtas, garīgie stāvokļi un uzvedība1. Mākslīgā intelekta antropomorfizāciju nostiprina attēlojumi daiļliteratūrā — filmās, TV un grāmatās —, kā arī ziņu medijos. Mediji bieži vien pēc noklusējuma izmanto smaidošu, cilvēkveidīgu robotu attēlus, lai ilustrētu stāstus par mākslīgā intelekta sistēmām1. Arī nozares valoda pēc savas būtības ir antropomorfiska, sākot ar nosaukumu mākslīgais intelekts un beidzot ar mašīnmācīšanos, halucinācijām un modināšanas vārdiem.\nŠos aprakstus var uztvert burtiski, ja studentiem trūkst stabila, izveidota mentālā modeļa par mākslīgā intelekta sistēmām2. Mākslīgā intelekta sistēmu aprakstīšanai izmantotā valoda tās attēlo kā spējīgas “domāt” vai “spriest”, kas maldīgi attēlo šo sistēmu izmantotos procesus kā līdzīgus cilvēkam līdzīgam intelektam3. Ja jūs uzskatāt, ka mākslīgā intelekta sistēmas spēj domāt, tad jūs varētu tām piedēvēt arī emocijas. Tas liek jums uzskatīt šīs mašīnas par tādām, kurām ir nodoms un morāls raksturs, vēl vairāk pastiprinot esošās bailes un nepareizos priekšstatus par šo sistēmu iespējām3\n\n\n                  \n                  Galvenie jēdzieni \n                  \n                \n\n\nAntropomorfizācija ir prakse, ar kuru objektiem, kas nav cilvēki, tiek piešķirtas cilvēkam līdzīgas īpašības un uzvedība1.\nMākslīgais intelekts (MI) bieži tiek aprakstīts, izmantojot ļoti uz cilvēkam orientētu valodu.\nMākslīgā intelekta antropomorfizācija rada maldīgus priekšstatus par mākslīgā intelekta sistēmu darbību un to pašreizējām\niespējām, kā arī zaudē lietotāju rīcībspēju3.\nPedagogi var izvairīties no mākslīgā intelekta sistēmu antropomorfizācijas,\n\nNelietot MI kā skaitāmu lietvārdu, kā tas ir vārdos “MI”\nVārdu, piemēram, “klausās”, “saprot” un “rada”, aizstāšana ar vārdiem “reģistrē”, “analizē” un “ģenerē”\nLietojot terminu MI tāpat kā “bioloģija” vai “kiberdrošība”\n\n\n\n\nAntropomorfizācijas riski\nJa jaunieši uzskatīs šo tehnoloģiju par dabiski cilvēcisku, mēs riskējam ietekmēt viņu…\n\nRīcības brīvības sajūta: Mākslīgā intelekta izmantošanas apzinātā vienkāršība var radīt skolēniem domu, ka viņiem ir maza vai nekāda kontrole pār tā lomu un ietekmi uz viņu dzīvi un izvēlēm. Cilvēki var pakļauties sistēmām, ja tās uzskata par viedākām, nekā patiesībā tās ir4.\nDrošība: Kad mākslīgā intelekta sistēmas tiek uztvertas kā cilvēciskas, jaunieši ziņo par emocionālas saiknes sajūtu ar tām, kas var viņus pakļaut ietekmei un manipulācijām5.\nSociālā saikne: Cilvēki jau tā biežāk antropomorfizējas, ja viņiem dzīvē trūkst sociālās saiknes vai ja viņi vēlas izprast neparedzamu vidi6.\nZiņkāre: Ja mākslīgā intelekta sistēmas tiek uztvertas kā cilvēciskas, tas noved pie “melnās kastes” skatījuma uz lietojumprogrammām. Šāds abstrakcijas līmenis var atturēt cilvēkus no vēlmes uzzināt par to, kā mākslīgais intelekts darbojas, liekot viņiem to uztvert kā “maģiju”7.\nAizspriedumi: Ja mākslīgā intelekta sistēmas tiek uztvertas kā cilvēkveidīgas, tās tiek uzskatītas arī par “baltām”. Šis skatījums uz mākslīgo intelektu nozīmē, ka daudzi krāsainie cilvēki jūtas atturīgi no mākslīgā intelekta aģentiem8. Daudzas mākslīgā intelekta sistēmas ir arī antropomorfizētas kā sieviešu asistentes, tādējādi uzturot stereotipus par sievietēm kā pakļautām9.\n\nKad antropomorfizācija darbojas\nMākslīgā intelekta sistēmu antropomorfizācija sniedz priekšrocības izstrādātājiem gan ieviešanas, gan uzticēšanās ziņā. Kad lietotāji uztver rīkus kā cilvēciskus, viņi ir daudz atvērtāki attiecōbā uz to integrēšanu savā\ndzīvē un lietošanu4, tāpēc mākslīgā intelekta sistēmu izstrādātājiem var būt personiska interese, lai cilvēki tos uztvertu šādi.\nIr pierādījumi, ka antropomorfizācija palīdz jaunākiem skolēniem izprast sarežģītas parādības zinātnē. Padarot sistēmas cilvēcīgākas, nekā tās ir patiesībā, mēs varam pastāstīt par tām\nstāstus, kas var būt noderīgi, apgūstot sarežģītus jēdzienus.\nKopumā antropomorfizācijas lietderība ir tieši saistīta ar to, cik tuvu kaut kas ir faktiskajam intelektam. Piemēram, tas ir noderīgi, mācoties par plūdmaiņām, bet, mācoties par pērtiķiem, tas var radīt maldīgus priekšstatus2. Mākslīgā intelekta sistēmas tiek pasniegtas kā ārkārtīgi tuvas cilvēka intelektam, tāpēc antropomorfizācija ir īpaši bīstama.\nKā izvairīties no mākslīgā intelekta sistēmu antropomorfizācijas\nLai palīdzētu studentiem izstrādāt pietiekami noturīgus mentālos modeļus, lai saprastu, kā mākslīgā intelekta sistēmas tiek attēlotas\nkā cilvēkam līdzīgas, jūs varat:\n\nIzvairieties lietot mākslīgo intelektu kā saskaitāmu lietvārdu. Tā vietā, lai kaut ko sauktu par “mākslīgo intelektu”, izmantojiet apzīmētāju, piemēram, “mākslīgā intelekta sistēma”, “lietojumprogramma” vai “modelis”. Lietojot terminu “mākslīgais intelekts”, lietojiet to tāpat kā “bioloģija” vai “kiberdrošība” — kā studiju un prakses jomu, nevis kā kaut ko, uz ko var norādīt.\nIzvairieties no cilvēku valodas lietošanas, lai aprakstītu mākslīgā intelekta lietojumprogrammu darbību. Tā vietā izmantojiet uz sistēmu balstītu valodu. Aizstājiet tādus vārdus kā “klausās”, “saprot” un “rada” ar “ieraksta”, “apstrādā” un “ģenerē”.\nNepiešķiriet mākslīgā intelekta sistēmai pārāk lielu rīcības brīvību, to aprakstot. Tā vietā, lai teiktu “mākslīgā intelekta sistēma mācās” vai “mašīnmācīšanās (ML) modelis to dara”, iekļaujiet vienādojumā cilvēku. Piemēram, “Mākslīgā intelekta izstrādātāji apmācīja sistēmu līdz…” vai “cilvēki izmanto mašīnmācīšanās modeli līdz…”.\n\n\n\nPiemēri\nŠeit ir daži praktiski piemēri, kā aprakstīt mākslīgā intelekta sistēmas, neizmantojot antropomorfizētus aprakstus:\nViedais runātājs\n“Viedais runātājs tiek aktivizēts ar tādu frāzi kā “Hei, Google”.” Pēc tam tas ieraksta jūsu balsi un nosūta to uz datoru, izmantojot internetu.\nŠis dators analizē ierakstu un paredz atbildi uz jūsu pieprasījumu, piemēram, mūzikas atskaņošanu vai atbildi uz jautājumu. Runātājs saņem paredzēto atbildi un atskaņo to jums\nLiels valodas modelis (LLM)\n“Liels valodas modelis (LLM) ir mākslīgā intelekta sistēma, kas ģenerē tekstu, reaģējot uz lietotāja uzvedni.” Kad tiek ievadīta uzvedne, sistēma to sadala mazākos gabalos un salīdzina ar plašu teksta datu kopu, uz kuras ir apmācīts LLM. LLM izmanto apmācības datos esošos modeļus un attiecības, lai novērtētu uzvedni. Pēc tam atbilde tiek ģenerēta, apvienojot vārdus un frāzes, kas, domājams, ir atbilstošas.”\nAtsauces\nAvota pdf fails\nFootnotes\n\n\nSalles, A., et al. (2020). Antropomorfisms mākslīgajā intelektā. qr22_1 ↩ ↩2 ↩3\n\n\nTang, X., &amp; Hammer, D. (2024). “Es par to domāju šādi, un tas man palīdz saprast”: antropomorfisms sākumskolas skolēnu mehāniskajos stāstos. qr22_2 ↩ ↩2\n\n\nPlacani, A. (2024). Antropomorfisms mākslīgajā intelektā: ažiotāža un maldi. qr22_3 ↩ ↩2 ↩3\n\n\nHuang, J., et al. (2024). Kad antropomorfisms sāp? Kā instrumentu antropomorfisms negatīvi ietekmē patērētāju atlīdzību par instrumentu lietotājiem  qr22_4 ↩ ↩2\n\n\nWilliams, R., et al. (2023). Mākslīgais intelekts + ētikas mācību programmas vidusskolas jauniešiem: mācības, kas gūtas no trim uz projektiem balstītām mācību programmām. qr22_5 ↩\n\n\nAlabed, A., et al. (2022). Mākslīgā intelekta antropomorfisms un tā ietekme uz lietotāju paškongruenci un pašintegrāciju ar mākslīgo intelektu: teorētiskais ietvars un pētījumu programma. qr22_6 ↩\n\n\nTedre, M., et al. (2016). Mašīnmācīšanās mācīšana datorzinātņu izglītībā K-12 klasēs: potenciāls un trūkumi. qr22_7 ↩\n\n\nCave, S., &amp; Dihal, K. (2020). Mākslīgā intelekta baltums. qr22_8 ↩\n\n\nBarau, S. (2024). Maldināšana, diskriminācija un objektivizācija: sieviešu mākslīgā intelekta aģentu ētiskie jautājumi. qr22_9 ↩\n\n\n","frontmatter":{"title":"Antropomorfizācijas ietekme uz studentu mentālajiem mākslīgā intelekta modeļiem","lang":"Latvian","translatedFrom":"[QR22](../QR22.md)","aliases":["QR22_lv"],"draft":null,"tags":["Liels"]}},"Quick-Reads/QR22_ro":{"slug":"Quick-Reads/QR22_ro","filePath":"Quick Reads/QR22_ro.md","title":"Efectele antropomorfizării asupra modelelor mentale ale elevilor despre AI","links":["Quick-Reads/the-cc.io/qr22_1","Quick-Reads/the-cc.io/qr22_2","Quick-Reads/the-cc.io/qr22_4","Quick-Reads/the-cc.io/qr22_5","Quick-Reads/the-cc.io/qr22_6","Quick-Reads/the-cc.io/qr22_7","Quick-Reads/the-cc.io/qr22_8","Quick-Reads/the-cc.io/qr22_9"],"tags":[],"content":"Ca profesori, rolul nostru este de să ajutăm tinerii să dezvolte modele mentale care să le permită să navigheze într-o lume din ce în ce mai dependentă de sistemele de inteligență artificială (AI). Sistemele AI sunt adesea prezentate ca având atribute umane, precum emoții, stări mentale și comportamente1. Tendința de a antropomorfiza inteligența artificială este întărită de reprezentările din ficțiune — filme, seriale TV, cărți — și din mass-media. Mass-media recurge frecvent la imagini cu roboți zâmbitori, asemănători oamenilor, pentru a ilustra povești despre sisteme AI1. Limbajul din acest domeniu este, de asemenea, în mod inerent antropomorf, de la denumirea de „inteligență artificială” până la termeni precum „învățare automată”, „halucinații” sau „cuvinte de trezire”.\nAceste descrieri pot fi luate ad litteram de către cei care nu au un model mental solid despre sistemele AI2. Limbajul folosit pentru a descrie sistemele AI le prezintă ca fiind capabile să „gândească” sau să „raționeze”, ceea ce prezintă în mod eronat procesele utilizate de aceste sisteme, făcându-le să pară similare cu inteligența umană3. Dacă crezi că sistemele AI pot gândi, atunci s-ar putea să le atribui și emoții. Asta te poate face să vezi aceste mașini ca având intenții și principii morale, ceea ce intensifică temerile și concepțiile greșite existente despre capacitățile acestor sisteme3\n\n\n                  \n                  Concepte-cheie \n                  \n                \n\n\nAntropomorfizarea este practica de a atribui caracteristici și comportamente umane unor obiecte care nu sunt umane1.\nInteligența artificială (AI) este adesea descrisă folosind un limbaj puternic centrat pe oameni.\nAntropomorfizarea AI duce la concepții greșite despre cum funcționează sistemele AI și despre capacitățile lor reale și determină o pierdere a autonomiei utilizatorilor3.\nProfesorii pot evita antropomorfizarea AI prin\n\nEvitarea folosirii AI ca substantiv numărabil („o AI”)\nÎnlocuirea cuvintelor „ascultă”, „înțelege”, „creează” cu „înregistrează”, „analizează”, „generează”\nFolosirea termenului AI la fel ca „biologie” sau „securitate cibernetică”\n\n\n\n\nRiscurile antropomorfizării\nDacă tinerii percep această tehnologie ca fiind în mod inerent asemănătoare oamenilor, riscăm să   le afectăm…\n\nAutonomia: Simplitatea intenționată a utilizării AI îi poate face pe elevi să creadă că au foarte puțin, sau chiar deloc, control asupra rolului și impactului acesteia în viața și deciziile lor. Oamenii își pot ceda puterea în fața sistemelor dacă le percep ca fiind mai inteligente decât ei4.\nSiguranța: Când sistemele AI sunt văzute ca umane, tinerii declară că simt o conexiune emoțională cu acestea, ceea ce îi poate face vulnerabili la influență și manipulare5.\nConexiunea socială: Oamenii sunt mai predispuși să antropomorfizeze atunci când conexiunea socială lipsește deja din viața lor sau dacă încearcă să înțeleagă un mediu imprevizibil6.\nCuriozitatea: Dacă sistemele AI sunt percepute ca fiind umane, acest lucru duce la o perspectivă de tip „cutie neagră” asupra aplicațiilor. Acest nivel de abstractizare îi poate descuraja pe oameni din a-și dori să afle cum funcționează acestea, făcându-i să aibă percepția că AI funcționează prin „magie”7.\nPrejudecățile: Când sistemele AI sunt percepute ca fiind asemănătoare oamenilor, ele sunt de asemenea considerate „albe”. Această perspectivă asupra AI înseamnă că multe persoane de culoare se simt descurajate de agenții AI8. Multe sisteme AI sunt, de asemenea, antropomorfizate ca asistente de gen feminin, perpetuând stereotipul că femeile sunt subordonate9.\n\nCând antropomorfizarea funcționează\nAntropomorfizarea sistemelor AI are beneficii pentru dezvoltatori în ceea ce privește utilizarea și nivelul de încredere. Când utilizatorii văd instrumentele ca fiind asemănătoare oamenilor, sunt mult mai receptivi la integrarea lor în   viața de zi cu zi și la utilizarea lor4, așa că dezvoltatorii de sisteme AI ar putea avea un interes direct ca oamenii să le privească în acest fel.\nExistă dovezi că antropomorfizarea îi ajută pe elevii mai mici să înțeleagă fenomene complexe din știință. De asemenea, ne permite să povestim   despre aceste sisteme, ceea ce poate fi util în învățarea unor concepte complicate.\nPer ansamblu, utilitatea antropomorfizării este direct legată de cât de aproape este ceva de inteligența reală. De exemplu, ea poate fi utilă atunci când învățăm despre maree, dar când învățăm   despre maimuțe poate duce la concepții greșite2. Sistemele AI sunt prezentate ca fiind extrem de apropiate de inteligența umană, ceea ce face antropomorfizarea deosebit de periculoasă.\nCum să evităm antropomorfizarea sistemelor AI\nPentru a-i ajuta pe elevi să dezvolte modele mentale suficient de rezistente încât să vadă dincolo de prezentarea   sistemelor IA ca fiind umane, poți:\n\nEvita folosirea AI ca substantiv numărabil. În loc să spui „o AI”, folosește „un sistem AI”, „o aplicație” sau „un model”. Folosește termenul „AI” la fel cum ai folosi „biologie” sau „securitate cibernetică” — ca domeniu de studiu și practică, nu ca un obiect concret.\nEvită folosirea limbajului uman pentru a descrie comportamentele aplicațiilor AI. Folosește în schimb limbaj centrat pe sisteme. Înlocuiește cuvinte precum „ascultă”, „înțelege” și „creează” cu „înregistrează”, „procesează” și „generează”.\nNu acorda prea multă putere unui sistem AI atunci când îl descrii. În loc de „sistemul AI învață” sau „modelul de învățare automată face”, includeți o persoană în ecuație. De exemplu: „dezvoltatorii de AI au antrenat sistemul să…” sau „oamenii folosesc modelul de învățare automată pentru a…”.\n\n\n\nExemple\nIată câteva exemple practice de descrieri ale sistemelor AI care nu sunt antropomorfizate:\nBoxă inteligentă\n„O boxă inteligentă este activată printr-o frază precum ‘Hei Google’. Aceasta înregistrează vocea ta și o trimite prin internet către un computer.\nComputerul analizează înregistrarea și prezice răspunsul la cererea ta, cum ar fi redarea de muzică sau răspunsul la o întrebare. Boxa primește răspunsul prezis și îl redă.”\nUn model de limbaj de mari dimensiuni (LLM)\n„Un model de limbaj de mari dimensiuni (LLM) este un sistem AI care generează text ca răspuns la cerința unui utilizator. Când este introdus un prompt, sistemul îl fragmentează în părți mai mici și îl compară cu un set vast de date text pe care a fost antrenat. LLM-ul utilizează tipare și relații din datele de antrenament pentru a evalua promptul. Apoi se generează un răspuns prin combinarea cuvintelor și a expresiilor despre care se prezice că ar putea fi relevante.”\nReferințe\nSource pdf\nFootnotes\n\n\nSalles, A., et al. (2020). Anthropomorphism in AI. qr22_1 ↩ ↩2 ↩3\n\n\nTang, X., &amp; Hammer, D. (2024). “I think of it that way and it helps me understand”: Anthropomorphism in elementary students’ mechanistic stories. qr22_2 ↩ ↩2\n\n\nPlacani, A. (2024). Anthropomorphism in AI: hype and fallacy. qr22_3 ↩ ↩2 ↩3\n\n\nHuang, J., et al. (2024). When does anthropomorphism hurt? How tool anthropomorphism negatively affects consumers’ rewards for tool users. qr22_4 ↩ ↩2\n\n\nWilliams, R., et al. (2023). AI + ethics curricula for middle school youth: lessons learned from three project-based curricula. qr22_5 ↩\n\n\nAlabed, A., et al. (2022). AI anthropomorphism and its effect on users’ self-congruence and self–AI integration: a theoretical framework and research agenda. qr22_6 ↩\n\n\nTedre, M., et al. (2016). Teaching machine learning in K–12 computing education: potential and pitfalls. qr22_7 ↩\n\n\nCave, S., &amp; Dihal, K. (2020). The Whiteness of AI. qr22_8 ↩\n\n\nBarau, S. (2024). Deception, discrimination, and objectification: ethical issues of female AI agents. qr22_9 ↩\n\n\n","frontmatter":{"title":"Efectele antropomorfizării asupra modelelor mentale ale elevilor despre AI","lang":"Romanian","translatedFrom":"[QR22](../QR22.md)","aliases":["QR22_ro"],"draft":null}},"Quick-Reads/QR23":{"slug":"Quick-Reads/QR23","filePath":"Quick Reads/QR23.md","title":"Feedback literacy: A framework for effectively using AI outputs in teaching and learning","links":["Image-Test","Quick-Reads/the-cc.io/qr23_4","Quick-Reads/the-cc.io/qr23_1","Quick-Reads/the-cc.io/qr23_2","Quick-Reads/the-cc.io/qr23_3","Quick-Reads/the-cc.io/qr23_6","Quick-Reads/the-cc.io/qr23_5","Quick-Reads/the-cc.io/qr23_7","Quick-Reads/the-cc.io/qr23_8"],"tags":[],"content":"Feedback is essential in any teaching and learning context. Hattie and Timperley describe feedback as “the information provided by an agent (e.g., teacher, peer, book, parent, self, experience) regarding aspects of one’s performance or understanding”1 . As well as people providing feedback, systems — including AI applications — now also provide feedback. How do we ensure that all students get the most out of AI system-produced feedback? Feedback literacy is a theory driven framework that can help teachers and system and resource designers to answer this question. It can help these groups to work out what we should teach about AI systems and how we should design related learning activities and learning systems that involve students interacting with the outputs of teaching and learning AI applications.\n\n\n                  \n                  Key concepts \n                  \n                \n\n\nFeedback literacy: \nA set of competencies that support the social interaction of feedback. \nFeedback types: \nDifferent classifications of feedback, which include feedback as telling, guiding, developing understanding, and opening up2 . \nStudent feedback literacy: \nStudent competencies related to feedback, which include the ability to appreciate the feedback process, make judgements about feedback, take action, and manage one’s responses to (the affect of) the feedback3.\nTeacher feedback literacy: \nTeacher competencies related to feedback, which include the ability to design feedback within the learning context, take account of the relational aspects of feedback, and be pragmatic about feedback4 .\n\n\n\nFeedback literacy and AI-produced explanations\nThree theories (feedback types, student feedback literacy, and teacher feedback literacy) are useful to think about within a feedback literacy framework5. Each of these component theories has been developed with the idea that the teacher and student are interacting directly rather than an AI application providing the feedback. However, in research on how teachers might use AI tools in computer science classrooms to help students learn to program, Cucuiat and Waite (2024) found that feedback literacy was essential to analyse how AI-enhanced explanations can be introduced for student use5.\n! Image Test\n[figcaption ]The three theories of feedback types2, student feedback literacy3, and teacher feedback literacy4 are interconnected and may also influence developers and AI applications (inspired by Rohlfing et al. 6).\nFeedback types\nThe four feedback types (telling, guiding, developing understanding, and opening up) are simple ways of describing the feedback created by people and by systems2 .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback typeEducator roleStudent roleTellingUnidrectionally transmit ‘correct’ informationPassiveGuidingPoint in the right directionActive — apply knowledgeDeveloping understandingProvide targeted teachingActive — construct or adjust knowledgeOpening upPresent new perspectivesActive — interpret and evaluate new knowledge\nWhen exploring AI system-produced explanations of program error messages, teachers have asked for feedback in the form of telling to be avoided; such feedback can lead to students becoming over-reliant on AI systems and not actively learning themselves. Teachers would prefer students to not be told the answers but instead guided to them. \nFeedback should also feed-forward7 and generalise, so that students can reuse new knowledge in other contexts. \nTeachers are likely to use a range of feedback types without even realising it, adapting to the student, the topic, the task being done, and the progression they expect for that learning experience. How effective AI-produced feedback will be in providing such nuanced feedback remains to be seen.\nStudent feedback literacy \nStudent feedback literacy has been described as having four main aspects: students need to be able to appreciate the feedback process, make judgements about the feedback, take action, and manage their responses to (the affect of) the feedback3. It serves as an important framework when thinking about how students should handle feedback.\nTeacher feedback literacy\nTeacher feedback literacy is a framework that identifies key teacher competencies in relation to feedback. It has been described as entailing the ability to design feedback within the learning context, take account of the relational aspects of feedback, and be pragmatic about feedback4 .\nEmbedding feedback literacy in classroom practice\nAs AI applications become more prevalent in classrooms, teachers will need to change what they teach and how. Meanwhile, students will need guidance as the way they learn changes. Indeed, many students are already using feedback produced by AI applications in different ways, to greater and lesser degrees of success (e.g. as discussed by Kazemitabaar et al.8 ). \nFeedback literacy provides a framework to begin addressing these changes and ensuring that teachers and students get the most out of AI teaching and learning applications in the classroom. \nFeedback literacy can help students to: \n\nCompare and judge what to do with feedback from their teacher, feedback from their peers, and output from an AI system \nUnderstand why AI-produced feedback may be wrong, use unfamiliar vocabulary, or point them towards a next step that is not very useful for their learning progression \nLearn new processes to work with AI-produced explanations, such as evaluation techniques and how to record judgements \n\nFeedback literacy can help teachers to: \n\nConsider how and when AI-produced feedback might enrich or even replace existing teacher-student dialogue \nTeach students about feedback literacy and support students in developing and applying their own feedback literacy \n\nAs time goes on, teachers may also demand more from AI tools, expecting functionalities such as the ability to turn off feedback in the form of telling and have feedback only in the form of guiding, to better lead students towards pre-defined learning objectives and feed forward to useful knowledge building.\nReferences\nSource pdf\nFootnotes\n\n\nHattie, J., &amp; Timperley, H. (2007). The power of feedback. qr23_4 ↩\n\n\nMcLean, A. J., et al. (2015). An anatomy of feedback: a phenomenographic investigation of undergraduate students’ conceptions of feedback. qr23_1 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Boud, D. (2018). The development of student feedback literacy: enabling uptake of feedback. qr23_2 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Winstone, N. (2023). Teacher feedback literacy and its interplay with student feedback literacy. qr23_3 ↩ ↩2 ↩3\n\n\nCucuiat, V., &amp; Waite, J. (2024). Feedback Literacy: Holistic Analysis of Secondary Educators’ Views of LLM Explanations of Program Error Messages. qr23_6 ↩ ↩2\n\n\nRohlfing, K. J., et al. (2020). Explanation as a social practice: Toward a conceptual framework for the social design of AI systems. qr23_5 ↩\n\n\nvan Heerden, M. (2021). (How) do written comments feed-forward? A translation device for developing tutors’ feedback-giving literacy. qr23_7 ↩\n\n\nKazemitabaar, M., et al. (2023). Studying the effect of AI code generators on supporting novice learners in introductory programming. qr23_8 ↩\n\n\n","frontmatter":{"title":"Feedback literacy: A framework for effectively using AI outputs in teaching and learning","fileOrder":23,"displayName":"23 - Feedback Literacy","aliases":["Feedback Literacy","QR23"],"draft":null}},"Quick-Reads/QR23_el":{"slug":"Quick-Reads/QR23_el","filePath":"Quick Reads/QR23_el.md","title":"Γραμματισμός σχολίων: Ένα πλαίσιο για την αποτελεσματική χρήση των αποτελεσμάτων από το AI στη διδασκαλία και τη μάθηση","links":["Quick-Reads/Εικόνα","Quick-Reads/the-cc.io/qr23_4","Quick-Reads/the-cc.io/qr23_1","Quick-Reads/the-cc.io/qr23_2","Quick-Reads/the-cc.io/qr23_3","Quick-Reads/the-cc.io/qr23_6","Quick-Reads/the-cc.io/qr23_5","Quick-Reads/the-cc.io/qr23_7","Quick-Reads/the-cc.io/qr23_8"],"tags":[],"content":"Τα σχόλια είναι απαραίτητα σε κάθε πλαίσιο διδασκαλίας και μάθησης. Οι Hattie και Timperley περιγράφουν τα σχόλια ως «πληροφορίες που παρέχονται από έναν φορέα (π.χ. δάσκαλο, συμμαθητή(-τρια), βιβλίο, γονέα, τον ίδιο τον μαθητή(-τρια), την εμπειρία) σχετικά με πτυχές της απόδοσης ή της κατανόησής του»1. Εκτός από τους ανθρώπους που παρέχουν σχόλια, πλέον και τα συστήματα, συμπεριλαμβανομένων των εφαρμογών AI παρέχουν επίσης σχόλια. Πώς διασφαλίζουμε ότι όλοι οι μαθητές(-τριες) αποκομίζουν τα μέγιστα από τα σχόλια που παράγονται από συστήματα AI; Ο γραμματισμός σχολίων είναι ένα θεωρητικά τεκμηριωμένο πλαίσιο που μπορεί να βοηθήσει τους εκπαιδευτικούς καθώς και τους σχεδιαστές συστημάτων και πόρων να απαντήσουν σε αυτό το ερώτημα. Μπορεί να βοηθήσει αυτές τις ομάδες να καθορίσουν τι πρέπει να διδάσκουμε σχετικά με τα συστήματα AI και πώς να σχεδιάζουμε τις αντίστοιχες μαθησιακές δραστηριότητες και τα μαθησιακά συστήματα που περιλαμβάνουν την αλληλεπίδραση των μαθητών με τα αποτελέσματα από τις εφαρμογές διδασκαλίας και μάθησης AI.\n\n\n                  \n                  Bασικές έννοιες \n                  \n                \n\n\nΓραμματισμός σχολίων:\nΈνα σύνολο ικανοτήτων που υποστηρίζουν την κοινωνική διάσταση των σχολίων.\nΤύποι σχολίων:\nΔιαφορετικές ταξινομήσεις σχολίων, οι οποίες περιλαμβάνουν τα σχόλια ως ενημέρωση, καθοδήγηση, ανάπτυξη κατανόησης και διεύρυνση προοπτικής2.\nΓραμματισμός σχολίων μαθητών:\nΙκανότητες των μαθητών που σχετίζονται με τα σχόλια, οι οποίες περιλαμβάνουν την ικανότητα να εκτιμούν τη διαδικασία των σχολίων, να κρίνουν τα σχόλια, να αναλαμβάνουν δράση και να διαχειρίζονται τις αντιδράσεις τους (την επίδραση που τους ασκούν) στα σχόλια3.\nΓραμματισμός σχολίων εκπαιδευτικών:\nΙκανότητες των εκπαιδευτικών που σχετίζονται με τα σχόλια, οι οποίες περιλαμβάνουν την ικανότητα να σχεδιάζουν τα σχόλια μέσα στο πλαίσιο μάθησης, να λαμβάνουν υπόψη τις σχεσιακές τους διαστάσεις και να έχουν μια πραγματιστική προσέγγιση απέναντι στα σχόλια4.\n\n\n\nΓραμματισμός σχολίων και επεξηγήσεις που παράγονται από το AI\nΤρεις θεωρίες (είδη σχολίων, γραμματισμός σχολίων μαθητών και γραμματισμός σχολίων εκπαιδευτικών) είναι χρήσιμες για να τις εξετάσουμε μέσα σε ένα πλαίσιο γραμματισμού σχολίων5. Καθεμία από αυτές τις επιμέρους θεωρίες έχει αναπτυχθεί με την ιδέα ότι ο εκπαιδευτικός και ο μαθητής(-τρια) αλληλεπιδρούν άμεσα, και όχι ότι μια εφαρμογή AI παρέχει τα σχόλια. Ωστόσο, σε έρευνα σχετικά με το πώς οι εκπαιδευτικοί μπορούν να χρησιμοποιήσουν εργαλεία AI σε αίθουσες διδασκαλίας πληροφορικής για να βοηθήσουν τους μαθητές να μάθουν προγραμματισμό, οι Cucuiat και Waite (2024) διαπίστωσαν ότι ο γραμματισμός σχολίων ήταν απαραίτητος για την ανάλυση του τρόπου με τον οποίο μπορούν να εισαχθούν επεξηγήσεις ενισχυμένες με AI για χρήση από τους μαθητές5.\n! Εικόνα \n[λεζάντα] Οι τρεις θεωρίες των ειδών σχολίων2, του γραμματισμού σχολίων μαθητών3 και του γραμματισμού σχολίων εκπαιδευτικών4 είναι αλληλένδετες και ενδέχεται επίσης να επηρεάζουν τους προγραμματιστές και τις εφαρμογές AI (εμπνευσμένο από Rohlfing et al.6).\nΤύποι σχολίων\nΟι τέσσερις τύποι σχολίων (ενημέρωση, καθοδήγηση,** ανάπτυξη κατανόησης** και διεύρυνση προοπτικής) αποτελούν απλούς τρόπους περιγραφής των σχολίων που δημιουργούνται από ανθρώπους και από συστήματα2 .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nΤύπος σχολίωνΡόλος εκπαιδευτικούΡόλος μαθητή(-τριας)ΕνημέρωσηΜονοκατευθυντική μετάδοση «σωστών» πληροφοριώνΠαθητικήΚαθοδήγησηΔείχνει προς τη σωστή κατεύθυνσηΕνεργή εφαρμογή γνώσηςΑνάπτυξη κατανόησηςΠαροχή στοχευμένης διδασκαλίαςΕνεργή οικοδόμηση ή προσαρμογή γνώσηςΔιεύρυνση προοπτικήςΠαρουσίαση νέων προοπτικώνΕνεργή ερμηνεία και αξιολόγηση νέας γνώσης\nΌταν διερευνώνται επεξηγήσεις που παράγονται από συστήματα AI για μηνύματα σφαλμάτων προγραμμάτων, οι εκπαιδευτικοί έχουν ζητήσει να αποφεύγονται τα σχόλια με τη μορφή της ενημέρωσης. Τέτοια σχόλια μπορεί να οδηγήσουν τους μαθητές σε υπερβολική εξάρτηση από τα συστήματα AI και σε μη ενεργή μάθηση. Οι εκπαιδευτικοί θα προτιμούσαν οι μαθητές να μη λαμβάνουν έτοιμες τις απαντήσεις, αλλά να καθοδηγούνται σε αυτές.\nΤα σχόλια θα πρέπει επίσης να περιλαμβάνουν προοπτική εξέλιξης (feed-forward)7 και να γενικεύονται, ώστε οι μαθητές να μπορούν να επαναχρησιμοποιούν τη νέα γνώση σε άλλα πλαίσια.\nΟι εκπαιδευτικοί είναι πιθανό να χρησιμοποιούν μια ποικιλία τύπων σχολίων χωρίς καν να το συνειδητοποιούν, προσαρμοζόμενοι στον μαθητή(-τρια), στο θέμα, στην εκάστοτε δραστηριότητα και στην πρόοδο που αναμένουν για τη συγκεκριμένη εμπειρία μάθησης. Το πόσο αποτελεσματικά θα αποδειχθούν τα σχόλια που παράγονται από AI στο να παρέχουν τόσο λεπτομερή σχόλια, μένει να φανεί.\nΓραμματισμός σχολίων μαθητών\nΟ γραμματισμός σχολίων των μαθητών έχει περιγραφεί ως κάτι που περιλαμβάνει τέσσερις κύριες διαστάσεις: οι μαθητές χρειάζεται να μπορούν να εκτιμούν τη διαδικασία σχολίων, να κρίνουν τα σχόλια, να αναλαμβάνουν δράση και να διαχειρίζονται τις αντιδράσεις τους (την επίδραση που τους ασκούν) στα σχόλια3. Αποτελεί ένα σημαντικό πλαίσιο όταν εξετάζουμε το πώς θα πρέπει οι μαθητές(-τριες) να διαχειρίζονται τα σχόλια.\nΓραμματισμός σχολίων εκπαιδευτικών\nΟ γραμματισμός σχολίων εκπαιδευτικών είναι ένα πλαίσιο που αναδεικνύει τις βασικές ικανότητες των εκπαιδευτικών σε σχέση με τα σχόλια. Έχει περιγραφεί ως η ικανότητα να σχεδιάζονται τα σχόλια μέσα στο πλαίσιο μάθησης, να λαμβάνονται υπόψη οι σχεσιακές τους διαστάσεις και να υπάρχει μια πραγματιστική προσέγγιση απέναντι στα σχόλια4.\nΕνσωμάτωση του γραμματισμού σχολίων στην πρακτική της αίθουσας διδασκαλίας\nΚαθώς οι εφαρμογές AI γίνονται όλο και πιο διαδεδομένες στις αίθουσες διδασκαλίας, οι εκπαιδευτικοί θα χρειαστεί να αλλάξουν τόσο το τι διδάσκουν όσο και το πώς. Παράλληλα, οι μαθητές(-τριες) θα χρειαστούν οδηγίες, καθώς ο τρόπος με τον οποίο μαθαίνουν μεταβάλλεται. Πράγματι, πολλοί μαθητές ήδη χρησιμοποιούν τα σχόλια που παράγονται από εφαρμογές AI με διαφορετικούς τρόπους, με μεγαλύτερο ή μικρότερο βαθμό επιτυχίας (π.χ. όπως συζητείται από τους Kazemitabaar et al.8).\nΟ γραμματισμός σχολίων προσφέρει ένα πλαίσιο για να αρχίσουμε να αντιμετωπίζουμε αυτές τις αλλαγές και να διασφαλίζουμε ότι οι εκπαιδευτικοί και οι μαθητές(-τριες) αποκομίζουν τα μέγιστα από τις εφαρμογές διδασκαλίας και μάθησης του AI στην αίθουσα διδασκαλίας.\nΟ γραμματισμός σχολίων μπορεί να βοηθήσει τους μαθητές να:\n\nΣυγκρίνουν και να κρίνουν πώς να αξιοποιήσουν τα σχόλια από τον εκπαιδευτικό τους, τα σχόλια από τους συμμαθητές τους και τα δεδομένα εξόδου από ένα σύστημα AI\nΚατανοήσουν γιατί τα σχόλια που παράγονται από AI μπορεί να είναι λανθασμένα, να χρησιμοποιούν άγνωστο λεξιλόγιο ή να τους κατευθύνει σε ένα επόμενο βήμα που δεν είναι ιδιαίτερα χρήσιμο για την πρόοδο της μάθησής τους\nΜάθουν νέες διαδικασίες για να εργάζονται με επεξηγήσεις που παράγονται από AI, όπως τεχνικές αξιολόγησης και τρόπους καταγραφής εκτιμήσεων\n\nΟ γραμματισμός σχολίων μπορεί να βοηθήσει τους εκπαιδευτικούς να:\n\nΕξετάσουν πώς και πότε τα σχόλια που παράγονται από AI ενδέχεται να εμπλουτίσουν ή ακόμη και να αντικαταστήσουν τον υφιστάμενο διάλογο εκπαιδευτικού-μαθητή(τριας)\nΔιδάσκουν στους μαθητές τον γραμματισμό σχολίων και να τους υποστηρίζουν στην ανάπτυξη και εφαρμογή του δικού τους γραμματισμού σχολίων\n\nΜε την πάροδο του χρόνου, οι εκπαιδευτικοί ενδέχεται επίσης να απαιτήσουν περισσότερα από τα εργαλεία AI, αναμένοντας λειτουργίες όπως η δυνατότητα απενεργοποίησης σχολίων με τη μορφή της ενημέρωσης και η παροχή σχολίων μόνο με τη μορφή της καθοδήγησης, ώστε να κατευθύνονται καλύτερα οι μαθητές προς προκαθορισμένους στόχους μάθησης και να προωθείται η οικοδόμηση χρήσιμης γνώσης.\nΒιβλιογραφικές αναφορές\nΤο αρχείο-πηγή σε μορφή pdf\nFootnotes\n\n\nHattie, J., &amp; Timperley, H. (2007). The power of feedback. qr23_4 ↩\n\n\nMcLean, A. J., et al. (2015). An anatomy of feedback: a phenomenographic investigation of undergraduate students’ conceptions of feedback. qr23_1 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Boud, D. (2018). The development of student feedback literacy: enabling uptake of feedback. qr23_2 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Winstone, N. (2023). Teacher feedback literacy and its interplay with student feedback literacy. qr23_3 ↩ ↩2 ↩3\n\n\nCucuiat, V., &amp; Waite, J. (2024). Feedback Literacy: Holistic Analysis of Secondary Educators’ Views of LLM Explanations of Program Error Messages. qr23_6 ↩ ↩2\n\n\nRohlfing, K. J., et al. (2020). Explanation as a social practice: Toward a conceptual framework for the social design of AI systems. qr23_5 ↩\n\n\nvan Heerden, M. (2021). (Με ποιον τρόπο) τα γραπτά σχόλια προωθούν την εξέλιξη; Ένα μεταφραστικό εργαλείο για την ανάπτυξη του γραμματισμού παροχής σχολίων των διδασκόντων. qr23_7 ↩\n\n\nKazemitabaar, M., et al. (2023). Studying the effect of AI code generators on supporting novice learners in introductory programming. qr23_8 ↩\n\n\n","frontmatter":{"title":"Γραμματισμός σχολίων: Ένα πλαίσιο για την αποτελεσματική χρήση των αποτελεσμάτων από το AI στη διδασκαλία και τη μάθηση","lang":"Greek","translatedFrom":"[QR23](../QR23.md)","aliases":["QR23_el"],"draft":null}},"Quick-Reads/QR23_es":{"slug":"Quick-Reads/QR23_es","filePath":"Quick Reads/QR23_es.md","title":"Alfabetización en retroalimentación: un marco de trabajo para el uso eficaz de las salidas de IA en la enseñanza y el aprendizaje","links":["Quick-Reads/Image","Quick-Reads/the-cc.io/qr23_4","Quick-Reads/the-cc.io/qr23_1","Quick-Reads/the-cc.io/qr23_2","Quick-Reads/the-cc.io/qr23_3","Quick-Reads/the-cc.io/qr23_6","Quick-Reads/the-cc.io/qr23_5","Quick-Reads/the-cc.io/qr23_7","Quick-Reads/the-cc.io/qr23_8"],"tags":[],"content":"La retroalimentación es de vital importancia en cualquier contexto de enseñanza y aprendizaje. Hattie y Timperley describen la retroalimentación como “la información que proporciona un agente (por ejemplo, docentes, compañeros, libros, padres, uno mismo o la experiencia) con respecto al rendimiento o al propio entendimiento”1. Además de las personas, los sistemas (incluidas las aplicaciones de IA) también proporcionan retroalimentación. ¿Cómo podemos asegurarnos de que todo el alumnado saque el máximo partido a la retroalimentación que producen los sistemas de IA? La alfabetización en retroalimentación es un marco basado en la teoría que puede ayudar al personal docente y a responsables del diseño de sistemas y recursos a responder esta pregunta. Puede ayudar a estos grupos a determinar qué debemos enseñar sobre los sistemas de IA y cómo debemos diseñar actividades de aprendizaje relacionadas y sistemas de aprendizaje que impliquen la interacción del alumnado con las salidas de la enseñanza y el aprendizaje sobre aplicaciones de IA.\n\n\n                  \n                  Conceptos clave \n                  \n                \n\n\nAlfabetización en retroalimentación:\nConjunto de competencias que fomentan la interacción social de la retroalimentación.\nTipos de retroalimentación:\nDiferentes clasificaciones de retroalimentación, que incluyen retroalimentación como explicaciones, guías, desarrollo de conocimientos y apertura2.\nAlfabetización en retroalimentación del alumnado:\nCompetencias del alumnado relacionadas con la retroalimentación, que incluyen la capacidad para apreciar el proceso de retroalimentación, emitir juicios sobre la retroalimentación, tomar medidas y gestionar las propias respuestas (emocionales) con respecto a la retroalimentación3.\nAlfabetización en retroalimentación del personal docente:\nEsta se describe como las competencias docentes relacionadas con la retroalimentación, como, por ejemplo, la capacidad para diseñar retroalimentación en el contexto del aprendizaje, para tener en cuenta los aspectos relacionales de la retroalimentación y mantener un enfoque pragmático con respecto a la retroalimentación4.\n\n\n\nAlfabetización en retroalimentación y explicaciones producidas por IA\nEs útil pensar en tres teorías (tipos de retroalimentación, alfabetización de retroalimentación del alumnado y alfabetización de retroalimentación del personal docente) dentro del marco de la alfabetización en retroalimentación5. Cada una de estas teorías se ha desarrollado con la idea de que tanto el personal docente como el alumnado interactúen directamente en lugar de ser la aplicación de IA la que proporcione la retroalimentación. Sin embargo, en una investigación sobre cómo podría el personal docente utilizar herramientas de IA en las aulas de informática para ayudar a los y las estudiantes a aprender a programar, Cucuiat y Waite (2024) descubrieron que la alfabetización en retroalimentación era esencial para analizar cómo se pueden introducir explicaciones mejoradas con IA para el alumnado5.\n! Image \n[figcaption ]Las tres teorías de los tipos de retroalimentación2, la alfabetización en retroalimentación del alumnado3 y la alfabetización en retroalimentación del personal docente4 están interconectadas y también pueden influir en los desarrolladores y las aplicaciones de IA (según Rohlfing et al. 6).\nTipos de retroalimentación\nLos cuatro tipos de retroalimentación (explicación, guía, desarrollo de conocimientos y apertura) son formas simples de describir la retroalimentación que generan las personas y los sistemas2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipo de retroalimentaciónRol del docenteRol del estudianteExplicaciónTransmitir información “correcta” de manera unidireccionalPasivoGuíaGuiar en la dirección correctaActivo: aplicar el conocimientoDesarrollo de conocimientosProporcionar enseñanza específicaActivo: construir o ajustar los conocimientosAperturaPresentar nuevas perspectivasActivo: interpretar y evaluar nuevos conocimientos\nAl explorar las explicaciones de los mensajes de error del programa que producen los sistemas de IA, el personal docente ha solicitado retroalimentación en forma de explicaciones que deben evitarse: esta retroalimentación puede hacer que el alumnado se vuelva demasiado dependiente de los sistemas de IA y que no aprenda activamente por sí mismo. Los y las docentes preferirían guiar a los y las estudiantes en lugar de decirles las respuestas.\nLa retroalimentación también debe impulsar el aprendizaje futuro7 y generalizarse para que el alumnado pueda reutilizar los nuevos conocimientos en otros contextos.\nEs probable que el personal docente utilice diferentes tipos de retroalimentación sin siquiera darse cuenta, adaptándose al alumnado, al tema, a la tarea que se está realizando y a la progresión que esperan de la experiencia de aprendizaje. Queda por ver cuán efectiva será la retroalimentación que produzca la IA en términos de detalles y matices de la retroalimentación.\nAlfabetización en retroalimentación del alumnado\nLa alfabetización en retroalimentación del alumnado se ha descrito como compuesta por cuatro aspectos principales: los y las estudiantes necesitan ser capaces de apreciar el proceso de retroalimentación, emitir juicios sobre la retroalimentación, tomar medidas y gestionar sus reacciones (emocionales) con respecto a la retroalimentación3. Esto es un marco importante a la hora de pensar en cómo debe el alumnado gestionar la retroalimentación.\nAlfabetización en retroalimentación del personal docente\nLa alfabetización en retroalimentación del personal docente es un marco que identifica las competencias clave de los y las docentes en relación con la retroalimentación. Esta se describe como la capacidad de diseñar la retroalimentación dentro del contexto de aprendizaje, de tener en cuenta los aspectos relacionales de la retroalimentación y de mantener un enfoque pragmático con respecto a la retroalimentación4.\nIncorporación de la alfabetización en retroalimentación en la práctica docente\nA medida que las aplicaciones de IA se vuelvan más frecuentes en las aulas, los y las docentes tendrán que cambiar lo que enseñan y la forma en que lo hacen. Mientras tanto, los y las estudiantes necesitarán orientación a medida que cambie su forma de aprender. De hecho, muchos estudiantes ya están utilizando la retroalimentación que producen aplicaciones de IA de diferentes maneras, con mayor o menor éxito (tal como exponen, por ejemplo, Kazemitabaar et al.8).\nLa alfabetización en retroalimentación proporciona un marco para comenzar a abordar estos cambios y garantizar que tanto el personal docente como el alumnado aprovechen al máximo las aplicaciones de enseñanza y aprendizaje de IA en el aula.\nLa alfabetización en retroalimentación puede ayudar a los y las estudiantes a:\n\nComparar y juzgar qué hacer con la retroalimentación de sus docentes, la retroalimentación de sus compañeros y las salidas de los sistemas de IA.\nComprender por qué la retroalimentación que produce la IA puede ser errónea, utilizar vocabulario desconocido o recomendar pasos que son muy útiles para su progresión de aprendizaje.\nAprender nuevos procesos para trabajar con explicaciones producidas por IA, como técnicas de evaluación, y cómo documentar sus juicios.\n\nLa alfabetización en retroalimentación puede ayudar al personal docente a:\n\nValorar cómo y cuándo la retroalimentación producida por IA podría enriquecer o incluso reemplazar el diálogo existente entre docentes y estudiantes.\nEnseñar a los y las estudiantes sobre alfabetización en retroalimentación y fomentar el desarrollo y la aplicación de su propia alfabetización en retroalimentación.\n\nCon el tiempo, es posible que el personal docente también empiece a exigir más a las herramientas de IA, esperando funcionalidades como la posibilidad de desactivar la retroalimentación en forma de indicaciones directas y recibirla solo en forma de orientación, para, de este modo, guiar mejor al alumnado hacia objetivos de aprendizaje predefinidos y promover la construcción de conocimiento útil.\nReferencias\nSource pdf\nFootnotes\n\n\nHattie, J., &amp; Timperley, H. (2007). The power of feedback. qr23_4 ↩\n\n\nMcLean, A. J., et al. (2015). An anatomy of feedback: a phenomenographic investigation of undergraduate students’ conceptions of feedback. qr23_1 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Boud, D. (2018). The development of student feedback literacy: enabling uptake of feedback. qr23_2 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Winstone, N. (2023). Teacher feedback literacy and its interplay with student feedback literacy. qr23_3 ↩ ↩2 ↩3\n\n\nCucuiat, V., &amp; Waite, J. (2024). Feedback Literacy: Holistic Analysis of Secondary Educators’ Views of LLM Explanations of Program Error Messages. qr23_6 ↩ ↩2\n\n\nRohlfing, K. J., et al. (2020). Explanation as a social practice: Toward a conceptual framework for the social design of AI systems. qr23_5 ↩\n\n\nvan Heerden, M. (2021). (How) do written comments feed-forward? A translation device for developing tutors’ feedback-giving literacy. qr23_7 ↩\n\n\nKazemitabaar, M., et al. (2023). Studying the effect of AI code generators on supporting novice learners in introductory programming. qr23_8 ↩\n\n\n","frontmatter":{"title":"Alfabetización en retroalimentación: un marco de trabajo para el uso eficaz de las salidas de IA en la enseñanza y el aprendizaje","lang":"Spanish","translatedFrom":"[QR23](../QR23.md)","aliases":["QR23_el"],"draft":null}},"Quick-Reads/QR23_lt":{"slug":"Quick-Reads/QR23_lt","filePath":"Quick Reads/QR23_lt.md","title":"Grįžtamojo ryšio raštingumas – sistema, skirta veiksmingai naudoti DI rezultatus mokymo ir mokymosi procese","links":["Quick-Reads/Vaizdas","Quick-Reads/the-cc.io/qr23_4","Quick-Reads/the-cc.io/qr23_1","Quick-Reads/the-cc.io/qr23_2","Quick-Reads/the-cc.io/qr23_3","Quick-Reads/the-cc.io/qr23_6","Quick-Reads/the-cc.io/qr23_5","Quick-Reads/the-cc.io/qr23_7","Quick-Reads/the-cc.io/qr23_8"],"tags":[],"content":"Grįžtamasis ryšys yra būtinas bet kokioje mokymo ir mokymosi aplinkoje. Hattie ir Timperley grįžtamąjį ryšį apibūdina kaip „informaciją, kurią kas nors (pvz., mokytojas, bendramokslis, knyga, tėvai, pats besimokantysis, patirtis) suteikia apie asmens rezultatų ar supratimo aspektus“1. Grįžtamąjį ryšį gali teikti ne tik žmonės, bet ir sistemos, įskaitant DI taikomąsias programas. Kaip užtikrinti, kad visi mokiniai kuo geriau pasinaudotų DI sistemos teikiamu grįžtamuoju ryšiu? Grįžtamojo ryšio raštingumas – tai teorija pagrįsta sistema, kuri gali padėti mokytojams ir sistemų bei išteklių kūrėjams atsakyti į šį klausimą. Tai gali padėti išsiaiškinti, ko turėtume mokyti apie DI sistemas ir kaip turėtume kurti susijusias mokymosi užduotis bei mokymosi sistemas, kuriose mokiniai sąveikautų su mokymo ir mokymosi DI taikomųjų programų rezultatais.\n\n\n                  \n                  Pagrindinės sąvokos \n                  \n                \n\n\nGrįžtamojo ryšio raštingumas\nKompetencijos, kurios palaiko socialinę grįžtamojo ryšio sąveiką.\nGrįžtamojo ryšio tipai\nSkirtingos grįžtamojo ryšio rūšys, įskaitant pasakojimą, konsultavimą, supratimo ugdymą ir atsivėrimą2\nMokinių grįžtamojo ryšio raštingumas\nSu grįžtamuoju ryšiu susijusios mokinių kompetencijos, apimančios gebėjimą įvertinti grįžtamojo ryšio procesą, priimti sprendimus, susijusius su grįžtamuoju ryšiu, imtis veiksmų ir valdyti savo reakcijas į grįžtamąjį ryšį (ir jo poveikį)3.\nMokytojų grįžtamojo ryšio raštingumas\nSu grįžtamuoju ryšiu susijusios mokytojų kompetencijos, apimančios gebėjimą kurti grįžtamąjį ryšį mokymosi kontekste, atsižvelgti į grįžtamojo ryšio santykinius aspektus ir pragmatiškai vertinti grįžtamąjį ryšį4.\n\n\n\nGrįžtamojo ryšio raštingumas ir DI generuoti paaiškinimai\nGrįžtamojo ryšio raštingumo kontekste naudinga apsvarstyti tris teorijas (grįžtamojo ryšio tipus, mokinių grįžtamojo ryšio raštingumą ir mokytojų grįžtamojo ryšio raštingumą).5 Kiekviena iš šių teorinių dalių buvo sukurta remiantis idėja, kad mokytojas ir mokinys bendrauja tiesiogiai, o ne per DI taikomąją programą, teikiančią grįžtamąjį ryšį. Tačiau Cucuiat ir Waite (2024) atlikę mokslinį tyrimą apie tai, kaip mokytojai galėtų naudoti DI įrankius informatikos pamokose, kad padėtų mokiniams išmokti programuoti, nustatė, kad grįžtamojo ryšio raštingumas yra būtinas analizuojant, kaip DI grindžiami paaiškinimai gali būti pateikti mokiniams5.\n! Image \n[figcaption ]Trys grįžtamojo ryšio tipų2, mokinių grįžtamojo ryšio raštingumo3 ir mokytojų grįžtamojo ryšio raštingumo4 teorijos yra tarpusavyje susijusios ir gali turėti įtakos kūrėjams bei DI taikomosioms programoms (remiantis Rohlfing et al. 6).\nGrįžtamojo ryšio tipai\nKeturi grįžtamojo ryšio tipai (pasakymas, konsultavimas, supratimo ugdymas ir atsivėrimas) leidžia paprastai apibūdinti žmonių ir sistemų kuriamą grįžtamąjį ryšį2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrįžtamojo ryšio tipaiPedagogo vaidmuoBesimokančiojo vaidmuoPasakymasVienakrypčiu būdu perduoti „teisingą“ informacijąPasyvusKonsultavimasNukreipti teisinga kryptimiAktyvus – pritaikyti žiniasSupratimo ugdymasTeikti tikslinį mokymąAktyvus – įgyti arba plėsti žiniasAtsivėrimasPristatyti naujas perspektyvasAktyvus – interpretuoti ir vertinti naujas žinias\nNagrinėdami DI sistemų pateiktus programos klaidų pranešimų paaiškinimus, mokytojai prašė vengti pasakymo tipo grįžtamojo ryšio; toks grįžtamasis ryšys gali priversti besimokančius per daug pasikliauti DI sistemomis ir patiems aktyviai nesimokyti. Mokytojai pageidautų, kad besimokantieji negautų atsakymų, o būtų nukreipti juos rasti patys.\nGrįžtamasis ryšys taip pat turėtų būti nukreiptas į tolesnį mokymąsi 7 ir apibendrintas, kad mokiniai galėtų pakartotinai panaudoti naujas žinias kituose kontekstuose.\nMokytojai linkę naudoti įvairius grįžtamojo ryšio tipus net to nesuvokdami, priklausomai nuo besimokančiojo, temos, atliekamos užduoties ir pažangos, kurios tikisi iš atitinkamos mokymosi patirties. Kiek veiksmingas bus DI generuotas grįžtamasis ryšys teikiant tokį įvairiapusį grįžtamąjį ryšį kol kas nėra aišku.\nMokinių grįžtamojo ryšio raštingumas\nMokinių grįžtamojo ryšio raštingumas apibūdinamas kaip sudarytas iš keturių pagrindinių aspektų: gebėjimo įvertinti grįžtamojo ryšio procesą, susidaryti nuomonę apie grįžtamąjį ryšį, imtis veiksmų ir valdyti savo reakcijas į grįžtamąjį ryšį (ir jo poveikį)3. Tai svarbu prisiminti vertinant, kaip mokiniai turėtų reaguoti į grįžtamąjį ryšį.\nMokytojų grįžtamojo ryšio raštingumas\nMokytojų grįžtamojo ryšio raštingumas yra sistema, kuri apibrėžia pagrindines mokytojų kompetencijas, susijusias su grįžtamuoju ryšiu. Ji apibūdina gebėjimą kurti grįžtamąjį ryšį mokymosi kontekste, atsižvelgti į grįžtamojo ryšio santykinius aspektus ir pragmatiškai vertinti grįžtamąjį ryšį4.\nGrįžtamojo ryšio raštingumo integravimas į klasės praktines užduotis\nPamokose vis dažniau naudojant DI taikomasias programas mokytojams reikės keisti mokymo turinį ir būdą. Tuo tarpu mokiniams reikės patarimų, nes keičiasi jų mokymosi būdai. Iš tiesų, daugelis mokinių jau dabar daugiau ar mažiau sėkmingai įvairiais būdais naudoja DI taikomųjų programų generuotą grįžtamąjį ryšį (pvz., kaip aptarta Kazemitabaar et al.8).\nGrįžtamojo ryšio raštingumas suteikia pagrindus atsižvelgti į šiuos pokyčius ir užtikrinti, kad mokytojai ir mokiniai kuo geriau išnaudotų DI mokymo ir mokymosi programas klasėje.\nGrįžtamojo ryšio raštingumas gali padėti mokiniams:\n\nPalyginti ir nuspręsti, ką daryti su mokytojo ar bendramokslių grįžtamuoju ryšiu ir DI sistemos rezultatais\nSuprasti, kodėl DI generuotas grįžtamasis ryšys gali būti klaidingas, naudoti nepažįstamas sąvokas arba nukreipti juos į kitą žingsnį, kuris nėra labai naudingas jų mokymosi pažangai\nIšmokti naujų procesų, kaip dirbti su DI generuotais paaiškinimais, pavyzdžiui, vertinimo metodų ir sprendimų registravimo\n\nGrįžtamojo ryšio raštingumas gali padėti mokytojams:\n\nĮvertinti, kaip ir kada DI generuojamas grįžtamasis ryšys galėtų praturtinti ar net pakeisti esamą dialogą tarp mokytojo ir mokinio\nMokyti mokinius apie grįžtamojo ryšio raštingumą ir padėti jiems ugdyti bei taikyti savo grįžtamojo ryšio raštingumo žinias\n\nLaikui bėgant, mokytojai taip pat gali reikalauti iš DI įrankių daugiau, tikėdamiesi tokių funkcijų, kaip galimybė išjungti grįžtamąjį ryšį pasakojimo forma ir gauti grįžtamąjį ryšį tik konsultavimo forma, siekiant geriau padėti mokiniams siekti iš anksto nustatytų mokymosi tikslų ir prisidėti prie naudingų žinių lavinimo.\nŠaltiniai\nŠaltinio pdf\nFootnotes\n\n\nHattie, J., Timperley, H. (2007). The power of feedback. qr23_4 ↩\n\n\nMcLean, A. J., et al. (2015). An anatomy of feedback: a phenomenographic investigation of undergraduate students’ conceptions of feedback. qr23_1 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Boud, D. (2018). The development of student feedback literacy: enabling uptake of feedback. qr23_2 ↩ ↩2 ↩3\n\n\nCarless, D., Winstone, N. (2023). Teacher feedback literacy and its interplay with student feedback literacy. qr23_3 ↩ ↩2 ↩3\n\n\nCucuiat, V., Waite, J. (2024). Feedback Literacy: Holistic Analysis of Secondary Educators’ Views of LLM Explanations of Program Error Messages. qr23_6 ↩ ↩2\n\n\nRohlfing, K. J., et al. (2020). Explanation as a social practice: Toward a conceptual framework for the social design of AI systems. qr23_5 ↩\n\n\nvan Heerden, M. (2021). (How) do written comments feed-forward? A translation device for developing tutors’ feedback-giving literacy. qr23_7 ↩\n\n\nKazemitabaar, M., et al. (2023). Studying the effect of AI code generators on supporting novice learners in introductory programming. qr23_8 ↩\n\n\n","frontmatter":{"title":"Grįžtamojo ryšio raštingumas – sistema, skirta veiksmingai naudoti DI rezultatus mokymo ir mokymosi procese","lang":"Lithuaniun","translatedFrom":"[QR23](../QR23.md)","aliases":["QR23_it"],"draft":null}},"Quick-Reads/QR23_lv":{"slug":"Quick-Reads/QR23_lv","filePath":"Quick Reads/QR23_lv.md","title":"Atgriezeniskās saites pratība: Ietvars mākslīgā intelekta rezultātu efektīvai izmantošanai mācību un mācīšanās procesā","links":["Quick-Reads/Attēls","Quick-Reads/the-cc.io/qr23_4","Quick-Reads/the-cc.io/qr23_1","Quick-Reads/the-cc.io/qr23_2","Quick-Reads/the-cc.io/qr23_3","Quick-Reads/the-cc.io/qr23_6","Quick-Reads/the-cc.io/qr23_5","Quick-Reads/the-cc.io/qr23_7","Quick-Reads/the-cc.io/qr23_8"],"tags":[],"content":"Atgriezeniskā saite ir būtiska jebkurā mācību un mācīšanās kontekstā. Hetija un Timperlija apraksta atgriezenisko saiti kā “informāciju, ko sniedz persona (piemēram, skolotājs, vienaudzis, grāmata, vecāks, es pats, pieredze) par personas snieguma vai izpratnes aspektiem”1. Papildus atsauksmēm, ko sniedz cilvēki, tagad atsauksmes sniedz arī sistēmas, tostarp mākslīgā intelekta lietojumprogrammas. Kā mēs varam nodrošināt, lai visi studenti maksimāli izmantotu mākslīgā intelekta sistēmas sniegtās atsauksmes? Atgriezeniskās saites pratība ir uz teoriju balstīta sistēma, kas var palīdzēt skolotājiem un sistēmu un resursu izstrādātājiem atbildēt uz šo jautājumu. Tas var palīdzēt šīm grupām izstrādāt to, kas mums būtu jāmāca par mākslīgā intelekta sistēmām un kā mums vajadzētu izstrādāt saistītas mācību aktivitātes un mācību sistēmas, kas ietver skolēnu mijiedarbību ar mākslīgā intelekta lietojumprogrammu mācīšanas un apguves rezultātiem.\n\n\n                  \n                  Galvenie jēdzieni \n                  \n                \n\n\nAtgriezeniskās saites pratība:\nKompetenču kopums, kas atbalsta atgriezeniskās saites sociālo mijiedarbību.\nAtsauksmju veidi:\nDažādas atgriezeniskās saites klasifikācijas, kas ietver atgriezenisko saiti kā stāstīšanu, vadīšanu, izpratnes attīstīšanu un atvēršanu2.\nStudentu atgriezeniskās saites pratība:\nAr atgriezenisko saiti saistītās studentu kompetences, kas ietver spēju novērtēt atgriezeniskās saites procesu, pieņemt spriedumus par atgriezenisko saiti, rīkoties un pārvaldīt savu reakciju uz (atgriezeniskās saites ietekmi)3.\nSkolotāju atgriezeniskās saites pratība:\nSkolotāju kompetences, kas saistītas ar atgriezenisko saiti, tostarp spēja veidot atgriezenisko saiti mācību kontekstā, ņemt vērā atgriezeniskās saites aspektus un pragmatiski izturēties pret atgriezenisko saiti4.\n\n\n\nAtgriezeniskās saites pratība un mākslīgā intelekta radīti skaidrojumi\nAtsauksmju pratības ietvarā ir lietderīgi apsvērt trīs teorijas (atsauksmju veidi, studentu atgriezeniskās saites pratība un skolotāju atgriezeniskās saites pratība).5. Katra no šīm komponentu teorijām ir izstrādāta ar ideju, ka skolotājs un skolēns mijiedarbojas tieši, nevis ar mākslīgā intelekta lietojumprogrammas palīdzību, kas sniedz atgriezenisko saiti. Tomēr pētījumā par to, kā skolotāji varētu izmantot mākslīgā intelekta rīkus datorzinātņu stundās, lai palīdzētu skolēniem apgūt programmēšanu, Kukuiats un Veits (2024) atklāja, ka atgriezeniskās saites pratība ir būtiska, lai analizētu, kā skolēniem var ieviest mākslīgā intelekta uzlabotus skaidrojumus5.\n! Image \n[figcaption] Trīs atgriezeniskās saites veidu teorijas2, studentu atgriezeniskās saites pratība3 un skolotāju atgriezeniskās saites pratība4 ir savstarpēji saistītas un var ietekmēt arī izstrādātājus un mākslīgā intelekta lietojumprogrammas (iedvesmojoties no Rohlfinga u.c. 6).\nAtsauksmju veidi\nČetri atgriezeniskās saites veidi (stāstīšana, vadīšana, izpratnes attīstīšana un atvēršana) ir vienkārši veidi, kā aprakstīt cilvēku un sistēmu radīto atgriezenisko saiti2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAtsauksmju veidsPedagoga lomaStudenta lomaStāstīšanaVienvirziena “pareizas” informācijas pārraidePasīvsVadošaisNorādiet pareizajā virzienāAktīvs — pielieto zināšanasIzpratnes attīstīšanaNodrošināt mērķtiecīgu mācīšanuAktīvs — konstruēt vai pielāgot zināšanasAtvēršanaPiedāvājiet jaunas perspektīvasAktīvs — interpretē un novērtē jaunas zināšanas\nIzpētot mākslīgā intelekta sistēmu sniegtos programmas kļūdu ziņojumu skaidrojumus, skolotāji ir lūguši izvairīties no atsauksmēm, kas izpaužas kā norādījumi; šāda atsauksme var novest pie tā, ka skolēni kļūst pārāk atkarīgi no mākslīgā intelekta sistēmām un paši aktīvi nemācās. Skolotāji vēlētos, lai skolēniem nevis pateiktu atbildes, bet gan tiktu vadīti.\nAtsauksmēm vajadzētu arī sniegt atgriezenisko saiti uz priekšu7 un vispārināt, lai skolēni varētu atkārtoti izmantot jaunās zināšanas citos kontekstos\nSkolotāji, visticamāk, izmantos dažādus atgriezeniskās saites veidus, pat to neapzinoties, pielāgojoties skolēnam, tēmai, veicamajam uzdevumam un progresam, ko viņi sagaida šajā mācību pieredzē. Cik efektīva būs mākslīgā intelekta radītā atgriezeniskā saite, sniedzot šādu niansētu atgriezenisko saiti, vēl jānoskaidro.\nStudentu atgriezeniskās saites pratība\n. Tas kalpo kā svarīgs ietvars, domājot par to, kā studentiem vajadzētu rīkoties ar atsauksmēm.\nSkolotāju atgriezeniskās saites pratība\nSkolotāju atgriezeniskās saites pratība ir sistēma, kas identificē galvenās skolotāju kompetences saistībā ar atgriezenisko saiti. Tā ir raksturota kā spēja veidot atgriezenisko saiti mācību kontekstā, ņemt vērā atgriezeniskās saites aspektus un pragmatiski izturēties pret atgriezenisko saiti4.\nAtgriezeniskās saites pratības integrēšana klases praksē\nTā kā mākslīgā intelekta lietojumprogrammas kļūst arvien izplatītākas klasēs, skolotājiem būs jāmaina tas, ko viņi māca un kā viņi to dara. Tikmēr skolēniem būs nepieciešama vadība, mainoties viņu mācīšanās veidam. Patiešām, daudzi studenti jau izmanto mākslīgā intelekta lietojumprogrammu sniegto atgriezenisko saiti dažādos veidos, ar lielākiem un mazākiem panākumiem (piemēram, kā apsprieduši Kazemitabaar et al.8).\nAtgriezeniskās saites pratība nodrošina ietvaru, lai sāktu risināt šīs izmaiņas un nodrošinātu, ka skolotāji un skolēni maksimāli izmanto mākslīgā intelekta mācību un mācīšanās lietojumprogrammas klasē\nAtgriezeniskās saites pratība var palīdzēt studentiem\n\nSalīdzināt un spriest, ko darīt ar skolotāja atsauksmēm, vienaudžu atsauksmēm un mākslīgā intelekta sistēmas rezultātiem\nIzprast, kāpēc mākslīgā intelekta radītā atgriezeniskā saite var būt nepareiza, lietot nepazīstamu vārdu krājumu vai norādīt uz nākamo soli, kas nav īpaši noderīgs viņu mācību progresam\nApgūstiet jaunus procesus darbam ar mākslīgā intelekta ģenerētiem skaidrojumiem, piemēram, novērtēšanas metodes un spriedumu reģistrēšanu\n\nAtgriezeniskās saites pratība var palīdzēt skolotājiem:\n\nApsveriet, kā un kad mākslīgā intelekta radītā atgriezeniskā saite varētu bagātināt vai pat aizstāt esošo skolotāju un skolēnu dialogu\nMāciet studentiem atgriezeniskās saites pratību un atbalstiet studentus savas atgriezeniskās saites pratības attīstīšanā un pielietošanā\n\nLaika gaitā skolotāji var arī pieprasīt vairāk no mākslīgā intelekta rīkiem, sagaidot tādas funkcijas kā iespēja izslēgt atgriezenisko saiti stāstīšanas veidā un saņemt atgriezenisko saiti tikai vadīšanas veidā, lai labāk vadītu skolēnus uz iepriekš definētiem mācību mērķiem un veicinātu noderīgu zināšanu uzkrāšanu.\nAtsauces\nAvota pdf fails\nFootnotes\n\n\nHattie, J., &amp; Timperley, H. (2007). Atgriezeniskās saites spēks. qr23_4 ↩\n\n\nMcLean, A. J., et al. (2015). Atgriezeniskās saites anatomija: bakalaura studentu priekšstatu par atgriezenisko saiti fenomenogrāfisks pētījums. qr23_1 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Boud, D. (2018). Studentu atgriezeniskās saites pratības attīstība: atgriezeniskās saites pieņemšanas veicināšana. qr23_2 ↩ ↩2\n\n\nCarless, D., &amp; Winstone, N. (2023). Skolotāju atgriezeniskās saites pratība un tās mijiedarbība ar skolēnu atgriezeniskās saites pratību. qr23_3 ↩ ↩2 ↩3\n\n\nCucuiat, V., &amp; Waite, J. (2024). Atgriezeniskās saites lasītprasme: holistiska vidusskolu pedagogu viedokļu par LLM programmas kļūdu ziņojumu skaidrojumiem analīze. qr23_6 ↩ ↩2\n\n\nRohlfing, K. J., et al. (2020). Skaidrojums kā sociāla prakse: ceļā uz konceptuālu ietvaru mākslīgā intelekta sistēmu sociālajam dizainam. qr23_5 ↩\n\n\nvan Heerden, M. (2021). (Kā) rakstiskie komentāri ietekmē situāciju? Tulkošanas rīks pasniedzēju atgriezeniskās saites sniegšanas prasmju attīstīšanai. qr23_7 ↩\n\n\nKazemitabaar, M., et al. (2023). Mākslīgā intelekta koda ģeneratoru ietekmes izpēte, atbalstot iesācējus programmēšanas ievadkursā. qr23_8 ↩\n\n\n","frontmatter":{"title":"Atgriezeniskās saites pratība: Ietvars mākslīgā intelekta rezultātu efektīvai izmantošanai mācību un mācīšanās procesā","lang":"Latvian","translatedFrom":"[QR23](../QR23.md)","aliases":["QR23_lv"],"draft":null}},"Quick-Reads/QR23_ro":{"slug":"Quick-Reads/QR23_ro","filePath":"Quick Reads/QR23_ro.md","title":"Competențe de feedback: Un cadru pentru utilizarea eficientă a rezultatelor AI în predare și învățare","links":["Quick-Reads/Image","Quick-Reads/the-cc.io/qr23_4","Quick-Reads/the-cc.io/qr23_1","Quick-Reads/the-cc.io/qr23_2","Quick-Reads/the-cc.io/qr23_3","Quick-Reads/the-cc.io/qr23_6","Quick-Reads/the-cc.io/qr23_5","Quick-Reads/the-cc.io/qr23_7","Quick-Reads/the-cc.io/qr23_8"],"tags":[],"content":"Feedback-ul este esențial în orice context de predare și învățare. Hattie și Timperley descriu feedback-ul ca fiind „informația furnizată de un agent (de exemplu, un profesor, un coleg, o carte, un părinte, tu însuți, o experiență) cu privire la aspecte ale performanței sau înțelegerii unei persoane”1. Pe lângă faptul că oamenii oferă feedback, și sistemele, inclusiv aplicațiile AI, oferă acum feedback. Cum ne asigurăm că toți elevii profită la maximum de feedback-ul generat de sistemele AI? Competențele de feedback reprezintă un cadru teoretic care îi poate ajuta pe profesori, dar și pe creatorii de sisteme și resurse să răspundă la această întrebare. Îi poate ajuta să decidă ce ar trebui să predăm despre sistemele AI și cum ar trebui să proiectăm activități și sisteme de învățare în care elevii interacționează cu rezultatele aplicațiilor AI.\n\n\n                  \n                  Concepte-cheie \n                  \n                \n\n\nCompetențe de feedback:\nUn set de competențe care sprijină oferirea și primirea feedbackului în interacțiuni sociale.\nTipuri de feedback:\nClasificări diferite ale feedback-ului, care includ feedback de tip informare, îndrumare, dezvoltarea înțelegerii și deschiderea către noi perspective2. \nCompetențe de feedback ale elevilor\nCompetențele ale elevilor legate de feedback, care includ abilitatea de a aprecia procesul de feedback, de a evalua feedback-ul, de a acționa și de a-și gestiona reacțiile la feedback3.\nCompetențe de feedback ale profesorilor\nCompetențe ale profesorilor legate de feedback, care includ abilitatea de a proiecta feedback-ul în contextul de învățare, de a ține cont de aspectele relaționale ale feedback-ului și de a fi pragmatici în privința feedback-ului4.\n\n\n\nCompetențele de feedback și explicațiile generate de AI\nTrei teorii (tipuri de feedback, competențele de feedback ale elevilor și competențele de feedback ale profesorilor) sunt utile de luat în considerare într-un cadru de competențe de feedback5. Fiecare dintre aceste teorii a fost dezvoltată pornind de la ideea că profesorul și elevul interacționează direct, și nu că o aplicație AI oferă feedback. Totuși, în cercetările despre cum ar putea profesorii să utilizeze instrumente AI la ora de informatică pentru a-i ajuta pe elevi să învețe să programeze, Cucuiat și Waite (2024) au descoperit că aceste competențe de feedback au fost esențiale pentru a analiza modul în care pot fi introduse explicațiile îmbunătățite ale AI pentru a le fi de folos elevilor5.\n! Image \n[figcaption] Cele trei teorii — tipurile de feedback2, competențele de feedback ale elevilor3 și competențele de feedback ale profesorilor4 sunt interconectate și pot influența și dezvoltatorii și aplicațiile AI (inspirat de Rohlfing et al. 6).\nTipurile de feedback\nCele patru tipuri de feedback (informarea, îndrumarea, dezvoltarea înțelegerii și deschiderea spre noi perspective) sunt modalități simple de a descrie feedback-ul creat de oameni sau de sisteme2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipul de feedbackRolul profesoruluiRolul elevuluiInformareaTransmite informația „corectă” în mod unidirecționalPasivÎndrumareaGhidează în direcția corectăActiv — aplică cunoștințeleDezvoltarea înțelegeriiOferă predare specificăActiv — își consolidează sau ajustează cunoștințeleDeschiderea spre noi perspectivePrezintă perspective noiActiv — interpretează și evaluează noile cunoștințe\nCând analizează explicații generate de sisteme AI cu privire la mesajele de eroare din programe, profesorii au solicitat ca feedback-ul de tip „informare” să fie evitat; un astfel de feedback poate duce la dependența excesivă de AI și la lipsa de învățare activă. Profesorii preferă ca elevii să nu primească direct răspunsurile, ci să fie ghidați către ele.\nFeedback-ul ar trebui, de asemenea, să fie orientat către viitor7 și general, astfel încât studenții să poată reutiliza noile cunoștințe în alte contexte. \nProfesorii tind să utilizeze o gamă variată de tipuri de feedback fără să-și dea seama, adaptându-se la elev, la subiect, la sarcina desfășurată și la progresul așteptat pentru acea experiență de învățare. Cât de eficient va fi feedback-ul produs de AI în a furniza un asemenea feedback nuanțat rămâne de văzut.\nCompetențele de feedback ale elevilor\nTeoria privind competențele de feedback ale elevilor a fost descrisă ca având patru aspecte principale: elevii trebuie să fie capabili să aprecieze procesul de feedback, să evalueze feedback-ul, să acționeze în baza lui și să își gestioneze reacțiile la feedback3. Este un cadru important atunci când ne gândim la modul în care elevii ar trebui să gestioneze feedback-ul.\nCompetențele de feedback ale profesorilor\nTeoria privind competențele de feedback ale profesorilor este un cadru care identifică abilitățile cheie ale profesorilor în ceea ce privește feedback-ul. A fost descrisă ca incluzând abilitatea de a proiecta feedback în contextul de învățare, de a lua în considerare aspectele relaționale ale feedback-ului și de a fi pragmatici în ceea ce privește feedback-ul4.\nIntegrarea competențelor de feedback la clasă\nPe măsură ce aplicațiile AI devin tot mai prezente în sălile de clasă, profesorii vor trebui să schimbe ceea ce predau și modul în care o fac. În același timp, elevii vor avea nevoie de îndrumare, deoarece modul în care învață se schimbă. Într-adevăr, mulți elevi utilizează deja feedback-ul produs de aplicațiile AI în moduri diferite, cu grade mai mari sau mai mici de succes (de exemplu, așa cum discută Kazemitabaar et al.8).\nCompetențele de feedback oferă un cadru pentru a începe să răspundem acestor schimbări și să ne asigurăm că profesorii și elevii profită la maximum de aplicațiile AI pentru predare și învățare în sala de clasă.\nCompetențele de feedback îi pot ajuta pe elevi să:\n\nCompare și să decidă ce să facă cu feedback-ul de la profesor, feedback-ul de la colegi și rezultatele unui sistem AI\nÎnțeleagă de ce feedback-ul produs de AI poate fi greșit, poate folosi un vocabular necunoscut sau poate indica un pas următor care nu este util pentru progresul lor în învățare\nÎnvețe noi procese pentru a lucra cu explicațiile produse de AI, cum ar fi tehnici de evaluare și modalități de a consemna evaluările\n\nCompetențele de feedback îi poate ajuta pe profesori să:\n\nIa în considerare cum și când feedback-ul produs de AI ar putea îmbogăți sau chiar înlocui dialogul existent între profesor și elev\nÎi învețe pe elevi despre competențele de feedback și să îi sprijine în dezvoltarea și aplicarea propriilor competențe de feedback\n\nÎn timp, profesorii ar putea, de asemenea, să ceară mai mult de la instrumentele AI, așteptând funcționalități precum posibilitatea de a dezactiva feedback-ul de tip „informare” și de a lăsa doar feedback-ul de tip „îndrumare”, pentru a conduce mai bine elevii către obiective de învățare prestabilite și către dobândirea de cunoștințe utile.\nReferințe\nSource pdf\nFootnotes\n\n\nHattie, J., &amp; Timperley, H. (2007). The power of feedback. qr23_4 ↩\n\n\nMcLean, A. J., et al. (2015). An anatomy of feedback: a phenomenographic investigation of undergraduate students’ conceptions of feedback. qr23_1 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Boud, D. (2018). The development of student feedback literacy: enabling uptake of feedback. qr23_2 ↩ ↩2 ↩3\n\n\nCarless, D., &amp; Winstone, N. (2023). Teacher feedback literacy and its interplay with student feedback literacy. qr23_3 ↩ ↩2 ↩3\n\n\nCucuiat, V., &amp; Waite, J. (2024). Feedback Literacy: Holistic Analysis of Secondary Educators’ Views of LLM Explanations of Program Error Messages. qr23_6 ↩ ↩2\n\n\nRohlfing, K. J., et al. (2020). Explanation as a social practice: Toward a conceptual framework for the social design of AI systems. qr23_5 ↩\n\n\nvan Heerden, M. (2021). (How) do written comments feed-forward? A translation device for developing tutors’ feedback-giving literacy. qr23_7 ↩\n\n\nKazemitabaar, M., et al. (2023). Studying the effect of AI code generators on supporting novice learners in introductory programming. qr23_8 ↩\n\n\n","frontmatter":{"title":"Competențe de feedback: Un cadru pentru utilizarea eficientă a rezultatelor AI în predare și învățare","lang":"Romanian","translatedFrom":"[QR23](../QR23.md)","aliases":["QR22_ro"],"draft":null}}}